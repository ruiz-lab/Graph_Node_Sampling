nohup: ignoring input
wandb: Agent Starting Run: f9026719 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: Currently logged in as: jamesli-wks (jamesli-wks-johns-hopkins-university). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_160717-f9026719
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/f9026719
Create sweep with ID: fqnv4fuu
Sweep URL: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  0%|          | 1/200 [00:00<01:00,  3.29it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:02, 81.47it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 133.47it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 164.10it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 181.94it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 194.84it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 206.63it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 212.69it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 216.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 171.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.43538
wandb: sub_train_loss 1.34878
wandb:       test_acc 0.333
wandb:      valid_acc 0.358
wandb: 
wandb: üöÄ View run solar-sweep-1 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/f9026719
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_160717-f9026719/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nfvhccah with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_160733-nfvhccah
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/nfvhccah
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 206.75it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 208.23it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 216.42it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 221.04it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 223.21it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 223.93it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 225.20it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:00<00:00, 224.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 222.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.66248
wandb: sub_train_loss 1.05219
wandb:       test_acc 0.613
wandb:      valid_acc 0.59
wandb: 
wandb: üöÄ View run fallen-sweep-2 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/nfvhccah
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_160733-nfvhccah/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: snx89j6i with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_160748-snx89j6i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/snx89j6i
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 222.29it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:00, 223.03it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 223.16it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 219.86it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 224.44it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 230.45it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 232.97it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:00<00:00, 235.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 230.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.63848
wandb: sub_train_loss 1.05567
wandb:       test_acc 0.685
wandb:      valid_acc 0.678
wandb: 
wandb: üöÄ View run valiant-sweep-3 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/snx89j6i
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_160748-snx89j6i/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 146kg2wu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_160800-146kg2wu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/146kg2wu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 206.23it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:00, 214.22it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 211.79it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 211.41it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 212.97it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 216.22it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 216.33it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:00<00:00, 210.83it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:00<00:00, 197.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 206.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.62518
wandb: sub_train_loss 1.17968
wandb:       test_acc 0.684
wandb:      valid_acc 0.694
wandb: 
wandb: üöÄ View run sunny-sweep-4 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/146kg2wu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_160800-146kg2wu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: n4hcqhnu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_160816-n4hcqhnu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/n4hcqhnu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 204.19it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 203.40it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 205.70it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 204.52it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 205.90it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 203.74it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 205.18it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 205.97it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:00<00:00, 208.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 205.60it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.67984
wandb: sub_train_loss 1.09384
wandb:       test_acc 0.612
wandb:      valid_acc 0.628
wandb: 
wandb: üöÄ View run pleasant-sweep-5 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/n4hcqhnu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_160816-n4hcqhnu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: cxh11iji with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_160830-cxh11iji
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/cxh11iji
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 205.36it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 203.71it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 201.87it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 201.60it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 202.52it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 203.28it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 210.16it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:00<00:00, 215.92it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:00<00:00, 223.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 212.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.6695
wandb: sub_train_loss 1.12002
wandb:       test_acc 0.686
wandb:      valid_acc 0.69
wandb: 
wandb: üöÄ View run jolly-sweep-6 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/cxh11iji
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_160830-cxh11iji/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: brignimc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_160847-brignimc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-7
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/brignimc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 178.98it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 179.28it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 173.54it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 171.18it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 169.08it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 167.11it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 166.06it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 173.01it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 178.74it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 182.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 176.58it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÅ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.40694
wandb: sub_train_loss 1.46124
wandb:       test_acc 0.25
wandb:      valid_acc 0.256
wandb: 
wandb: üöÄ View run super-sweep-7 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/brignimc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_160847-brignimc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: fdo8mn4j with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_160909-fdo8mn4j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-8
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/fdo8mn4j
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 173.94it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 171.20it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 171.32it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 169.73it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 173.08it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 174.68it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 173.28it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 171.17it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 174.12it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 175.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 174.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 173.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30318
wandb: sub_train_loss 1.75784
wandb:       test_acc 0.298
wandb:      valid_acc 0.306
wandb: 
wandb: üöÄ View run stilted-sweep-8 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/fdo8mn4j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_160909-fdo8mn4j/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: d5tbfpp1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_160921-d5tbfpp1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-9
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/d5tbfpp1
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 184.09it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 188.33it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 190.14it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 190.95it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 192.01it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 191.84it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 189.74it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 186.30it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:00<00:00, 181.80it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 178.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 185.16it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.39476
wandb: sub_train_loss 1.58949
wandb:       test_acc 0.533
wandb:      valid_acc 0.52
wandb: 
wandb: üöÄ View run sunny-sweep-9 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/d5tbfpp1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_160921-d5tbfpp1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: yf2acmy7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_160942-yf2acmy7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-10
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/yf2acmy7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 148.05it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 155.13it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 161.49it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 165.53it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 167.91it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 169.94it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 170.87it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 169.85it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:00<00:00, 166.09it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 165.47it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 166.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 166.50it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.41027
wandb: sub_train_loss 1.44311
wandb:       test_acc 0.483
wandb:      valid_acc 0.486
wandb: 
wandb: üöÄ View run deep-sweep-10 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/yf2acmy7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_160942-yf2acmy7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lfdb369u with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_160956-lfdb369u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-11
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/lfdb369u
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 187.74it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 161.02it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 155.47it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 161.86it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 167.57it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 170.38it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 170.57it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 171.12it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 170.35it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 172.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 175.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 170.16it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.55096
wandb: sub_train_loss 1.15676
wandb:       test_acc 0.459
wandb:      valid_acc 0.452
wandb: 
wandb: üöÄ View run whole-sweep-11 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/lfdb369u
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_160956-lfdb369u/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ks0bylrw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161008-ks0bylrw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-12
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ks0bylrw
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 188.50it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 192.77it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 191.18it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 191.08it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 190.25it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 189.39it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 186.80it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 181.39it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:00<00:00, 171.63it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 170.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 180.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.44572
wandb: sub_train_loss 1.36565
wandb:       test_acc 0.445
wandb:      valid_acc 0.444
wandb: 
wandb: üöÄ View run olive-sweep-12 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ks0bylrw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161008-ks0bylrw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fcv146bg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161023-fcv146bg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-13
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/fcv146bg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  0%|          | 1/200 [00:00<01:09,  2.85it/s]  7%|‚ñã         | 14/200 [00:00<00:04, 39.25it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:02, 64.79it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 81.95it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:01, 94.47it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 103.35it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:01, 115.35it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:01<00:00, 123.63it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:01<00:00, 129.10it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:01<00:00, 132.90it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 134.52it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 135.53it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 136.33it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 138.12it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 137.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 109.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñà‚ñá‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñà‚ñÜ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.32275
wandb: sub_train_loss 1.71466
wandb:       test_acc 0.183
wandb:      valid_acc 0.2
wandb: 
wandb: üöÄ View run comfy-sweep-13 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/fcv146bg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161023-fcv146bg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0pk6h1iq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161038-0pk6h1iq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-14
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0pk6h1iq
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 166.71it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 164.48it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 161.40it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 161.66it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 161.91it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 160.47it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 157.68it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 131.97it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 133.31it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 126.63it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 126.28it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 124.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 138.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.32349
wandb: sub_train_loss 1.58564
wandb:       test_acc 0.264
wandb:      valid_acc 0.272
wandb: 
wandb: üöÄ View run honest-sweep-14 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0pk6h1iq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161038-0pk6h1iq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1mksyqpq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161053-1mksyqpq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-15
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/1mksyqpq
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 132.27it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 140.77it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 134.55it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 140.71it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 144.24it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 145.54it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 145.15it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 141.78it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 144.78it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 150.34it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 152.78it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 154.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 147.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.45347
wandb: sub_train_loss 1.48005
wandb:       test_acc 0.345
wandb:      valid_acc 0.368
wandb: 
wandb: üöÄ View run helpful-sweep-15 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/1mksyqpq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161053-1mksyqpq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: cu96zcrf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161114-cu96zcrf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-16
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/cu96zcrf
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 155.61it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 144.71it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 142.94it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 141.41it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 141.44it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 142.73it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 144.74it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 146.86it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 150.33it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 152.02it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 150.84it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 150.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 147.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÑ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.20052
wandb: sub_train_loss 1.87527
wandb:       test_acc 0.172
wandb:      valid_acc 0.196
wandb: 
wandb: üöÄ View run colorful-sweep-16 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/cu96zcrf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161114-cu96zcrf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vub4f16u with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161128-vub4f16u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-17
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/vub4f16u
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 114.08it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 126.70it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 125.10it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 119.41it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 118.60it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 118.35it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 118.65it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 120.68it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 123.84it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:01<00:00, 126.12it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 127.04it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 128.75it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 130.82it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 133.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 136.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 126.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.40916
wandb: sub_train_loss 1.60493
wandb:       test_acc 0.386
wandb:      valid_acc 0.394
wandb: 
wandb: üöÄ View run breezy-sweep-17 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/vub4f16u
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161128-vub4f16u/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ldbpq8lb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161144-ldbpq8lb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-18
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ldbpq8lb
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 136.85it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 140.12it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 134.94it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 141.19it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 145.58it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 149.01it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 151.00it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 150.54it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 149.72it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 148.47it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 146.07it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 145.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 146.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 146.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.41211
wandb: sub_train_loss 1.66115
wandb:       test_acc 0.26
wandb:      valid_acc 0.286
wandb: 
wandb: üöÄ View run generous-sweep-18 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ldbpq8lb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161144-ldbpq8lb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3jex1vzc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161159-3jex1vzc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-19
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/3jex1vzc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 22/300 [00:00<00:01, 217.15it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 220.12it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 220.17it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:00, 222.26it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:00, 221.62it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 221.01it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 220.72it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:00<00:00, 220.41it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:00<00:00, 220.92it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 219.95it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 222.24it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 224.35it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 222.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 221.60it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.68131
wandb: sub_train_loss 0.84468
wandb:       test_acc 0.552
wandb:      valid_acc 0.56
wandb: 
wandb: üöÄ View run vivid-sweep-19 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/3jex1vzc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161159-3jex1vzc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2iywv4lt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161215-2iywv4lt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-20
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/2iywv4lt
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 242.42it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 237.81it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:00, 235.54it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:00, 236.29it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:00, 239.23it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 241.43it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 235.05it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:00<00:00, 230.94it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:00<00:00, 226.32it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 226.72it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 226.98it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 227.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 231.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.7692
wandb: sub_train_loss 0.69026
wandb:       test_acc 0.548
wandb:      valid_acc 0.542
wandb: 
wandb: üöÄ View run elated-sweep-20 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/2iywv4lt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161215-2iywv4lt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: oxrfr79u with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161237-oxrfr79u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-21
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/oxrfr79u
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 219.09it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 211.62it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 212.24it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 207.44it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:00, 198.79it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 204.92it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 211.18it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:00<00:00, 211.99it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:00<00:00, 212.91it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 213.25it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 201.99it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 203.66it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 204.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 207.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.65583
wandb: sub_train_loss 0.89347
wandb:       test_acc 0.542
wandb:      valid_acc 0.554
wandb: 
wandb: üöÄ View run sparkling-sweep-21 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/oxrfr79u
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161237-oxrfr79u/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: vmybxchg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161257-vmybxchg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-22
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/vmybxchg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 228.12it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 220.93it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 215.38it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:00, 215.98it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:00, 215.85it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 210.98it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 205.66it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 205.72it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:00<00:00, 205.80it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 208.28it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 213.82it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 217.36it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 218.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 214.08it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.70052
wandb: sub_train_loss 0.88199
wandb:       test_acc 0.724
wandb:      valid_acc 0.736
wandb: 
wandb: üöÄ View run unique-sweep-22 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/vmybxchg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161257-vmybxchg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4s0h4csh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161312-4s0h4csh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-23
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/4s0h4csh
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 231.25it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 235.68it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:00, 238.50it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:00, 238.76it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 238.07it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 236.15it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:00<00:00, 232.34it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:00<00:00, 232.30it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:00<00:00, 230.56it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 229.98it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 229.31it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 230.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 232.66it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.65251
wandb: sub_train_loss 0.95422
wandb:       test_acc 0.646
wandb:      valid_acc 0.674
wandb: 
wandb: üöÄ View run wise-sweep-23 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/4s0h4csh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161312-4s0h4csh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ncnwsw5j with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161328-ncnwsw5j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-24
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ncnwsw5j
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 236.33it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 238.68it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:00, 232.98it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:00, 229.77it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 227.58it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 222.49it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:00<00:00, 223.13it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:00<00:00, 222.60it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:00<00:00, 223.51it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 219.75it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 217.38it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 217.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 223.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.54394
wandb: sub_train_loss 1.36379
wandb:       test_acc 0.517
wandb:      valid_acc 0.552
wandb: 
wandb: üöÄ View run dashing-sweep-24 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ncnwsw5j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161328-ncnwsw5j/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5y69ewcv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161343-5y69ewcv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-25
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5y69ewcv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 187.11it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 179.90it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 179.12it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 179.20it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 178.85it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 174.52it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:00, 174.00it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 173.36it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 172.33it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 170.91it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 169.07it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 169.42it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 169.27it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 170.67it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 171.77it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 172.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 173.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.50369
wandb: sub_train_loss 1.38893
wandb:       test_acc 0.553
wandb:      valid_acc 0.518
wandb: 
wandb: üöÄ View run honest-sweep-25 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5y69ewcv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161343-5y69ewcv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kxipfmon with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161358-kxipfmon
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-26
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/kxipfmon
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 187.26it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 181.94it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 181.93it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 181.84it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 180.96it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 179.54it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 178.65it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 178.11it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 176.01it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 174.26it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 169.70it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 165.21it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 167.00it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 169.89it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 171.62it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 172.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 174.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.56204
wandb: sub_train_loss 1.15635
wandb:       test_acc 0.401
wandb:      valid_acc 0.388
wandb: 
wandb: üöÄ View run absurd-sweep-26 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/kxipfmon
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161358-kxipfmon/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 91llik7i with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161414-91llik7i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-27
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/91llik7i
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 193.31it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 193.42it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 188.70it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 184.59it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 182.37it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 180.18it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 178.44it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 178.89it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 181.20it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 181.03it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 182.67it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 181.17it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 178.77it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 176.67it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 175.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 180.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.37149
wandb: sub_train_loss 1.69018
wandb:       test_acc 0.448
wandb:      valid_acc 0.466
wandb: 
wandb: üöÄ View run zesty-sweep-27 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/91llik7i
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161414-91llik7i/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 2bk2qf29 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161434-2bk2qf29
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-28
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/2bk2qf29
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 182.07it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 184.21it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 180.14it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 180.19it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 178.08it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 176.23it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 175.96it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 176.15it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 176.33it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 176.11it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 176.20it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 175.60it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 176.61it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 179.44it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 179.51it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 180.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 178.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñà‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31499
wandb: sub_train_loss 1.56353
wandb:       test_acc 0.476
wandb:      valid_acc 0.516
wandb: 
wandb: üöÄ View run visionary-sweep-28 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/2bk2qf29
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161434-2bk2qf29/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tt7aeh3d with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161451-tt7aeh3d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-29
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/tt7aeh3d
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 167.58it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 168.78it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 169.87it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 169.32it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 169.37it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 170.12it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 167.56it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 168.22it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 168.79it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 168.81it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 169.19it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 169.93it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 161.60it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 152.46it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 155.88it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 157.00it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 158.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 163.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñá‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.44904
wandb: sub_train_loss 1.45247
wandb:       test_acc 0.432
wandb:      valid_acc 0.434
wandb: 
wandb: üöÄ View run helpful-sweep-29 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/tt7aeh3d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161451-tt7aeh3d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dpcaepwx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161507-dpcaepwx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-30
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/dpcaepwx
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 174.22it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 177.43it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 179.62it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 179.46it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 175.81it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 180.03it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:00, 182.66it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 185.52it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:00<00:00, 187.32it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 189.41it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 189.12it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 189.46it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 190.11it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 190.18it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 188.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 185.55it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.53656
wandb: sub_train_loss 1.13068
wandb:       test_acc 0.431
wandb:      valid_acc 0.45
wandb: 
wandb: üöÄ View run sage-sweep-30 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/dpcaepwx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161507-dpcaepwx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: p2ciws9t with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161523-p2ciws9t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-31
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/p2ciws9t
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 154.77it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 154.74it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 153.88it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 153.74it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 153.44it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 152.94it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 151.38it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 150.33it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 148.42it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:00, 143.54it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 137.64it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 137.17it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 133.22it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 130.35it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 130.30it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 130.41it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 129.84it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 130.43it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 130.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 132.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 139.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÅ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñá‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.44018
wandb: sub_train_loss 1.46966
wandb:       test_acc 0.246
wandb:      valid_acc 0.262
wandb: 
wandb: üöÄ View run hearty-sweep-31 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/p2ciws9t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161523-p2ciws9t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5jyu8vda with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161538-5jyu8vda
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-32
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5jyu8vda
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 151.69it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 153.75it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 151.81it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 153.07it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 154.21it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 154.83it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 154.08it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 153.36it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 153.29it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 152.33it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 152.20it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 152.62it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 152.44it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 153.35it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 151.04it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 146.02it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 143.23it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 140.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 149.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.43612
wandb: sub_train_loss 1.47163
wandb:       test_acc 0.296
wandb:      valid_acc 0.274
wandb: 
wandb: üöÄ View run deft-sweep-32 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5jyu8vda
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161538-5jyu8vda/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lbuizj7h with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161554-lbuizj7h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-33
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/lbuizj7h
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 132.28it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 140.80it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 140.69it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 131.78it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 138.61it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 143.54it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 148.51it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 152.45it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:01, 154.64it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:00, 155.74it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 156.13it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 156.15it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 156.13it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 155.96it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 155.58it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 155.43it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 155.26it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 153.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 151.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 150.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.42762
wandb: sub_train_loss 1.49675
wandb:       test_acc 0.368
wandb:      valid_acc 0.386
wandb: 
wandb: üöÄ View run gallant-sweep-33 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/lbuizj7h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161554-lbuizj7h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xhukd5bs with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161609-xhukd5bs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-34
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/xhukd5bs
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 154.45it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 150.66it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 144.62it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 146.76it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 145.23it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 142.70it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 144.96it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 145.04it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:01, 142.15it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:00, 146.01it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 149.33it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 148.28it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 144.94it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 143.00it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 144.62it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 148.62it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 151.11it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 152.81it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 151.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 147.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.44682
wandb: sub_train_loss 1.48264
wandb:       test_acc 0.395
wandb:      valid_acc 0.402
wandb: 
wandb: üöÄ View run pious-sweep-34 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/xhukd5bs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161609-xhukd5bs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6rfny4s7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161623-6rfny4s7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-35
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/6rfny4s7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 133.81it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 143.82it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 147.17it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 124.11it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 126.77it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 134.63it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 139.69it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 147.06it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:01, 153.01it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:00, 154.84it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 155.78it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 155.73it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 155.05it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 152.72it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 149.94it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 149.71it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 148.03it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 146.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 146.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 146.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.35894
wandb: sub_train_loss 1.58447
wandb:       test_acc 0.487
wandb:      valid_acc 0.526
wandb: 
wandb: üöÄ View run tough-sweep-35 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/6rfny4s7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161623-6rfny4s7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7bogwe97 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161639-7bogwe97
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-36
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/7bogwe97
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 128.92it/s]  9%|‚ñâ         | 27/300 [00:00<00:02, 129.88it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 124.77it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 124.72it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 123.34it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 133.53it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 140.73it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 137.73it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 140.84it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 143.42it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:00, 146.41it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 148.13it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 147.88it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 143.74it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 144.32it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 143.76it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 144.68it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 144.48it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 142.57it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 142.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 140.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.017 MB of 0.023 MB uploadedwandb: - 0.017 MB of 0.023 MB uploadedwandb: \ 0.017 MB of 0.023 MB uploadedwandb: | 0.017 MB of 0.023 MB uploadedwandb: / 0.017 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.37814
wandb: sub_train_loss 1.47667
wandb:       test_acc 0.573
wandb:      valid_acc 0.602
wandb: 
wandb: üöÄ View run sweet-sweep-36 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/7bogwe97
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161639-7bogwe97/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6i29154y with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161659-6i29154y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-37
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/6i29154y
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 117.71it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 139.32it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:01, 141.92it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 142.57it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 137.98it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 139.98it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 141.17it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 142.41it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 143.47it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 146.73it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 146.90it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 148.14it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 146.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 143.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.55133
wandb: sub_train_loss 1.207
wandb:       test_acc 0.579
wandb:      valid_acc 0.6
wandb: 
wandb: üöÄ View run vocal-sweep-37 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/6i29154y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161659-6i29154y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7sk9k1ih with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161715-7sk9k1ih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-38
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/7sk9k1ih
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.88it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 148.42it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 146.08it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 147.91it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 146.92it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 150.95it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 154.06it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 156.56it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 154.62it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 148.14it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 144.19it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 141.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 147.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.61411
wandb: sub_train_loss 0.99879
wandb:       test_acc 0.619
wandb:      valid_acc 0.65
wandb: 
wandb: üöÄ View run hopeful-sweep-38 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/7sk9k1ih
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161715-7sk9k1ih/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 35xm3qfq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161730-35xm3qfq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-39
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/35xm3qfq
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 159.92it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 154.82it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 152.71it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 152.30it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 151.92it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 148.85it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 148.69it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 150.95it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 150.38it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 149.43it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 148.84it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 148.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 150.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.40362
wandb: sub_train_loss 1.48943
wandb:       test_acc 0.323
wandb:      valid_acc 0.346
wandb: 
wandb: üöÄ View run avid-sweep-39 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/35xm3qfq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161730-35xm3qfq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bv48ipfm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161745-bv48ipfm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-40
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/bv48ipfm
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 153.31it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 157.50it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 158.10it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 157.43it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 157.25it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 154.97it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 152.65it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 150.77it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 149.48it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 148.48it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 147.52it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 146.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 150.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.70532
wandb: sub_train_loss 0.84831
wandb:       test_acc 0.71
wandb:      valid_acc 0.738
wandb: 
wandb: üöÄ View run unique-sweep-40 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/bv48ipfm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161745-bv48ipfm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mffavcu9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161801-mffavcu9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-41
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/mffavcu9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 157.80it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 157.38it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 156.90it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 157.43it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 152.94it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 155.48it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 156.21it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 157.20it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 155.97it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 156.91it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 158.00it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 158.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 156.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.54468
wandb: sub_train_loss 1.11947
wandb:       test_acc 0.541
wandb:      valid_acc 0.538
wandb: 
wandb: üöÄ View run helpful-sweep-41 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/mffavcu9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161801-mffavcu9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 11nytvhs with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161826-11nytvhs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-42
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/11nytvhs
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 138.90it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 145.63it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 145.68it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 145.03it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 142.49it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 140.95it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 139.70it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 138.59it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 134.69it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 135.80it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 136.29it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 139.11it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 140.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 139.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.56167
wandb: sub_train_loss 1.22532
wandb:       test_acc 0.526
wandb:      valid_acc 0.52
wandb: 
wandb: üöÄ View run restful-sweep-42 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/11nytvhs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161826-11nytvhs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: efyop40o with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161841-efyop40o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-43
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/efyop40o
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 99.96it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 108.63it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 111.79it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 113.20it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 114.45it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 115.25it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:01, 115.30it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 115.49it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 113.56it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:01<00:00, 113.42it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 112.47it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 111.18it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 110.74it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 110.56it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 110.33it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 111.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 112.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñá
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÉ‚ñÅ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.32422
wandb: sub_train_loss 1.79251
wandb:       test_acc 0.237
wandb:      valid_acc 0.264
wandb: 
wandb: üöÄ View run valiant-sweep-43 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/efyop40o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161841-efyop40o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 11n66ifg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161857-11n66ifg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-44
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/11n66ifg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 120.09it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 113.65it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 115.37it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 115.97it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:01, 115.08it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:01, 113.41it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:01, 113.95it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 113.60it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 113.61it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:01<00:00, 113.95it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:01<00:00, 114.40it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 114.88it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 115.15it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 115.49it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 115.78it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 116.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 115.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.45532
wandb: sub_train_loss 1.28385
wandb:       test_acc 0.392
wandb:      valid_acc 0.394
wandb: 
wandb: üöÄ View run dulcet-sweep-44 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/11n66ifg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161857-11n66ifg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: i4zdy7ee with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161912-i4zdy7ee
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-45
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/i4zdy7ee
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 121.79it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 122.56it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 118.13it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 115.37it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 113.93it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:01, 113.93it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 113.71it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 113.29it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 113.37it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:01<00:00, 113.40it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 111.62it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 110.42it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 111.27it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 111.78it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 111.91it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 111.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 113.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.42245
wandb: sub_train_loss 1.45167
wandb:       test_acc 0.404
wandb:      valid_acc 0.394
wandb: 
wandb: üöÄ View run celestial-sweep-45 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/i4zdy7ee
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161912-i4zdy7ee/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ah4lyv79 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161933-ah4lyv79
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-46
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ah4lyv79
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 121.95it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 123.05it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 123.24it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 122.50it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 122.80it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 122.88it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 123.39it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 123.60it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 122.71it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 123.35it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 123.03it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 122.46it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 122.04it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 122.17it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 121.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 122.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31019
wandb: sub_train_loss 1.65214
wandb:       test_acc 0.225
wandb:      valid_acc 0.228
wandb: 
wandb: üöÄ View run olive-sweep-46 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ah4lyv79
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161933-ah4lyv79/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hhjm5kl1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_161948-hhjm5kl1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-47
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/hhjm5kl1
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 115.98it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 115.76it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 111.05it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 111.00it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 111.54it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 114.25it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 115.74it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 113.97it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 112.20it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 111.25it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 107.59it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 106.93it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 107.04it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 108.12it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 110.17it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 114.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 112.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÇ‚ñÇ‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñÉ‚ñÇ‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.51809
wandb: sub_train_loss 1.32938
wandb:       test_acc 0.563
wandb:      valid_acc 0.578
wandb: 
wandb: üöÄ View run fearless-sweep-47 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/hhjm5kl1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_161948-hhjm5kl1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pffat9p3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162003-pffat9p3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-48
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/pffat9p3
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 112.48it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 111.59it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 110.36it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 107.22it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:01, 112.06it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:01, 113.81it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:01, 112.75it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 111.80it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 108.95it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 108.94it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 109.15it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 108.17it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 107.90it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 108.65it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 108.47it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 109.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 109.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 109.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñà
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.44904
wandb: sub_train_loss 1.31795
wandb:       test_acc 0.506
wandb:      valid_acc 0.518
wandb: 
wandb: üöÄ View run true-sweep-48 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/pffat9p3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162003-pffat9p3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fqfiaen0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162014-fqfiaen0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-49
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/fqfiaen0
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 99.99it/s] 10%|‚ñà         | 21/200 [00:00<00:01, 101.79it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 102.31it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:01, 103.25it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 103.86it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 104.00it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 104.12it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:01, 104.04it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 103.20it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:01<00:00, 102.29it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 102.11it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 101.29it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 101.36it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 102.60it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 102.94it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 101.59it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 100.25it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 100.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 102.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.17762
wandb: sub_train_loss 1.76861
wandb:       test_acc 0.148
wandb:      valid_acc 0.176
wandb: 
wandb: üöÄ View run laced-sweep-49 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/fqfiaen0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162014-fqfiaen0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: j5nitmd5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162029-j5nitmd5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-50
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/j5nitmd5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 93.32it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 91.20it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 90.39it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 90.78it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 90.94it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 91.50it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 90.61it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 90.97it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:01, 93.94it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:01<00:01, 96.47it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:01<00:00, 97.82it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:01<00:00, 98.43it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:01<00:00, 98.67it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 99.64it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 99.84it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 100.20it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 100.58it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 100.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:02<00:00, 98.81it/s] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 96.30it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñá‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÜ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.34749
wandb: sub_train_loss 1.91626
wandb:       test_acc 0.298
wandb:      valid_acc 0.326
wandb: 
wandb: üöÄ View run scarlet-sweep-50 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/j5nitmd5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162029-j5nitmd5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: b0hxwnhr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162044-b0hxwnhr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-51
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/b0hxwnhr
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 91.35it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 92.93it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 93.10it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 93.23it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 93.22it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 93.99it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 93.91it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 93.05it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 93.01it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 93.33it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 92.29it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 92.66it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 92.76it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 92.13it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 92.40it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 91.41it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 92.69it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 93.18it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:02<00:00, 95.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 93.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÉ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÉ‚ñà
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÉ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.34047
wandb: sub_train_loss 2.26749
wandb:       test_acc 0.299
wandb:      valid_acc 0.308
wandb: 
wandb: üöÄ View run sweet-sweep-51 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/b0hxwnhr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162044-b0hxwnhr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: q7sm9s4v with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162055-q7sm9s4v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-52
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/q7sm9s4v
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 103.00it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 104.45it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 104.99it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 105.07it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 104.31it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 104.15it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 103.03it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:01, 103.40it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 103.55it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 103.89it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 103.37it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 102.64it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 103.25it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 103.44it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 103.15it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 103.00it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 100.79it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 101.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 102.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÑ
wandb: sub_train_loss ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñà
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.4062
wandb: sub_train_loss 2.09351
wandb:       test_acc 0.389
wandb:      valid_acc 0.39
wandb: 
wandb: üöÄ View run jolly-sweep-52 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/q7sm9s4v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162055-q7sm9s4v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ws4j7blc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162111-ws4j7blc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-53
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ws4j7blc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 97.60it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 96.38it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 94.37it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 92.33it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 93.20it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 93.60it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 93.31it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 93.27it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 92.06it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 92.96it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 92.75it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 91.96it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 91.80it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 91.44it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 89.19it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 90.24it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 91.50it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 92.06it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:02<00:00, 92.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 92.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 92.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.80609
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run morning-sweep-53 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ws4j7blc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162111-ws4j7blc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ouhrpsun with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162126-ouhrpsun
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-54
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ouhrpsun
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 96.83it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 94.68it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 93.15it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 93.17it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 94.18it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 94.46it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 95.22it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 95.95it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 95.73it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 94.16it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 94.00it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 94.81it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 94.52it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 96.37it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 95.00it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 92.32it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 90.62it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 90.28it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:02<00:00, 89.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 88.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 92.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.49705
wandb: sub_train_loss 1.443
wandb:       test_acc 0.501
wandb:      valid_acc 0.488
wandb: 
wandb: üöÄ View run leafy-sweep-54 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ouhrpsun
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162126-ouhrpsun/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wrednkx5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162141-wrednkx5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-55
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/wrednkx5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 152.56it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 155.24it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 156.73it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 156.77it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 156.76it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 156.59it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 155.41it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 152.61it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 147.56it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:00, 145.15it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 144.06it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 143.18it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 143.43it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 143.39it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 142.27it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 141.51it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 141.84it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 143.19it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 144.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 147.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.5469
wandb: sub_train_loss 1.19191
wandb:       test_acc 0.492
wandb:      valid_acc 0.502
wandb: 
wandb: üöÄ View run helpful-sweep-55 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/wrednkx5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162141-wrednkx5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: wkubih60 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162202-wkubih60
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-56
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/wkubih60
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 143.35it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 150.69it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 156.20it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 157.09it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 158.37it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 157.68it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 158.89it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:01, 159.65it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 159.25it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:00, 156.56it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 153.74it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 152.60it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 151.45it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 150.11it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 149.44it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 148.90it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 148.22it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 145.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 151.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.63552
wandb: sub_train_loss 0.98983
wandb:       test_acc 0.641
wandb:      valid_acc 0.666
wandb: 
wandb: üöÄ View run upbeat-sweep-56 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/wkubih60
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162202-wkubih60/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uugpikba with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162216-uugpikba
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-57
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/uugpikba
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 148.40it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 144.65it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 144.19it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 143.56it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 143.98it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 141.50it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 142.64it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 142.02it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 141.92it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 141.16it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 141.21it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 140.28it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 140.31it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 140.24it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 137.95it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 137.40it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 137.22it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 136.12it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:02<00:00, 136.57it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 136.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 139.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.66137
wandb: sub_train_loss 1.00939
wandb:       test_acc 0.636
wandb:      valid_acc 0.618
wandb: 
wandb: üöÄ View run hardy-sweep-57 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/uugpikba
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162216-uugpikba/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nefel3i1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162228-nefel3i1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-58
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/nefel3i1
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 140.76it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 142.36it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 143.24it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 146.26it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 148.29it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 150.46it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 151.38it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 152.55it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:01, 152.24it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:00, 152.66it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 152.71it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 152.70it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 152.00it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 152.49it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 154.86it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 156.47it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 157.97it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 157.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 152.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.60044
wandb: sub_train_loss 1.16394
wandb:       test_acc 0.583
wandb:      valid_acc 0.61
wandb: 
wandb: üöÄ View run grateful-sweep-58 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/nefel3i1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162228-nefel3i1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wwntn7ed with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162245-wwntn7ed
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-59
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/wwntn7ed
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 155.65it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 155.21it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 155.56it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 157.20it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 157.59it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 158.56it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 156.69it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:01, 156.55it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 156.75it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:00, 153.50it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 149.47it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 146.68it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 144.54it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:01<00:00, 145.25it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 144.64it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 142.83it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 142.57it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 142.79it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 143.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 149.08it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.014 MB uploadedwandb: | 0.013 MB of 0.014 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.68316
wandb: sub_train_loss 0.89892
wandb:       test_acc 0.687
wandb:      valid_acc 0.686
wandb: 
wandb: üöÄ View run crisp-sweep-59 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/wwntn7ed
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162245-wwntn7ed/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2djbt202 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162300-2djbt202
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-60
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/2djbt202
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 157.56it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 157.56it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 157.92it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 155.87it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 155.66it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 157.45it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 158.62it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:01, 159.81it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:00, 159.43it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:00, 159.08it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 156.51it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 154.74it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 155.56it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 153.11it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 151.88it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 151.17it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 150.57it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 150.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 154.60it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.75074
wandb: sub_train_loss 0.86721
wandb:       test_acc 0.767
wandb:      valid_acc 0.748
wandb: 
wandb: üöÄ View run summer-sweep-60 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/2djbt202
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162300-2djbt202/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: oa59fhfa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162312-oa59fhfa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-61
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/oa59fhfa
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 125.39it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 124.13it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 123.38it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 124.21it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 125.95it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 126.89it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 127.39it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 127.52it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 126.19it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 126.42it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 127.01it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 126.81it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 126.65it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 126.40it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 126.25it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 125.28it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 125.07it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 123.29it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 123.01it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 122.96it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 121.34it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 120.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 119.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 124.16it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.56019
wandb: sub_train_loss 1.27432
wandb:       test_acc 0.589
wandb:      valid_acc 0.632
wandb: 
wandb: üöÄ View run fallen-sweep-61 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/oa59fhfa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162312-oa59fhfa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: t2qdhg8u with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162326-t2qdhg8u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-62
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/t2qdhg8u
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 123.57it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 121.10it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 120.52it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 119.56it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 119.54it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 119.98it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 119.69it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 119.64it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 118.70it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:01<00:01, 119.39it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 119.25it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 119.04it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 118.48it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:01, 117.00it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 117.23it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 118.23it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 118.39it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 119.07it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 119.12it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:02<00:00, 120.93it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 120.94it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 119.50it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:02<00:00, 118.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 119.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 119.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñá‚ñà‚ñÖ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÖ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÉ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.38516
wandb: sub_train_loss 1.57839
wandb:       test_acc 0.309
wandb:      valid_acc 0.312
wandb: 
wandb: üöÄ View run peach-sweep-62 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/t2qdhg8u
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162326-t2qdhg8u/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ljdcts3o with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162341-ljdcts3o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-63
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ljdcts3o
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 123.85it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 126.07it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 127.04it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 127.81it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 127.83it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 127.61it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 127.80it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 128.07it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 128.60it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 128.35it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 127.16it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 126.87it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 127.06it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 126.92it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 127.20it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 127.16it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 127.31it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 127.23it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 127.21it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 126.99it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 126.24it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 125.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 125.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 126.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñà‚ñà‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÇ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñá‚ñà‚ñÖ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÇ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.33789
wandb: sub_train_loss 1.89414
wandb:       test_acc 0.303
wandb:      valid_acc 0.32
wandb: 
wandb: üöÄ View run swept-sweep-63 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ljdcts3o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162341-ljdcts3o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jvuq6kgg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162357-jvuq6kgg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-64
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/jvuq6kgg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 120.27it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 123.19it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 124.83it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 125.50it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 125.32it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 125.21it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 123.46it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 119.54it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 118.91it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:01<00:01, 118.37it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 118.58it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 116.82it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 114.20it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:01, 113.40it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 115.87it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 118.05it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 117.76it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 118.87it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 120.59it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 120.58it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 117.00it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 116.17it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:02<00:00, 118.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 119.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÑ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÑ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.49742
wandb: sub_train_loss 1.26903
wandb:       test_acc 0.442
wandb:      valid_acc 0.434
wandb: 
wandb: üöÄ View run classic-sweep-64 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/jvuq6kgg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162357-jvuq6kgg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0eutuuv5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162412-0eutuuv5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-65
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0eutuuv5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 123.42it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 123.11it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 123.71it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 124.42it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 124.81it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 125.32it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 123.95it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 117.97it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 114.82it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:01<00:01, 111.99it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 109.95it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 110.55it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 111.86it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:01, 112.08it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 113.31it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 114.01it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 114.00it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 114.23it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:02<00:00, 114.87it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:02<00:00, 112.30it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 110.32it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 109.57it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 113.72it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 113.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 115.11it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÉ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.51699
wandb: sub_train_loss 1.28173
wandb:       test_acc 0.506
wandb:      valid_acc 0.522
wandb: 
wandb: üöÄ View run lunar-sweep-65 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0eutuuv5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162412-0eutuuv5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: aviquqfu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162428-aviquqfu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-66
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/aviquqfu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 124.16it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 124.23it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 125.27it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 125.96it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 126.35it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 126.75it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 126.45it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 126.20it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 125.40it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 125.54it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 125.70it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 124.72it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 124.11it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 124.05it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 123.77it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 123.57it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 123.35it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 123.42it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 122.87it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 122.99it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 123.30it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 122.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 123.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 124.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ
wandb: sub_train_loss ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.28693
wandb: sub_train_loss 1.66955
wandb:       test_acc 0.235
wandb:      valid_acc 0.246
wandb: 
wandb: üöÄ View run electric-sweep-66 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/aviquqfu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162428-aviquqfu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4s7s9sc0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162442-4s7s9sc0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-67
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/4s7s9sc0
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 96.77it/s]  7%|‚ñã         | 21/300 [00:00<00:02, 101.29it/s] 11%|‚ñà         | 32/300 [00:00<00:02, 102.61it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:02, 103.61it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:02, 104.28it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:02, 102.12it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:02, 95.83it/s]  29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:02, 94.73it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:02, 94.48it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:01<00:02, 94.79it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:01<00:01, 94.69it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:01<00:01, 94.58it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:01<00:01, 94.66it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 94.76it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 94.06it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 94.21it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:01, 94.50it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:01, 93.86it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:02<00:01, 92.75it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:02<00:01, 90.92it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:02<00:00, 90.25it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:02<00:00, 90.66it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:02<00:00, 91.00it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:02<00:00, 91.05it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 90.74it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 93.01it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 94.02it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:03<00:00, 95.29it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:03<00:00, 95.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 94.78it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ
wandb: sub_train_loss ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÑ‚ñÖ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÑ‚ñÉ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñÑ‚ñÉ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.14402
wandb: sub_train_loss 1.94775
wandb:       test_acc 0.118
wandb:      valid_acc 0.106
wandb: 
wandb: üöÄ View run pleasant-sweep-67 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/4s7s9sc0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162442-4s7s9sc0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0szx711y with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162457-0szx711y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-68
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0szx711y
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 92.99it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 91.72it/s] 10%|‚ñà         | 30/300 [00:00<00:03, 88.36it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 87.22it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 87.12it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:02, 86.19it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:02, 85.84it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:02, 86.13it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:02, 89.12it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:01<00:02, 90.92it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:01<00:02, 92.84it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:01<00:01, 93.72it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:01<00:01, 95.25it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:01<00:01, 95.43it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 93.48it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 94.05it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 92.27it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:01, 91.98it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:02<00:01, 92.77it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:02<00:01, 93.86it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:02<00:01, 94.54it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:02<00:00, 92.26it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:02<00:00, 90.81it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:02<00:00, 90.61it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:02<00:00, 92.77it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:02<00:00, 91.94it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 93.65it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:03<00:00, 91.80it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:03<00:00, 94.08it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:03<00:00, 96.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 92.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÜ‚ñà‚ñÉ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÉ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñá‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.2921
wandb: sub_train_loss 1.73828
wandb:       test_acc 0.273
wandb:      valid_acc 0.29
wandb: 
wandb: üöÄ View run solar-sweep-68 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0szx711y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162457-0szx711y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pg52t36e with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162513-pg52t36e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-69
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/pg52t36e
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 94.99it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 92.61it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 94.75it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 94.38it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 95.47it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 96.61it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 96.77it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 96.58it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 97.30it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 96.96it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:02, 94.47it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 91.63it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 89.35it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 88.15it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 87.17it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 87.11it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 87.27it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:01, 87.06it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:02<00:01, 87.19it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:02<00:01, 85.68it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:02<00:01, 84.65it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:02<00:01, 84.51it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:02<00:00, 84.31it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:02<00:00, 83.64it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:02<00:00, 83.82it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:02<00:00, 83.84it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 83.17it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 83.34it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:03<00:00, 83.57it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:03<00:00, 83.16it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:03<00:00, 83.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 88.10it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñÜ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.17061
wandb: sub_train_loss 2.02375
wandb:       test_acc 0.145
wandb:      valid_acc 0.156
wandb: 
wandb: üöÄ View run vibrant-sweep-69 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/pg52t36e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162513-pg52t36e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vfje7cl8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162528-vfje7cl8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-70
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/vfje7cl8
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 102.08it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 92.88it/s]  11%|‚ñà         | 32/300 [00:00<00:02, 95.10it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:02, 96.30it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 97.09it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:02, 99.06it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:02, 101.49it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:02, 102.73it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 103.33it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:01<00:01, 103.42it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:01<00:01, 102.66it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:01, 97.93it/s]  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 95.73it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 94.92it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 94.57it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 94.40it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:01, 94.74it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:01, 96.05it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:02<00:01, 97.00it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:02<00:00, 96.56it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:02<00:00, 95.78it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:02<00:00, 98.55it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:02<00:00, 100.72it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 102.04it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 102.80it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 102.29it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 101.80it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:03<00:00, 98.34it/s] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 98.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñá
wandb: sub_train_loss ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñá‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñá
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÖ‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.39623
wandb: sub_train_loss 1.84108
wandb:       test_acc 0.397
wandb:      valid_acc 0.442
wandb: 
wandb: üöÄ View run sleek-sweep-70 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/vfje7cl8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162528-vfje7cl8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0wbthhmg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162544-0wbthhmg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-71
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0wbthhmg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 101.70it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 101.88it/s] 11%|‚ñà         | 33/300 [00:00<00:02, 102.53it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:02, 102.89it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:02, 103.30it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:02, 102.98it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:02, 102.89it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:02, 102.31it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 102.92it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:01, 103.50it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:01<00:01, 103.04it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 100.35it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 98.43it/s]  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 97.55it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 95.81it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:01, 95.86it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:01, 96.30it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:01, 93.91it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:02<00:01, 93.01it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:02<00:00, 93.12it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:02<00:00, 94.07it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:02<00:00, 94.39it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:02<00:00, 94.90it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 95.30it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 95.66it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 95.34it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 93.77it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 95.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 97.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.4339
wandb: sub_train_loss 1.49371
wandb:       test_acc 0.429
wandb:      valid_acc 0.424
wandb: 
wandb: üöÄ View run vague-sweep-71 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0wbthhmg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162544-0wbthhmg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: i5tcdjsp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162559-i5tcdjsp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-72
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/i5tcdjsp
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 100.90it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 103.42it/s] 11%|‚ñà         | 33/300 [00:00<00:02, 105.02it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:02, 105.78it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:02, 105.44it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:02, 105.69it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:02, 105.46it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:02, 104.18it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 102.90it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:01, 102.33it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:01<00:01, 99.58it/s]  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 99.22it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 100.08it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 100.77it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 101.11it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:01, 101.01it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:01, 101.34it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:01, 102.25it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:02<00:00, 101.95it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:02<00:00, 100.53it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:02<00:00, 100.54it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:02<00:00, 99.93it/s]  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:02<00:00, 99.62it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 98.84it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:02<00:00, 98.97it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 99.47it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 99.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 101.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.17541
wandb: sub_train_loss 1.82503
wandb:       test_acc 0.207
wandb:      valid_acc 0.22
wandb: 
wandb: üöÄ View run devoted-sweep-72 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/i5tcdjsp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162559-i5tcdjsp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: seydzp07 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162616-seydzp07
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-73
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/seydzp07
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 214.95it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:00, 225.30it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 226.51it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 224.79it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 220.17it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 219.34it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 222.10it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:00<00:00, 222.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 222.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.17688
wandb: sub_train_loss 1.91307
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run generous-sweep-73 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/seydzp07
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162616-seydzp07/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: cp7f2k1v with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162637-cp7f2k1v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-74
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/cp7f2k1v
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:00, 231.43it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 228.68it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 226.17it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 227.32it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 228.09it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 228.36it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 228.19it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:00<00:00, 228.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 228.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.2452
wandb: sub_train_loss 1.90169
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run bumbling-sweep-74 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/cp7f2k1v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162637-cp7f2k1v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: f1nor29l with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162650-f1nor29l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-75
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/f1nor29l
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:00, 237.14it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 239.09it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 238.27it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 233.12it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 233.29it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 234.53it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 236.14it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:00<00:00, 232.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 234.71it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.34527
wandb: sub_train_loss 1.89796
wandb:       test_acc 0.439
wandb:      valid_acc 0.426
wandb: 
wandb: üöÄ View run sleek-sweep-75 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/f1nor29l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162650-f1nor29l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qxh6d0tm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162702-qxh6d0tm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-76
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/qxh6d0tm
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 216.41it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:00, 226.09it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 231.32it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 235.26it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 236.23it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 237.63it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:00<00:00, 238.75it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:00<00:00, 239.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 236.11it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.88761
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run cerulean-sweep-76 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/qxh6d0tm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162702-qxh6d0tm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9s2rs4r8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162716-9s2rs4r8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-77
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/9s2rs4r8
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 219.22it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:00, 229.88it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 230.01it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 218.27it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 211.67it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 207.03it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:00<00:00, 206.78it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 207.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 207.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 211.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.88353
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run leafy-sweep-77 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/9s2rs4r8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162716-9s2rs4r8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: w2p1vmsm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162737-w2p1vmsm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-78
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/w2p1vmsm
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 220.97it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:00, 216.80it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 214.38it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 212.08it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 209.73it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 211.12it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:00<00:00, 213.06it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:00<00:00, 212.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 213.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.85184
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run dainty-sweep-78 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/w2p1vmsm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162737-w2p1vmsm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: embzx6nc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162751-embzx6nc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-79
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/embzx6nc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 183.21it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 189.52it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:00, 191.07it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 189.24it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 188.24it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 188.13it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 187.97it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 186.78it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:00<00:00, 186.76it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 186.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 187.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.86755
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run good-sweep-79 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/embzx6nc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162751-embzx6nc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 02k0g0z9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162802-02k0g0z9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-80
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/02k0g0z9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 174.48it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 176.99it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 178.09it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 176.37it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 173.74it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 175.01it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 178.41it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 176.18it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 174.19it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 174.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 176.88it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.15731
wandb: sub_train_loss 1.92726
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run peach-sweep-80 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/02k0g0z9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162802-02k0g0z9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ske6ocds with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162823-ske6ocds
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-81
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ske6ocds
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 192.16it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 195.36it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 196.30it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 195.72it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 195.39it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 195.32it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 195.30it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 172.14it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:00<00:00, 167.69it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 165.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 179.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.8862
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run glorious-sweep-81 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ske6ocds
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162823-ske6ocds/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: h59u0803 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162838-h59u0803
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-82
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/h59u0803
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 182.04it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 182.24it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 178.94it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 178.54it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 180.15it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 177.99it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 176.29it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 172.05it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 167.30it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 171.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 174.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.86968
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run royal-sweep-82 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/h59u0803
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162838-h59u0803/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rev6pry4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162854-rev6pry4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-83
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/rev6pry4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 176.25it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 177.41it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 173.55it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 171.85it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 169.35it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 167.92it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 167.39it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 168.75it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 173.61it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 178.04it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 168.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 169.98it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.85936
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run divine-sweep-83 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/rev6pry4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162854-rev6pry4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: t0ipkuok with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162908-t0ipkuok
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-84
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/t0ipkuok
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 154.36it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 162.47it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 169.21it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 173.28it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 174.59it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 170.75it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 171.56it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 171.05it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 170.80it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 173.20it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 175.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 172.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.86687
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run zany-sweep-84 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/t0ipkuok
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162908-t0ipkuok/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 99qisykt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162929-99qisykt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-85
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/99qisykt
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 161.24it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 161.98it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 160.44it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 160.20it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 159.55it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 159.17it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 160.91it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 160.15it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 159.40it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 157.49it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 153.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 151.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 157.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31499
wandb: sub_train_loss 1.9244
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run splendid-sweep-85 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/99qisykt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162929-99qisykt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5ne2yduc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_162952-5ne2yduc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-86
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5ne2yduc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 159.77it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 160.04it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 157.32it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 156.97it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 158.41it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 157.37it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 157.71it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 156.50it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 155.91it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 154.77it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 154.69it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 152.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 155.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.87774
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run wise-sweep-86 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5ne2yduc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_162952-5ne2yduc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zx90u625 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163003-zx90u625
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-87
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/zx90u625
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 150.91it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 141.48it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 135.83it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:01, 133.07it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 131.72it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 132.53it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 133.39it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 133.42it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 137.38it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 141.77it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 144.80it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 144.66it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 144.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 139.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.15953
wandb: sub_train_loss 1.9286
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run splendid-sweep-87 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/zx90u625
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163003-zx90u625/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6kkxfmfz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163019-6kkxfmfz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-88
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/6kkxfmfz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 142.67it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 143.67it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 141.96it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 138.03it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 142.67it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 148.23it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 149.94it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 151.98it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 151.85it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 151.86it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 154.23it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 155.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 150.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31093
wandb: sub_train_loss 1.87108
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run lemon-sweep-88 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/6kkxfmfz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163019-6kkxfmfz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5zpgbkcp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163033-5zpgbkcp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-89
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5zpgbkcp
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.03it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 145.26it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 149.06it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 150.35it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 149.59it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 148.70it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 148.46it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 149.18it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:00<00:00, 149.78it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 147.22it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 145.13it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 143.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 140.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 145.86it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30391
wandb: sub_train_loss 1.85133
wandb:       test_acc 0.231
wandb:      valid_acc 0.224
wandb: 
wandb: üöÄ View run autumn-sweep-89 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5zpgbkcp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163033-5zpgbkcp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dkfeu6vk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163045-dkfeu6vk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-90
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/dkfeu6vk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 138.79it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 146.40it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 149.56it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 151.83it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 152.36it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 149.25it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 150.47it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 148.81it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 148.95it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 151.50it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 149.93it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 149.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 149.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.83019
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run restful-sweep-90 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/dkfeu6vk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163045-dkfeu6vk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rdavtews with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163100-rdavtews
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-91
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/rdavtews
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 237.31it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 239.54it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:00, 237.86it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:00, 237.52it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 238.21it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 239.00it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:00<00:00, 234.55it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:00<00:00, 235.19it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:00<00:00, 236.32it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 234.92it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 235.38it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 235.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 236.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.25775
wandb: sub_train_loss 1.90502
wandb:       test_acc 0.435
wandb:      valid_acc 0.42
wandb: 
wandb: üöÄ View run giddy-sweep-91 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/rdavtews
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163100-rdavtews/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zg90kl9d with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163114-zg90kl9d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-92
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/zg90kl9d
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 25/300 [00:00<00:01, 245.44it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 237.56it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:00, 235.26it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:00, 232.22it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:00, 228.12it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 228.91it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:00<00:00, 228.80it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:00<00:00, 227.93it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:00<00:00, 227.76it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 223.70it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 222.59it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 223.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 227.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.32164
wandb: sub_train_loss 1.83805
wandb:       test_acc 0.421
wandb:      valid_acc 0.402
wandb: 
wandb: üöÄ View run brisk-sweep-92 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/zg90kl9d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163114-zg90kl9d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lvbxodo4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163126-lvbxodo4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-93
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/lvbxodo4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 223.27it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 220.41it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 220.53it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:00, 220.46it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:00, 225.06it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 228.59it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:00<00:00, 230.71it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:00<00:00, 227.02it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:00<00:00, 225.02it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 222.61it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 220.47it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 218.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 222.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñà‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñá‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.38589
wandb: sub_train_loss 1.85179
wandb:       test_acc 0.288
wandb:      valid_acc 0.272
wandb: 
wandb: üöÄ View run peachy-sweep-93 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/lvbxodo4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163126-lvbxodo4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: k71yuslu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163140-k71yuslu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-94
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/k71yuslu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 231.32it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 231.07it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:00, 231.30it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:00, 227.77it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 227.34it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 226.85it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:00<00:00, 229.03it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:00<00:00, 226.63it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:00<00:00, 225.10it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 223.06it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 221.01it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 219.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 224.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.83929
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run generous-sweep-94 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/k71yuslu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163140-k71yuslu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ptw02dhk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163156-ptw02dhk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-95
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ptw02dhk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 234.16it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 235.60it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:00, 236.65it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:00, 237.99it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:00, 238.76it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 238.16it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:00<00:00, 238.87it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:00<00:00, 237.61it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:00<00:00, 238.60it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 239.18it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 231.24it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 225.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 233.98it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31019
wandb: sub_train_loss 1.80489
wandb:       test_acc 0.326
wandb:      valid_acc 0.326
wandb: 
wandb: üöÄ View run cool-sweep-95 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ptw02dhk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163156-ptw02dhk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jlooajeg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163211-jlooajeg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-96
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/jlooajeg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 225.39it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 231.65it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:00, 232.91it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:00, 234.48it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 235.23it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 234.19it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 234.48it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:00<00:00, 230.83it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:00<00:00, 231.35it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 233.52it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 235.33it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 235.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 233.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30724
wandb: sub_train_loss 1.8353
wandb:       test_acc 0.322
wandb:      valid_acc 0.32
wandb: 
wandb: üöÄ View run glad-sweep-96 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/jlooajeg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163211-jlooajeg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: cbge33lx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163231-cbge33lx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-97
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/cbge33lx
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 177.78it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 176.73it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 181.39it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 180.18it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 177.32it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 177.02it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:00, 178.03it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:00<00:00, 178.91it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 180.23it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 181.15it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 180.55it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 179.45it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 177.83it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 174.92it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 175.12it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 175.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 177.81it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31388
wandb: sub_train_loss 1.81805
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run pious-sweep-97 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/cbge33lx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163231-cbge33lx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rw3j0r5o with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163246-rw3j0r5o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-98
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/rw3j0r5o
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 191.65it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 190.21it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 191.45it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 189.25it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 187.52it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:00, 187.06it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 188.90it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 182.58it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 178.30it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 174.66it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 177.21it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 180.54it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 181.90it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 183.76it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 183.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 183.14it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31388
wandb: sub_train_loss 1.8357
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run olive-sweep-98 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/rw3j0r5o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163246-rw3j0r5o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0ji0elyx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163258-0ji0elyx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-99
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0ji0elyx
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 162.89it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 162.11it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 157.84it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 155.53it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 154.28it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 158.98it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 163.41it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 165.48it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 162.90it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 162.71it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 159.07it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 156.49it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 156.33it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 156.64it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 161.14it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 162.89it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 163.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 160.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.33272
wandb: sub_train_loss 1.82645
wandb:       test_acc 0.355
wandb:      valid_acc 0.36
wandb: 
wandb: üöÄ View run copper-sweep-99 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0ji0elyx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163258-0ji0elyx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ocs27fsl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163312-ocs27fsl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-100
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ocs27fsl
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 167.94it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 166.33it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 171.15it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 173.70it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 177.52it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 178.99it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:00, 180.32it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 179.60it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 180.23it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 181.35it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 179.64it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 177.30it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 175.93it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 174.58it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 175.41it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 174.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 176.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30355
wandb: sub_train_loss 1.80625
wandb:       test_acc 0.321
wandb:      valid_acc 0.32
wandb: 
wandb: üöÄ View run peach-sweep-100 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ocs27fsl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163312-ocs27fsl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: s0zl7372 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163333-s0zl7372
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-101
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/s0zl7372
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 172.01it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 168.48it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 173.47it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 181.72it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 186.71it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:00, 189.65it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 191.04it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 190.66it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 191.49it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 192.51it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 193.35it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 192.22it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 190.56it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 180.23it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 178.93it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 184.88it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.82852
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run resilient-sweep-101 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/s0zl7372
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163333-s0zl7372/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dnjgkimo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163347-dnjgkimo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-102
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/dnjgkimo
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 192.61it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 191.49it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 186.35it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 185.17it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 184.24it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:00, 185.42it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:01, 142.92it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:01, 135.57it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 143.53it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 151.25it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 158.09it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 164.12it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 171.39it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 174.59it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 177.83it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 173.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 166.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.78373
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run vital-sweep-102 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/dnjgkimo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163347-dnjgkimo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0qmm8i93 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163359-0qmm8i93
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-103
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0qmm8i93
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 147.50it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 154.01it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 155.16it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 155.98it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 157.32it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 158.12it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 158.16it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 158.94it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 158.83it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 158.02it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 156.89it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 155.94it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 155.70it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 153.78it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 149.74it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 143.42it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 139.43it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 138.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 150.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31388
wandb: sub_train_loss 1.8482
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run tough-sweep-103 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0qmm8i93
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163359-0qmm8i93/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nfzrg94i with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163413-nfzrg94i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-104
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/nfzrg94i
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 138.18it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 140.11it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 137.17it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 142.54it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 145.46it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 148.02it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 152.13it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 152.66it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:01, 151.80it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:00, 151.66it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 151.12it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 150.93it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 150.55it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 150.73it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 150.93it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 151.18it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 151.23it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 153.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 150.09it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31388
wandb: sub_train_loss 1.81726
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run grateful-sweep-104 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/nfzrg94i
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163413-nfzrg94i/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xg0iso9e with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163434-xg0iso9e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-105
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/xg0iso9e
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 138.42it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 149.06it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 152.35it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 153.02it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 152.90it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 152.18it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 149.49it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 149.78it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:01, 148.61it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:00, 148.78it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 149.07it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 148.26it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 149.70it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 150.56it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 151.47it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 151.70it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 150.65it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 150.44it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 151.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 150.50it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.14845
wandb: sub_train_loss 1.87317
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run rose-sweep-105 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/xg0iso9e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163434-xg0iso9e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: j6145mmq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163446-j6145mmq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-106
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/j6145mmq
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 149.36it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 152.70it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 149.22it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 148.15it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 145.59it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 143.47it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 142.18it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 139.47it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:01, 139.57it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 138.77it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 135.83it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 136.87it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 138.35it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 140.46it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 140.88it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 140.67it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 140.66it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 135.50it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 134.31it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 137.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 140.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.34047
wandb: sub_train_loss 1.8287
wandb:       test_acc 0.189
wandb:      valid_acc 0.202
wandb: 
wandb: üöÄ View run young-sweep-106 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/j6145mmq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163446-j6145mmq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: oyieauak with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163500-oyieauak
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-107
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/oyieauak
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 142.68it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 148.27it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 145.79it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 143.69it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 146.22it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 148.24it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 150.54it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 150.81it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:01, 152.18it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:00, 153.73it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 153.36it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 152.42it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 152.49it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 152.58it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 153.45it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 154.60it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 155.36it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 155.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 151.98it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.8349
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run effortless-sweep-107 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/oyieauak
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163500-oyieauak/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ne26xw5f with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163518-ne26xw5f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-108
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ne26xw5f
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 164.32it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 163.16it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 163.30it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 163.57it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 161.13it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 157.43it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 156.08it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:01, 155.14it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 154.64it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:00, 153.57it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 152.87it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 147.81it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 143.50it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 139.48it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 137.15it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 136.21it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 134.87it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 132.04it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 133.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 146.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.83662
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run true-sweep-108 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ne26xw5f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163518-ne26xw5f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dasz6h5p with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163531-dasz6h5p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-109
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/dasz6h5p
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 158.89it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 160.53it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 161.18it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:00, 157.56it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 155.49it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 153.70it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 153.39it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 153.77it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 149.60it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 151.25it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 151.52it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 150.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 153.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.85769
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run sandy-sweep-109 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/dasz6h5p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163531-dasz6h5p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bg4ya4pr with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163543-bg4ya4pr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-110
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/bg4ya4pr
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 159.81it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 155.59it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 155.78it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 156.86it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 157.71it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 158.39it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 158.25it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 155.61it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 155.97it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 156.48it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 155.92it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 155.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 156.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.85697
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run legendary-sweep-110 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/bg4ya4pr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163543-bg4ya4pr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 07fy8f6o with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163557-07fy8f6o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-111
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/07fy8f6o
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 153.80it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 152.21it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 151.54it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 152.09it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 151.15it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 149.61it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 149.78it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 149.53it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 150.44it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 149.89it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 149.54it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 150.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 151.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.85132
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run rose-sweep-111 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/07fy8f6o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163557-07fy8f6o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0j389jic with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163613-0j389jic
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-112
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0j389jic
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 160.78it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 161.83it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 162.58it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 160.86it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 160.96it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 161.65it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 161.81it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 161.75it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 161.84it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 162.52it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 162.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 161.67it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31019
wandb: sub_train_loss 1.85
wandb:       test_acc 0.321
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run drawn-sweep-112 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0j389jic
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163613-0j389jic/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gqxqzpuy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163627-gqxqzpuy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-113
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/gqxqzpuy
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 142.47it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 150.87it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 155.65it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 159.31it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 156.73it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 152.74it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 151.07it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 150.07it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 148.71it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 146.50it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 145.63it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 144.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 148.95it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30244
wandb: sub_train_loss 1.84571
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run silver-sweep-113 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/gqxqzpuy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163627-gqxqzpuy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: btn5m689 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163643-btn5m689
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-114
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/btn5m689
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 150.11it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 149.06it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 148.51it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 148.56it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 149.04it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 148.75it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 147.97it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 147.47it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 147.82it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 149.36it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 149.96it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 148.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 146.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 148.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.014 MB uploadedwandb: - 0.013 MB of 0.014 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.85074
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run valiant-sweep-114 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/btn5m689
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163643-btn5m689/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: o3od0jgs with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163659-o3od0jgs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-115
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/o3od0jgs
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 115.31it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 116.93it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 114.64it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 114.89it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 115.71it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 116.44it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 116.77it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 116.86it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 118.12it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:01<00:00, 119.14it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 120.08it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 121.53it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 122.48it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 123.13it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 123.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 123.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 119.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.83006
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run vibrant-sweep-115 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/o3od0jgs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163659-o3od0jgs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fc0urxa0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163710-fc0urxa0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-116
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/fc0urxa0
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 119.48it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 114.99it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 115.16it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 115.21it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 115.73it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 114.58it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 115.15it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 115.47it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 114.36it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 115.31it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 116.40it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 117.08it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 117.20it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 117.09it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 117.30it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 117.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 116.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.84986
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run rose-sweep-116 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/fc0urxa0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163710-fc0urxa0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uzlty9h7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163725-uzlty9h7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-117
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/uzlty9h7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 118.24it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 120.97it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 121.33it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 119.79it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 119.59it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 120.48it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 121.43it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 122.35it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 123.17it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 122.02it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 122.19it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 122.59it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 120.83it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 119.59it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 117.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 119.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.8186
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run eternal-sweep-117 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/uzlty9h7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163725-uzlty9h7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a424p5xa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163740-a424p5xa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-118
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/a424p5xa
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 120.01it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 117.62it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 120.80it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 122.69it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 123.72it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 120.46it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 117.84it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 115.32it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 114.90it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:01<00:00, 113.76it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:01<00:00, 112.98it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 112.35it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 111.00it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 111.84it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 111.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 112.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 115.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.85244
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run rich-sweep-118 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/a424p5xa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163740-a424p5xa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6g5niqip with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163752-6g5niqip
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-119
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/6g5niqip
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 112.86it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 119.28it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:01, 115.04it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:01, 106.88it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:01, 111.53it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:01, 109.74it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:01, 108.79it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:01, 98.22it/s]  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:01<00:00, 100.45it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:01<00:00, 102.94it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 105.97it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 109.42it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 111.85it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 112.67it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 113.85it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 115.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 110.30it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.82648
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run ethereal-sweep-119 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/6g5niqip
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163752-6g5niqip/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: g146ax1d with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163806-g146ax1d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-120
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/g146ax1d
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 116.13it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 115.45it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:01, 119.25it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:01, 108.92it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:01, 111.50it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:01, 115.93it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 118.28it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 120.40it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 115.61it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:01<00:00, 117.46it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 117.72it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 117.92it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 119.35it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 120.11it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 121.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 118.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.82139
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run robust-sweep-120 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/g146ax1d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163806-g146ax1d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6sp81unw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163822-6sp81unw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-121
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/6sp81unw
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 101.57it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 101.89it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 100.83it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 96.18it/s]  27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 97.41it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 97.04it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:01, 90.61it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 85.16it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:01<00:01, 81.80it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:01<00:01, 79.09it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:01, 76.68it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:01<00:01, 77.33it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 83.02it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 87.60it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 91.60it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 92.90it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 94.11it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 95.18it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:02<00:00, 96.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:02<00:00, 93.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 90.08it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.85162
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run spring-sweep-121 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/6sp81unw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163822-6sp81unw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: k6yyu7df with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163837-k6yyu7df
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-122
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/k6yyu7df
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 97.11it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 94.52it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 94.44it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 94.40it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 94.14it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 94.07it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:01, 96.98it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:01, 98.87it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:01, 98.23it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:01<00:00, 98.62it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:01<00:00, 98.31it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:01<00:00, 98.19it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 96.91it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 95.90it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 94.55it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 90.65it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 91.25it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 92.89it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:02<00:00, 94.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 95.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.80404
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run worldly-sweep-122 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/k6yyu7df
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163837-k6yyu7df/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hkq5ioqs with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163852-hkq5ioqs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-123
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/hkq5ioqs
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 102.49it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 103.30it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 100.23it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 98.80it/s]  27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 98.84it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 98.97it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:01, 96.19it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 95.96it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:01, 97.44it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:01<00:01, 91.61it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:01<00:00, 92.15it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:01<00:00, 93.40it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:01<00:00, 96.71it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 98.53it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 100.26it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 101.35it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 102.15it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 102.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 98.78it/s] 
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.79784
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run glamorous-sweep-123 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/hkq5ioqs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163852-hkq5ioqs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8vzqakw9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163907-8vzqakw9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-124
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/8vzqakw9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 101.85it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 102.40it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 102.74it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 101.90it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 100.64it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 99.24it/s]  38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 100.63it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:01, 100.93it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 101.78it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 101.51it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 101.63it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 98.40it/s]  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 95.95it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 94.77it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 92.84it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 92.98it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 94.10it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 94.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 96.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.83516
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run misty-sweep-124 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/8vzqakw9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163907-8vzqakw9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 915x5j9e with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163919-915x5j9e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-125
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/915x5j9e
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 94.99it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 95.06it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 93.02it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 89.42it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:01, 85.13it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 81.13it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [00:00<00:01, 80.30it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 83.60it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:01<00:01, 86.29it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:01<00:01, 86.84it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:01<00:01, 88.13it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:01<00:00, 90.16it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:01<00:00, 91.47it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:01<00:00, 92.62it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 93.05it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 93.58it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 93.49it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 94.04it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:02<00:00, 95.47it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:02<00:00, 96.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 90.75it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.80395
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run confused-sweep-125 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/915x5j9e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163919-915x5j9e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: znvyh84k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163933-znvyh84k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-126
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/znvyh84k
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 99.26it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 99.50it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 101.34it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 102.32it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:01, 103.27it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 102.50it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:01, 102.91it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:01, 102.53it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:01, 100.37it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:01<00:00, 98.54it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:01<00:00, 95.83it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 92.82it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 91.99it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 91.57it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 91.85it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 92.90it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 93.69it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 94.73it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:02<00:00, 95.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 96.85it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.8159
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run balmy-sweep-126 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/znvyh84k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163933-znvyh84k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1w635fhp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_163948-1w635fhp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-127
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/1w635fhp
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 149.10it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 155.94it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 155.23it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 152.28it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 151.27it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 150.12it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 150.20it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 150.64it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 152.54it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 146.28it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 146.80it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 145.81it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 144.16it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 144.52it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 144.38it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 144.61it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 143.99it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 144.70it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:02<00:00, 144.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 147.25it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30465
wandb: sub_train_loss 1.77116
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run tough-sweep-127 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/1w635fhp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_163948-1w635fhp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9p071com with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164000-9p071com
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-128
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/9p071com
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 159.61it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 159.84it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 155.45it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 157.02it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 156.78it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 156.64it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 159.78it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:01, 161.51it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 162.79it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 161.68it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 162.27it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 162.38it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 161.83it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 161.65it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 162.36it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 156.75it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 148.56it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 147.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 156.98it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.73696
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run lunar-sweep-128 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/9p071com
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164000-9p071com/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 19tn59r8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164015-19tn59r8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-129
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/19tn59r8
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 161.10it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 159.71it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 160.01it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 155.96it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 153.50it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 151.78it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 151.29it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:01, 154.47it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:00<00:00, 157.57it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:00, 160.01it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 159.71it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 160.28it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 158.18it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 157.57it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 159.18it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 158.84it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 155.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 153.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 156.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.81901
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run elated-sweep-129 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/19tn59r8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164015-19tn59r8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 3t4xayu3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164031-3t4xayu3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-130
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/3t4xayu3
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 154.02it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 152.18it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 147.25it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 146.41it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 149.78it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 148.14it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 148.32it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 142.44it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:01, 136.62it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 136.89it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 138.26it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 137.37it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 137.84it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 141.32it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 143.24it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 144.96it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 145.89it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 146.76it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 147.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 144.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.40657
wandb: sub_train_loss 1.79611
wandb:       test_acc 0.423
wandb:      valid_acc 0.414
wandb: 
wandb: üöÄ View run leafy-sweep-130 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/3t4xayu3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164031-3t4xayu3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: n6cyuepb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164047-n6cyuepb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-131
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/n6cyuepb
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 156.46it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 155.30it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 156.04it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 155.43it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 154.99it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 151.92it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 147.60it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 145.89it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 149.90it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:00, 153.19it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 155.10it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 155.97it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 157.30it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 156.36it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 156.63it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 157.61it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 157.77it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 157.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 154.81it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30835
wandb: sub_train_loss 1.76928
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run divine-sweep-131 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/n6cyuepb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164047-n6cyuepb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: icom27qv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164103-icom27qv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-132
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/icom27qv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 149.52it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 145.48it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 145.38it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 142.05it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 142.76it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 142.86it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 142.66it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 141.91it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 143.19it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 141.33it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 141.87it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 140.65it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 141.67it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 141.85it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 142.97it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 142.84it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 143.32it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 143.83it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 143.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 143.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 142.86it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.79429
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run skilled-sweep-132 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/icom27qv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164103-icom27qv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rifrso03 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164117-rifrso03
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-133
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/rifrso03
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 107.19it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 119.04it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:02, 122.33it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 123.80it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 124.63it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 125.16it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 123.18it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 123.80it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 124.70it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:01<00:01, 125.18it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 124.38it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 121.96it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 122.53it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 122.56it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 123.05it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 123.41it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 123.83it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 123.28it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 123.19it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:02<00:00, 122.15it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:02<00:00, 122.62it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:02<00:00, 123.10it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 121.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 122.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.74723
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run wise-sweep-133 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/rifrso03
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164117-rifrso03/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: js78d936 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164129-js78d936
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-134
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/js78d936
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 115.74it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 117.28it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 115.76it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 117.32it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 115.75it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 115.58it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 116.21it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 115.60it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 117.24it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:01<00:01, 119.23it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:01<00:01, 120.39it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 121.45it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:01, 121.83it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:01, 122.64it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 123.37it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 123.91it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 123.98it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 123.89it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 123.52it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 121.51it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 112.98it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 113.34it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 115.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 118.75it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.74548
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run usual-sweep-134 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/js78d936
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164129-js78d936/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: co6dvmxz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164145-co6dvmxz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-135
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/co6dvmxz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 109.04it/s]  8%|‚ñä         | 23/300 [00:00<00:02, 112.40it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:02, 112.72it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:02, 110.82it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:02, 110.26it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:02, 110.54it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 110.95it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 110.91it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 110.65it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:01<00:01, 111.99it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 111.97it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 111.78it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 111.13it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 110.00it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:01, 109.08it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 109.71it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 111.99it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 113.05it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:02<00:00, 113.19it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:02<00:00, 108.52it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 107.24it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 102.34it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 98.82it/s]  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 100.88it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 106.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 109.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.72348
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run royal-sweep-135 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/co6dvmxz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164145-co6dvmxz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: oisvo1lv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164201-oisvo1lv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-136
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/oisvo1lv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 121.06it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 121.87it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 121.90it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 121.92it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 122.44it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 123.21it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 123.26it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 123.74it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 123.25it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 123.61it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 123.24it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 122.84it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 122.96it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 118.24it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 112.86it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 112.14it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 111.97it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 111.55it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:02<00:00, 111.39it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:02<00:00, 113.33it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 107.01it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 108.12it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:02<00:00, 107.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 116.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30428
wandb: sub_train_loss 1.73622
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run unique-sweep-136 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/oisvo1lv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164201-oisvo1lv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vxc3jd50 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164221-vxc3jd50
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-137
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/vxc3jd50
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 111.45it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 113.55it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 114.02it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 114.72it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 112.32it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:02, 110.32it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 112.40it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 114.19it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 113.91it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 114.51it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:01<00:01, 117.69it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 119.04it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 121.38it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:01, 122.37it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 122.87it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 121.42it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 120.01it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 118.51it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:02<00:00, 117.93it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:02<00:00, 117.75it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 118.34it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 117.00it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:02<00:00, 115.98it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 114.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 116.60it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30465
wandb: sub_train_loss 1.76102
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run sandy-sweep-137 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/vxc3jd50
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164221-vxc3jd50/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tb3s2yjh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164237-tb3s2yjh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-138
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/tb3s2yjh
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 118.05it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 116.23it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:02, 119.11it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 120.90it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 121.89it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 122.75it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 123.16it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 122.96it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 123.40it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:01<00:01, 122.03it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 122.55it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 122.92it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 123.29it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 123.28it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 123.29it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 123.38it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 123.48it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 123.40it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 123.44it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:02<00:00, 122.72it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:02<00:00, 122.85it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:02<00:00, 122.71it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 122.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 122.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.73135
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run silvery-sweep-138 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/tb3s2yjh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164237-tb3s2yjh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4j3wopi6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164252-4j3wopi6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-139
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/4j3wopi6
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 8/300 [00:00<00:03, 79.42it/s]  6%|‚ñå         | 17/300 [00:00<00:03, 83.05it/s]  9%|‚ñä         | 26/300 [00:00<00:03, 78.42it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:03, 83.46it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:02, 89.60it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:02, 94.33it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:02, 96.80it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 98.36it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 98.67it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:01<00:01, 99.76it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:01<00:01, 100.02it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:01<00:01, 98.86it/s]  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:01<00:01, 99.78it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 99.84it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 100.31it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 99.90it/s]  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:01, 100.59it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:01, 97.86it/s]  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:02<00:01, 94.75it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:02<00:00, 93.44it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:02<00:00, 92.70it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:02<00:00, 92.26it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:02<00:00, 93.98it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:02<00:00, 93.94it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:02<00:00, 93.64it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:02<00:00, 93.90it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 92.77it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:03<00:00, 92.37it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:03<00:00, 94.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 94.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.74214
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run likely-sweep-139 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/4j3wopi6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164252-4j3wopi6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gq9s6w0n with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164308-gq9s6w0n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-140
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/gq9s6w0n
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 94.62it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 95.86it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 95.57it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 95.09it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 95.52it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 95.13it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 95.12it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:02, 96.91it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:02, 97.01it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:01<00:02, 97.90it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:01<00:01, 97.86it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:01<00:01, 98.36it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 98.60it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 98.06it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 98.39it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 98.34it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:01, 99.06it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:01, 99.26it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:01, 99.11it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:02<00:00, 98.49it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:02<00:00, 97.61it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:02<00:00, 98.03it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:02<00:00, 98.66it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:02<00:00, 98.95it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:02<00:00, 99.17it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 98.81it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 97.04it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:02<00:00, 96.43it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:03<00:00, 95.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 97.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31462
wandb: sub_train_loss 1.68727
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run misunderstood-sweep-140 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/gq9s6w0n
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164308-gq9s6w0n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9z016o5n with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164322-9z016o5n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-141
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/9z016o5n
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 90.91it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 88.62it/s] 10%|‚ñâ         | 29/300 [00:00<00:03, 81.87it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:03, 77.35it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:03, 71.25it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:03, 69.84it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:03, 69.02it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:03, 69.98it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:01<00:03, 66.30it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:01<00:03, 65.61it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:01<00:02, 75.88it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:01<00:02, 83.31it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:01<00:02, 88.76it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:01, 93.17it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 95.89it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 97.77it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 98.65it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:02<00:01, 98.79it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:02<00:01, 99.05it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:02<00:01, 99.70it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:02<00:00, 99.95it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:02<00:00, 100.28it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:02<00:00, 100.24it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:02<00:00, 100.80it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:02<00:00, 101.11it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:02<00:00, 101.16it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:03<00:00, 101.27it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:03<00:00, 101.15it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:03<00:00, 99.42it/s] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 90.07it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.7302
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run firm-sweep-141 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/9z016o5n
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164322-9z016o5n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: l9w1hghb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164338-l9w1hghb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-142
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/l9w1hghb
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 9/300 [00:00<00:03, 89.16it/s]  6%|‚ñã         | 19/300 [00:00<00:03, 91.06it/s] 10%|‚ñâ         | 29/300 [00:00<00:03, 84.84it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:03, 83.30it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:03, 83.70it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:02, 87.28it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:02, 89.14it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:02, 93.35it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:02, 96.80it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 99.34it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:01<00:01, 100.05it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:01<00:01, 100.84it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:01<00:01, 100.40it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 99.71it/s]  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 98.28it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 97.06it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:01, 96.24it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:01, 96.33it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:02<00:01, 97.10it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:02<00:00, 98.25it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:02<00:00, 99.36it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:02<00:00, 98.17it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:02<00:00, 96.15it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:02<00:00, 93.72it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 91.05it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 91.69it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 93.41it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:03<00:00, 96.24it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:03<00:00, 98.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 95.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.70545
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run glad-sweep-142 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/l9w1hghb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164338-l9w1hghb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wlib50vu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164353-wlib50vu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-143
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/wlib50vu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 96.51it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 95.42it/s] 10%|‚ñà         | 30/300 [00:00<00:03, 86.06it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:03, 84.76it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 86.03it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:02, 87.55it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:02, 87.37it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:02, 87.84it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:02, 85.26it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:01<00:02, 85.36it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:01<00:02, 86.51it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:01<00:02, 86.46it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:01<00:01, 89.03it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 89.89it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 91.92it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 94.96it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 94.50it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:01, 96.47it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:02<00:01, 96.84it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:02<00:01, 97.21it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:02<00:00, 97.18it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:02<00:00, 96.99it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:02<00:00, 97.17it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:02<00:00, 96.95it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:02<00:00, 96.97it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:02<00:00, 95.78it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 95.57it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 95.76it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:03<00:00, 94.92it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:03<00:00, 94.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 92.59it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.73831
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run easy-sweep-143 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/wlib50vu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164353-wlib50vu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 68de03bm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 32
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164408-68de03bm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-144
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/68de03bm
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 9/300 [00:00<00:03, 84.95it/s]  6%|‚ñã         | 19/300 [00:00<00:03, 92.50it/s] 10%|‚ñâ         | 29/300 [00:00<00:02, 95.34it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 96.24it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:02, 95.84it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:02, 96.54it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:02, 95.83it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:02, 93.71it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:02, 90.72it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:01<00:02, 93.21it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:01, 95.56it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 96.59it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 95.93it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 95.94it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 95.88it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 95.83it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 95.58it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 95.96it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:01, 95.81it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:02<00:01, 96.87it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:02<00:00, 98.83it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:02<00:00, 99.03it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:02<00:00, 98.01it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:02<00:00, 97.55it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:02<00:00, 96.91it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 96.81it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:02<00:00, 96.74it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:02<00:00, 97.43it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:03<00:00, 99.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 96.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.74021
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run stoic-sweep-144 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/68de03bm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164408-68de03bm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5ks9a96n with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164424-5ks9a96n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-145
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5ks9a96n
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 206.45it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:00, 207.85it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 205.78it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 210.84it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 218.74it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 221.78it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 226.91it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:00<00:00, 230.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 223.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.61854
wandb: sub_train_loss 1.02226
wandb:       test_acc 0.56
wandb:      valid_acc 0.572
wandb: 
wandb: üöÄ View run sandy-sweep-145 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5ks9a96n
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164424-5ks9a96n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: naibrksl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164439-naibrksl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-146
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/naibrksl
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 224.48it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:00, 216.92it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 214.64it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 214.83it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 210.54it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 211.34it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 216.82it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 201.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 198.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 207.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.48338
wandb: sub_train_loss 1.35543
wandb:       test_acc 0.573
wandb:      valid_acc 0.56
wandb: 
wandb: üöÄ View run distinctive-sweep-146 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/naibrksl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164439-naibrksl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gttbnkey with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164450-gttbnkey
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-147
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/gttbnkey
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 225.80it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:00, 225.90it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 226.28it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 230.93it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 231.03it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 223.19it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:00<00:00, 220.34it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:00<00:00, 217.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 221.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.62999
wandb: sub_train_loss 1.00823
wandb:       test_acc 0.61
wandb:      valid_acc 0.63
wandb: 
wandb: üöÄ View run resilient-sweep-147 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/gttbnkey
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164450-gttbnkey/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: g7176mll with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164505-g7176mll
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-148
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/g7176mll
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 223.48it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:00, 225.19it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 226.99it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 228.92it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 225.34it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 216.70it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 214.89it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:00<00:00, 215.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 219.07it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.65916
wandb: sub_train_loss 0.96662
wandb:       test_acc 0.698
wandb:      valid_acc 0.726
wandb: 
wandb: üöÄ View run amber-sweep-148 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/g7176mll
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164505-g7176mll/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9iiypy8s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164519-9iiypy8s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-149
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/9iiypy8s
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 218.52it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:00, 224.55it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 226.28it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 228.15it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 227.03it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 229.42it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 236.52it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:00<00:00, 240.27it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 233.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.67762
wandb: sub_train_loss 0.95322
wandb:       test_acc 0.561
wandb:      valid_acc 0.54
wandb: 
wandb: üöÄ View run cosmic-sweep-149 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/9iiypy8s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164519-9iiypy8s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: de34v5up with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164531-de34v5up
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-150
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/de34v5up
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 223.11it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:00, 222.48it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 220.51it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 219.59it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 220.72it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 222.16it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 223.33it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:00<00:00, 224.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 223.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.62666
wandb: sub_train_loss 1.15046
wandb:       test_acc 0.747
wandb:      valid_acc 0.738
wandb: 
wandb: üöÄ View run vague-sweep-150 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/de34v5up
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164531-de34v5up/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dixdchn8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164546-dixdchn8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-151
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/dixdchn8
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 176.05it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 177.41it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 174.16it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 173.51it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 172.93it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 170.99it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 171.27it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 172.60it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:00<00:00, 178.89it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 181.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 176.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.39882
wandb: sub_train_loss 1.45886
wandb:       test_acc 0.231
wandb:      valid_acc 0.224
wandb: 
wandb: üöÄ View run sage-sweep-151 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/dixdchn8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164546-dixdchn8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 0cbxtbn6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164606-0cbxtbn6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-152
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0cbxtbn6
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 166.54it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 178.82it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 183.48it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 186.47it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 182.66it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 179.93it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 179.48it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 179.04it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 180.58it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 178.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 179.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb:       test_acc ‚ñÅ‚ñá‚ñá‚ñá‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñá‚ñá‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ‚ñà‚ñà‚ñá‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.21972
wandb: sub_train_loss 1.78566
wandb:       test_acc 0.215
wandb:      valid_acc 0.236
wandb: 
wandb: üöÄ View run honest-sweep-152 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0cbxtbn6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164606-0cbxtbn6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pw9vdqc0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164621-pw9vdqc0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-153
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/pw9vdqc0
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 183.70it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 186.12it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 187.51it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 187.80it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 188.07it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 186.46it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 186.13it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 184.35it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 184.09it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 185.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 185.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.44461
wandb: sub_train_loss 1.49157
wandb:       test_acc 0.501
wandb:      valid_acc 0.496
wandb: 
wandb: üöÄ View run apricot-sweep-153 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/pw9vdqc0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164621-pw9vdqc0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lpm4ln4j with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164632-lpm4ln4j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-154
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/lpm4ln4j
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 187.13it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 179.26it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 169.30it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 166.32it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 164.66it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 161.47it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 161.93it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 161.76it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 167.49it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 170.37it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 172.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 168.72it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñá
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31425
wandb: sub_train_loss 1.87581
wandb:       test_acc 0.248
wandb:      valid_acc 0.236
wandb: 
wandb: üöÄ View run peach-sweep-154 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/lpm4ln4j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164632-lpm4ln4j/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gwfp9q3r with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164647-gwfp9q3r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-155
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/gwfp9q3r
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 178.94it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 177.32it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 174.22it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 173.89it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 174.16it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 175.14it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 175.46it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 176.22it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 177.69it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 178.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 178.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 176.55it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñà‚ñà‚ñÉ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.37223
wandb: sub_train_loss 1.40615
wandb:       test_acc 0.388
wandb:      valid_acc 0.416
wandb: 
wandb: üöÄ View run gallant-sweep-155 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/gwfp9q3r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164647-gwfp9q3r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: vs7mkb1d with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164708-vs7mkb1d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-156
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/vs7mkb1d
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 178.89it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 177.00it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 174.46it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 175.27it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 170.50it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 167.60it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 175.96it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:00<00:00, 181.94it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 185.57it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 186.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 180.29it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.57349
wandb: sub_train_loss 1.28225
wandb:       test_acc 0.411
wandb:      valid_acc 0.4
wandb: 
wandb: üöÄ View run helpful-sweep-156 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/vs7mkb1d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164708-vs7mkb1d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: shefliaj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164722-shefliaj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-157
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/shefliaj
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 160.91it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 159.67it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:00, 160.72it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:00, 154.52it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 153.18it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 154.90it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 157.19it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 155.66it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 156.20it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 156.94it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 157.73it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 158.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 157.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñá‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.32164
wandb: sub_train_loss 1.5845
wandb:       test_acc 0.182
wandb:      valid_acc 0.19
wandb: 
wandb: üöÄ View run playful-sweep-157 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/shefliaj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164722-shefliaj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: h1hj2l7d with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164738-h1hj2l7d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-158
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/h1hj2l7d
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 155.33it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 155.25it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 152.88it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 151.10it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 150.56it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 149.64it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 150.44it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 151.81it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 151.48it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 151.17it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 152.04it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 153.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 152.34it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.45716
wandb: sub_train_loss 1.54402
wandb:       test_acc 0.266
wandb:      valid_acc 0.268
wandb: 
wandb: üöÄ View run lemon-sweep-158 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/h1hj2l7d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164738-h1hj2l7d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: r2nigppj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164758-r2nigppj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-159
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/r2nigppj
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 122.64it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 129.88it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 133.03it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 130.12it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 135.36it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 141.48it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 144.60it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 148.10it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 132.92it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 121.93it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 118.38it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 116.54it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 118.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 129.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñá‚ñá‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.22083
wandb: sub_train_loss 1.83304
wandb:       test_acc 0.228
wandb:      valid_acc 0.262
wandb: 
wandb: üöÄ View run rare-sweep-159 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/r2nigppj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164758-r2nigppj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ff8bpmkw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164813-ff8bpmkw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-160
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ff8bpmkw
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 156.34it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 152.86it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 152.07it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 151.66it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 151.88it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 150.48it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 150.11it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 150.48it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 150.98it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 150.07it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 147.94it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 147.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 150.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.43353
wandb: sub_train_loss 1.45351
wandb:       test_acc 0.52
wandb:      valid_acc 0.526
wandb: 
wandb: üöÄ View run zesty-sweep-160 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ff8bpmkw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164813-ff8bpmkw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lr7kr234 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164825-lr7kr234
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-161
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/lr7kr234
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 152.92it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 153.55it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 152.73it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 156.33it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 157.88it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 157.91it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 160.47it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 160.40it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 159.96it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 159.80it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 159.30it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 158.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 158.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñá‚ñà
wandb:       test_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.37888
wandb: sub_train_loss 2.24367
wandb:       test_acc 0.243
wandb:      valid_acc 0.25
wandb: 
wandb: üöÄ View run exalted-sweep-161 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/lr7kr234
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164825-lr7kr234/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: spb46azk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164840-spb46azk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-162
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/spb46azk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 139.43it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 145.15it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 144.85it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 150.12it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 154.26it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 156.71it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 155.85it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 153.03it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 149.39it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 151.47it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 151.55it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 153.38it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 151.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.28767
wandb: sub_train_loss 1.7877
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run stilted-sweep-162 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/spb46azk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164840-spb46azk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: y8x7sh1r with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164852-y8x7sh1r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-163
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/y8x7sh1r
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 227.13it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 230.95it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:00, 234.35it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:00, 235.47it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 236.05it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 236.84it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 237.54it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:00<00:00, 237.79it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:00<00:00, 238.18it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 237.24it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 237.37it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 235.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 235.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.70384
wandb: sub_train_loss 0.73346
wandb:       test_acc 0.688
wandb:      valid_acc 0.694
wandb: 
wandb: üöÄ View run denim-sweep-163 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/y8x7sh1r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164852-y8x7sh1r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8vs7yjq8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164913-8vs7yjq8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-164
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/8vs7yjq8
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 222.61it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 230.71it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:00, 233.88it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:00, 235.77it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 232.79it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 219.83it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:00<00:00, 208.89it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:00<00:00, 200.76it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:00<00:00, 193.72it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 189.80it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 184.17it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 184.60it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 189.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 202.78it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.65214
wandb: sub_train_loss 0.94977
wandb:       test_acc 0.595
wandb:      valid_acc 0.56
wandb: 
wandb: üöÄ View run bumbling-sweep-164 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/8vs7yjq8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164913-8vs7yjq8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: amzuft13 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164927-amzuft13
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-165
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/amzuft13
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 228.60it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 236.37it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:00, 238.69it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:00, 239.67it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:00, 241.15it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 237.38it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 232.57it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:00<00:00, 234.45it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:00<00:00, 236.06it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 236.89it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 236.71it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 235.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 236.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.70975
wandb: sub_train_loss 0.79477
wandb:       test_acc 0.727
wandb:      valid_acc 0.744
wandb: 
wandb: üöÄ View run smooth-sweep-165 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/amzuft13
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164927-amzuft13/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0igwk5i2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164939-0igwk5i2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-166
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0igwk5i2
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 22/300 [00:00<00:01, 216.18it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 220.97it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 218.47it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:00, 220.10it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:00, 219.55it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 220.04it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 226.70it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:00<00:00, 230.57it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:00<00:00, 233.23it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 234.91it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 236.42it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 237.68it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 230.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.64513
wandb: sub_train_loss 0.97739
wandb:       test_acc 0.618
wandb:      valid_acc 0.61
wandb: 
wandb: üöÄ View run solar-sweep-166 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0igwk5i2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164939-0igwk5i2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: agtjqjtv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_164952-agtjqjtv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-167
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/agtjqjtv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 231.10it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 237.73it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:00, 234.16it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:00, 232.13it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 230.42it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 229.34it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 226.24it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:00<00:00, 225.64it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:00<00:00, 229.73it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 229.92it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 222.88it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 222.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 227.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.65288
wandb: sub_train_loss 1.05085
wandb:       test_acc 0.629
wandb:      valid_acc 0.666
wandb: 
wandb: üöÄ View run skilled-sweep-167 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/agtjqjtv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_164952-agtjqjtv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zmsn1uzi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165004-zmsn1uzi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-168
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/zmsn1uzi
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 203.57it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 203.01it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 199.02it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 202.72it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:00, 209.88it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:00, 216.45it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 219.56it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 221.17it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:00<00:00, 226.31it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 228.76it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 230.49it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 232.15it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 233.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 222.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.68538
wandb: sub_train_loss 1.10263
wandb:       test_acc 0.711
wandb:      valid_acc 0.73
wandb: 
wandb: üöÄ View run stoic-sweep-168 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/zmsn1uzi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165004-zmsn1uzi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pw1l7e0m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165019-pw1l7e0m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-169
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/pw1l7e0m
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 163.16it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 160.53it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 168.11it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:02, 78.72it/s]  27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:02, 86.53it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:02, 93.67it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:01<00:01, 97.73it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:01<00:01, 99.71it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:01, 101.78it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 101.43it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 102.46it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 104.31it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 124.06it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 140.96it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 150.58it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 158.85it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:02<00:00, 163.33it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 171.06it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 176.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 128.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÖ‚ñÜ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÉ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.4339
wandb: sub_train_loss 1.70108
wandb:       test_acc 0.215
wandb:      valid_acc 0.22
wandb: 
wandb: üöÄ View run chocolate-sweep-169 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/pw1l7e0m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165019-pw1l7e0m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 3yz0ntjm with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165039-3yz0ntjm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-170
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/3yz0ntjm
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 186.90it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:01, 189.01it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 189.45it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 190.65it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 191.54it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:00, 192.13it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 189.07it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 190.19it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 191.49it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 191.43it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 192.00it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 192.08it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 189.60it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 185.38it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 183.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 188.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñÜ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñá‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.33456
wandb: sub_train_loss 1.61194
wandb:       test_acc 0.263
wandb:      valid_acc 0.27
wandb: 
wandb: üöÄ View run dashing-sweep-170 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/3yz0ntjm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165039-3yz0ntjm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5wcsgojo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165100-5wcsgojo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-171
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5wcsgojo
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 163.12it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 145.55it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 159.06it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 164.94it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 168.26it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 168.42it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 168.72it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 169.30it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 171.35it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 174.48it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 177.96it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 177.54it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 180.69it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 183.26it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 186.07it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 186.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 175.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñÇ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.55835
wandb: sub_train_loss 1.19307
wandb:       test_acc 0.587
wandb:      valid_acc 0.58
wandb: 
wandb: üöÄ View run hardy-sweep-171 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5wcsgojo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165100-5wcsgojo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 2008ispq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165120-2008ispq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-172
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/2008ispq
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 177.44it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:01, 182.43it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 185.70it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 181.67it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 181.87it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 185.82it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 189.49it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 191.38it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 190.88it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 190.99it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 179.39it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 169.24it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 159.75it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 146.74it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 146.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 148.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 169.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñÅ‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.44867
wandb: sub_train_loss 1.32668
wandb:       test_acc 0.606
wandb:      valid_acc 0.632
wandb: 
wandb: üöÄ View run prime-sweep-172 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/2008ispq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165120-2008ispq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: swzwkdbk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165135-swzwkdbk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-173
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/swzwkdbk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 177.13it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 169.42it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 169.11it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 168.58it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 168.51it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 168.28it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 169.86it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 171.75it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 168.49it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 166.92it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 165.04it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 167.81it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 169.53it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 170.80it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 171.44it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 174.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 170.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÉ‚ñÑ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.48929
wandb: sub_train_loss 1.32452
wandb:       test_acc 0.372
wandb:      valid_acc 0.4
wandb: 
wandb: üöÄ View run leafy-sweep-173 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/swzwkdbk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165135-swzwkdbk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9r7mtvj9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165151-9r7mtvj9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-174
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/9r7mtvj9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 185.75it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 186.19it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 187.87it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 189.67it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 190.47it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:00, 187.01it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 186.64it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 186.88it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:00<00:00, 189.11it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 187.36it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 181.25it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 178.30it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 172.90it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 171.89it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 172.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 181.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.64328
wandb: sub_train_loss 1.15156
wandb:       test_acc 0.568
wandb:      valid_acc 0.608
wandb: 
wandb: üöÄ View run dainty-sweep-174 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/9r7mtvj9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165151-9r7mtvj9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: cycrds8b with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165206-cycrds8b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-175
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/cycrds8b
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  0%|          | 1/300 [00:00<01:04,  4.65it/s]  6%|‚ñå         | 17/300 [00:00<00:04, 65.36it/s] 11%|‚ñà         | 33/300 [00:00<00:02, 98.42it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:02, 111.19it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 120.19it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 126.36it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 133.12it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 136.69it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 137.09it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:01<00:01, 139.49it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 140.60it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:00, 144.70it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 148.43it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 151.16it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 151.66it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 152.60it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 152.68it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 136.68it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 121.73it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:02<00:00, 122.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 127.75it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.22194
wandb: sub_train_loss 1.80111
wandb:       test_acc 0.152
wandb:      valid_acc 0.158
wandb: 
wandb: üöÄ View run misty-sweep-175 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/cycrds8b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165206-cycrds8b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 52mimus8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165221-52mimus8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-176
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/52mimus8
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 156.52it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 158.95it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 158.68it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 159.18it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 159.39it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 160.77it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 160.42it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:01, 159.71it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 159.79it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:00, 156.60it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 155.65it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 155.84it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 154.46it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 153.78it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 152.98it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 154.06it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 153.75it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 155.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 156.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÖ‚ñà‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:       test_acc ‚ñá‚ñá‚ñá‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.32386
wandb: sub_train_loss 1.81894
wandb:       test_acc 0.36
wandb:      valid_acc 0.404
wandb: 
wandb: üöÄ View run ruby-sweep-176 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/52mimus8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165221-52mimus8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: cq9l17qx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165234-cq9l17qx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-177
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/cq9l17qx
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 141.49it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 142.36it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 140.78it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 140.99it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 140.66it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 141.08it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 141.32it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 141.62it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 141.92it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 142.70it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 143.84it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 144.72it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 144.80it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 145.73it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 145.90it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 146.79it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 148.61it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 148.78it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 151.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 145.80it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñá‚ñÅ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:       test_acc ‚ñá‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÜ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.34269
wandb: sub_train_loss 1.72362
wandb:       test_acc 0.351
wandb:      valid_acc 0.364
wandb: 
wandb: üöÄ View run giddy-sweep-177 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/cq9l17qx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165234-cq9l17qx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ugjoa5me with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165248-ugjoa5me
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-178
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ugjoa5me
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 153.63it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 150.76it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 150.48it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 151.29it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 151.38it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 148.87it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 148.40it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 150.11it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:01, 149.47it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:00, 151.48it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 153.19it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 153.81it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 154.97it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 154.81it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 154.57it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 154.39it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 155.61it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 155.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 152.99it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñá‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.41765
wandb: sub_train_loss 1.44147
wandb:       test_acc 0.422
wandb:      valid_acc 0.426
wandb: 
wandb: üöÄ View run glamorous-sweep-178 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ugjoa5me
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165248-ugjoa5me/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dxe2dwoj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165302-dxe2dwoj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-179
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/dxe2dwoj
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 144.23it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 149.58it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 150.46it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 149.83it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 148.23it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:01, 139.55it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 142.66it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 146.93it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:01, 148.03it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:00, 148.04it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 140.85it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 136.23it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 139.41it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 139.74it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 142.32it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 146.74it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 149.55it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 148.24it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 141.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 143.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.37445
wandb: sub_train_loss 1.70103
wandb:       test_acc 0.4
wandb:      valid_acc 0.398
wandb: 
wandb: üöÄ View run lilac-sweep-179 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/dxe2dwoj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165302-dxe2dwoj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mph1g8ts with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165318-mph1g8ts
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-180
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/mph1g8ts
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 152.24it/s] 11%|‚ñà         | 32/300 [00:00<00:02, 129.11it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 133.65it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 136.70it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 137.03it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 137.17it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 141.61it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 144.75it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:01, 146.17it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:00, 148.31it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 145.80it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 140.71it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 138.11it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 139.20it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 141.26it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 144.66it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 148.54it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 151.06it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 151.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 143.86it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÖ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.27511
wandb: sub_train_loss 1.6739
wandb:       test_acc 0.335
wandb:      valid_acc 0.346
wandb: 
wandb: üöÄ View run wobbly-sweep-180 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/mph1g8ts
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165318-mph1g8ts/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: g5ac19p0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165333-g5ac19p0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-181
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/g5ac19p0
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 155.81it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 118.83it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 102.56it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 95.57it/s]  33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 93.42it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:01, 103.36it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 119.00it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 130.58it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 136.64it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 137.99it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 138.97it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 139.76it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 140.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 126.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.57127
wandb: sub_train_loss 1.21308
wandb:       test_acc 0.6
wandb:      valid_acc 0.598
wandb: 
wandb: üöÄ View run super-sweep-181 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/g5ac19p0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165333-g5ac19p0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jr3gqv9o with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165348-jr3gqv9o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-182
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/jr3gqv9o
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 150.93it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 146.90it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 145.58it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 144.74it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 144.54it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 143.46it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 144.68it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 143.46it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 143.35it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 140.97it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 139.01it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 140.81it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 141.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 142.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.66322
wandb: sub_train_loss 0.98623
wandb:       test_acc 0.654
wandb:      valid_acc 0.646
wandb: 
wandb: üöÄ View run wise-sweep-182 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/jr3gqv9o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165348-jr3gqv9o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zflkxzij with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165403-zflkxzij
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-183
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/zflkxzij
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 149.79it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 147.59it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 151.19it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 149.91it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 150.86it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 153.53it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 155.04it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 150.23it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 145.28it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 145.36it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 145.02it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 145.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 148.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.49778
wandb: sub_train_loss 1.24634
wandb:       test_acc 0.484
wandb:      valid_acc 0.484
wandb: 
wandb: üöÄ View run icy-sweep-183 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/zflkxzij
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165403-zflkxzij/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 69iya3sk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165419-69iya3sk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-184
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/69iya3sk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 148.33it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 146.09it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 145.92it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 145.44it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 145.35it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 144.69it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 145.16it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 145.11it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 137.82it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 139.24it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 139.37it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 139.86it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 139.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 141.98it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.52179
wandb: sub_train_loss 1.5706
wandb:       test_acc 0.475
wandb:      valid_acc 0.484
wandb: 
wandb: üöÄ View run youthful-sweep-184 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/69iya3sk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165419-69iya3sk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: kxcidh5e with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165439-kxcidh5e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-185
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/kxcidh5e
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 157.59it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 151.65it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 143.96it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 141.68it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 139.19it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 141.04it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 142.05it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 143.18it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 143.51it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 140.59it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 141.34it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 144.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 145.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 143.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÑ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.60635
wandb: sub_train_loss 1.00535
wandb:       test_acc 0.593
wandb:      valid_acc 0.618
wandb: 
wandb: üöÄ View run vivid-sweep-185 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/kxcidh5e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165439-kxcidh5e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: p8tnnac7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165454-p8tnnac7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-186
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/p8tnnac7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 145.68it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 146.06it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 146.67it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 147.43it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 148.03it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 147.28it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 144.91it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 145.35it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 146.75it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 146.97it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 139.37it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 138.06it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 133.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 141.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.6178
wandb: sub_train_loss 1.05842
wandb:       test_acc 0.605
wandb:      valid_acc 0.588
wandb: 
wandb: üöÄ View run sage-sweep-186 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/p8tnnac7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165454-p8tnnac7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dfh79q9h with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165510-dfh79q9h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-187
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/dfh79q9h
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 118.31it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 118.43it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 118.89it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 118.36it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:01, 119.06it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:01, 118.00it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:01, 113.23it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 108.84it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 107.14it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:01<00:00, 106.51it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 104.80it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 102.56it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 103.73it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 106.07it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 108.29it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 110.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 110.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 110.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÇ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñà
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñà‚ñÑ‚ñÉ‚ñÅ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÜ‚ñà‚ñÑ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.32016
wandb: sub_train_loss 2.89794
wandb:       test_acc 0.272
wandb:      valid_acc 0.282
wandb: 
wandb: üöÄ View run proud-sweep-187 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/dfh79q9h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165510-dfh79q9h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5w8vrfe0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165526-5w8vrfe0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-188
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5w8vrfe0
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 123.20it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 120.27it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 122.39it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 123.03it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 123.09it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 121.44it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 122.06it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 122.10it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 122.24it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 121.01it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 120.78it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 121.06it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 121.02it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 120.67it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 120.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 121.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.46824
wandb: sub_train_loss 1.54848
wandb:       test_acc 0.474
wandb:      valid_acc 0.486
wandb: 
wandb: üöÄ View run bright-sweep-188 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5w8vrfe0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165526-5w8vrfe0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fzekruz5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165542-fzekruz5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-189
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/fzekruz5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 109.51it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 116.23it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 113.72it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 115.09it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 110.58it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 111.90it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 111.82it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 112.63it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 112.15it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 112.86it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 113.04it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 113.18it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 113.38it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 113.74it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 113.38it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 113.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 112.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÉ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.44572
wandb: sub_train_loss 1.61284
wandb:       test_acc 0.375
wandb:      valid_acc 0.382
wandb: 
wandb: üöÄ View run royal-sweep-189 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/fzekruz5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165542-fzekruz5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: t9ttg4wg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165556-t9ttg4wg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-190
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/t9ttg4wg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 122.48it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 119.19it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 116.89it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 118.00it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 119.71it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 121.22it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 121.15it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 114.60it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 113.13it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:01<00:00, 113.54it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 111.80it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 110.87it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 109.12it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 108.87it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 107.98it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 105.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 112.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÑ
wandb: sub_train_loss ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñà
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñÖ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.39217
wandb: sub_train_loss 2.15207
wandb:       test_acc 0.37
wandb:      valid_acc 0.394
wandb: 
wandb: üöÄ View run pious-sweep-190 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/t9ttg4wg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165556-t9ttg4wg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: nlsbbiyz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165617-nlsbbiyz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-191
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/nlsbbiyz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 123.28it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 126.09it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 124.39it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 125.84it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 127.05it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 127.74it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 128.38it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 128.92it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 128.07it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 128.35it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 127.64it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 125.26it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 122.55it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 120.50it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 121.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 125.10it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÜ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñÉ‚ñÅ
wandb:      valid_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñÑ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.33715
wandb: sub_train_loss 1.69005
wandb:       test_acc 0.289
wandb:      valid_acc 0.302
wandb: 
wandb: üöÄ View run fluent-sweep-191 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/nlsbbiyz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165617-nlsbbiyz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: uubd4yfz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165638-uubd4yfz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-192
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/uubd4yfz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 121.47it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 122.85it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 123.25it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 121.49it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 121.11it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 113.38it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 103.26it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 102.96it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:01<00:00, 102.77it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:01<00:00, 100.54it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:01<00:00, 96.91it/s]  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 93.27it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 91.07it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 92.81it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 95.95it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 100.63it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 102.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 103.78it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÇ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÅ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÇ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.57718
wandb: sub_train_loss 1.36479
wandb:       test_acc 0.516
wandb:      valid_acc 0.53
wandb: 
wandb: üöÄ View run good-sweep-192 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/uubd4yfz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165638-uubd4yfz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lsu6eyps with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165651-lsu6eyps
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-193
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/lsu6eyps
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 97.58it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 94.39it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 95.26it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 94.30it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 93.05it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 91.64it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 92.08it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 90.78it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 91.07it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 92.33it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 92.77it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 94.95it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 95.46it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 95.55it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 96.04it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 97.52it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 98.76it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 98.34it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:02<00:00, 97.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 95.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.37334
wandb: sub_train_loss 1.66764
wandb:       test_acc 0.397
wandb:      valid_acc 0.422
wandb: 
wandb: üöÄ View run genial-sweep-193 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/lsu6eyps
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165651-lsu6eyps/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: cfte82lw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165706-cfte82lw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-194
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/cfte82lw
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 97.85it/s] 10%|‚ñà         | 21/200 [00:00<00:01, 99.08it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 96.55it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 97.06it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 97.76it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:01, 97.17it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:01, 95.53it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:01, 96.73it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:01, 98.27it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:01<00:00, 99.47it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:01<00:00, 99.87it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:01<00:00, 99.30it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:01<00:00, 98.49it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 97.75it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 98.13it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 99.13it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 99.68it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 100.23it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:02<00:00, 99.70it/s] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 98.53it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÉ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.47341
wandb: sub_train_loss 1.48113
wandb:       test_acc 0.455
wandb:      valid_acc 0.466
wandb: 
wandb: üöÄ View run daily-sweep-194 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/cfte82lw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165706-cfte82lw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bpchv0v8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165721-bpchv0v8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-195
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/bpchv0v8
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 98.14it/s] 10%|‚ñà         | 21/200 [00:00<00:01, 100.52it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 100.97it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:01, 101.75it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 101.71it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 101.39it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 101.25it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:01, 100.96it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:01, 99.61it/s]  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:01<00:00, 99.38it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:01<00:00, 99.12it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:01<00:00, 99.47it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:01<00:00, 99.21it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 99.14it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 99.51it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 99.46it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 98.03it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 97.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 98.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 99.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÅ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÖ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.15916
wandb: sub_train_loss 2.2113
wandb:       test_acc 0.149
wandb:      valid_acc 0.164
wandb: 
wandb: üöÄ View run icy-sweep-195 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/bpchv0v8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165721-bpchv0v8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bnvbj2w5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165734-bnvbj2w5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-196
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/bnvbj2w5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 100.44it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 101.27it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 101.22it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 100.88it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 101.17it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 101.46it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 102.06it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:01, 102.42it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 102.08it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 102.50it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 101.64it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 95.57it/s]  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 92.82it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 95.59it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 97.64it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 98.52it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 97.76it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 97.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 99.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.43685
wandb: sub_train_loss 1.73002
wandb:       test_acc 0.454
wandb:      valid_acc 0.452
wandb: 
wandb: üöÄ View run warm-sweep-196 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/bnvbj2w5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165734-bnvbj2w5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 28sya3h3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165747-28sya3h3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-197
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/28sya3h3
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 101.30it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 101.59it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 101.64it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 102.06it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 102.36it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 102.50it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 102.75it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:01, 102.88it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 102.47it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 101.76it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 100.62it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 100.58it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 98.87it/s]  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 98.00it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 98.47it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 99.95it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 100.95it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 100.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 100.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñá
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñÉ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30355
wandb: sub_train_loss 2.38554
wandb:       test_acc 0.321
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run lilac-sweep-197 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/28sya3h3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165747-28sya3h3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: l5yjsvhw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165809-l5yjsvhw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-198
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/l5yjsvhw
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 98.66it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 92.64it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 92.89it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 92.11it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 91.99it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 92.52it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 93.02it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 93.47it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 93.26it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 93.77it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 93.18it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 93.03it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 93.03it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 93.50it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 92.72it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 93.42it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 94.84it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 94.05it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:02<00:00, 94.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 94.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 93.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñà‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÖ
wandb:       test_acc ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÖ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñà‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.35266
wandb: sub_train_loss 1.67369
wandb:       test_acc 0.315
wandb:      valid_acc 0.312
wandb: 
wandb: üöÄ View run hearty-sweep-198 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/l5yjsvhw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165809-l5yjsvhw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: f4543niw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165822-f4543niw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-199
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/f4543niw
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 159.92it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 158.78it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 157.98it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 159.21it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 160.39it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 153.91it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 153.97it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:01, 152.78it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 129.34it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 119.26it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:01, 117.22it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 114.01it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 113.88it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 110.18it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 104.91it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 108.45it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:01<00:00, 116.46it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:02<00:00, 127.09it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 135.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 142.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 132.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.014 MB of 0.023 MB uploadedwandb: | 0.017 MB of 0.023 MB uploadedwandb: / 0.017 MB of 0.023 MB uploadedwandb: - 0.017 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÉ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÉ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.62629
wandb: sub_train_loss 1.09998
wandb:       test_acc 0.632
wandb:      valid_acc 0.636
wandb: 
wandb: üöÄ View run dandy-sweep-199 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/f4543niw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165822-f4543niw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: y58xzwf0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165837-y58xzwf0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-200
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/y58xzwf0
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 151.26it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 153.51it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 148.01it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 144.93it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 145.77it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 148.73it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 147.28it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 147.39it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:01, 147.62it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:00, 146.69it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 146.23it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 145.91it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 144.28it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 142.14it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 126.43it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 124.60it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 129.79it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 131.89it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 137.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 141.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.77326
wandb: sub_train_loss 0.75079
wandb:       test_acc 0.777
wandb:      valid_acc 0.77
wandb: 
wandb: üöÄ View run gallant-sweep-200 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/y58xzwf0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165837-y58xzwf0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mua7grxq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165848-mua7grxq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-201
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/mua7grxq
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 154.45it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 156.09it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 157.30it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 157.99it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 157.29it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 156.19it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 152.57it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 152.31it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 153.97it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 155.31it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 154.13it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 153.80it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 153.72it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 155.31it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 155.84it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 157.04it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 157.52it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 155.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 155.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.67467
wandb: sub_train_loss 0.91949
wandb:       test_acc 0.671
wandb:      valid_acc 0.68
wandb: 
wandb: üöÄ View run fancy-sweep-201 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/mua7grxq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165848-mua7grxq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6qio3kpy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165903-6qio3kpy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-202
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/6qio3kpy
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 160.98it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 158.15it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 150.78it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 149.94it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 149.47it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 148.99it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 149.62it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:01, 150.42it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:01, 150.63it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:00, 150.78it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 150.07it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 149.67it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 148.85it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 148.73it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 148.63it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 148.66it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 149.19it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 146.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 146.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 149.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñÉ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.67836
wandb: sub_train_loss 1.15531
wandb:       test_acc 0.676
wandb:      valid_acc 0.67
wandb: 
wandb: üöÄ View run glorious-sweep-202 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/6qio3kpy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165903-6qio3kpy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lt98b108 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165917-lt98b108
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-203
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/lt98b108
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 162.27it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 152.86it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 156.74it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 158.21it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 158.43it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 157.62it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 157.11it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:01, 154.00it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 152.58it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:00, 147.97it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 144.41it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 142.07it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 140.52it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 141.10it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 140.55it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 139.98it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 141.78it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 143.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 143.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 147.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.60155
wandb: sub_train_loss 1.29009
wandb:       test_acc 0.584
wandb:      valid_acc 0.592
wandb: 
wandb: üöÄ View run swift-sweep-203 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/lt98b108
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165917-lt98b108/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zdfachwv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165933-zdfachwv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-204
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/zdfachwv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 150.85it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 151.26it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 150.31it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 149.62it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 148.40it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 148.33it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 148.60it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 147.88it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:01, 147.76it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:00, 147.68it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:00, 147.95it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 150.07it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 149.26it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 148.93it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 148.38it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 148.05it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 146.10it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 144.41it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 142.72it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 147.30it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.68759
wandb: sub_train_loss 0.81456
wandb:       test_acc 0.704
wandb:      valid_acc 0.696
wandb: 
wandb: üöÄ View run frosty-sweep-204 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/zdfachwv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165933-zdfachwv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: n4f8muu8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165945-n4f8muu8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-205
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/n4f8muu8
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 119.52it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 105.60it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 110.73it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 114.00it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:02, 117.32it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 119.85it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 121.37it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 122.33it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 122.49it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:01<00:01, 123.07it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 123.14it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 118.70it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 116.98it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:01, 116.80it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 113.83it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 113.60it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 114.62it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 115.61it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:02<00:00, 116.10it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:02<00:00, 117.82it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 120.74it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 121.87it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 123.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 118.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÜ‚ñà‚ñÜ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñÇ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñÉ‚ñÅ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñÇ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÉ‚ñÅ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.5229
wandb: sub_train_loss 1.1817
wandb:       test_acc 0.487
wandb:      valid_acc 0.488
wandb: 
wandb: üöÄ View run solar-sweep-205 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/n4f8muu8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165945-n4f8muu8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: acrfndyv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_165959-acrfndyv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-206
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/acrfndyv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 121.22it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 121.45it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 122.12it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 122.83it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 123.91it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 123.72it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 120.65it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 116.76it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 113.89it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:01<00:01, 112.99it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 110.33it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 107.49it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 103.02it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:01, 103.90it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:01, 107.73it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 111.63it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 113.20it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 114.88it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:02<00:00, 115.05it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:02<00:00, 116.67it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 118.05it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 118.00it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 118.52it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 118.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 115.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÇ‚ñÅ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.59749
wandb: sub_train_loss 1.11544
wandb:       test_acc 0.577
wandb:      valid_acc 0.592
wandb: 
wandb: üöÄ View run usual-sweep-206 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/acrfndyv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_165959-acrfndyv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 216xwidk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170014-216xwidk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-207
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/216xwidk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 119.76it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 116.19it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:02, 121.20it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 121.26it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 119.47it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 120.84it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 122.08it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 119.84it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 109.61it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:01<00:01, 112.31it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 111.98it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 114.00it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 113.92it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:01, 116.37it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 117.38it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 117.47it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 118.12it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 118.57it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:02<00:00, 118.88it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:02<00:00, 113.38it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:02<00:00, 108.52it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 99.13it/s]  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:02<00:00, 94.34it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 100.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 112.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ
wandb: sub_train_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.50074
wandb: sub_train_loss 1.64772
wandb:       test_acc 0.494
wandb:      valid_acc 0.488
wandb: 
wandb: üöÄ View run clean-sweep-207 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/216xwidk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170014-216xwidk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uy1d9jto with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170029-uy1d9jto
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-208
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/uy1d9jto
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 120.93it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 116.08it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 114.81it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 116.02it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:02, 107.05it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:02, 108.49it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 108.73it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 108.47it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 112.31it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:01<00:01, 114.14it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:01<00:01, 113.96it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 114.54it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 115.25it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 115.34it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:01, 115.31it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 115.27it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 115.40it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 117.21it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:02<00:00, 119.45it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:02<00:00, 121.16it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:02<00:00, 121.98it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 122.40it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 124.06it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 124.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 116.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.48191
wandb: sub_train_loss 1.23158
wandb:       test_acc 0.466
wandb:      valid_acc 0.474
wandb: 
wandb: üöÄ View run desert-sweep-208 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/uy1d9jto
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170029-uy1d9jto/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yc0wmv9v with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170045-yc0wmv9v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-209
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/yc0wmv9v
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 118.52it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 119.82it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:02, 116.33it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:02, 116.46it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:02, 114.80it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 118.02it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 118.87it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 118.97it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 118.68it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:01<00:01, 118.26it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:01<00:01, 117.45it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 116.02it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 114.72it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:01, 113.91it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:01, 114.89it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 114.21it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 112.92it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 113.18it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 113.51it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:02<00:00, 113.53it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:02<00:00, 113.85it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:02<00:00, 113.68it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:02<00:00, 113.78it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:02<00:00, 113.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 115.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñÖ‚ñÇ‚ñÉ‚ñÖ‚ñá
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.39439
wandb: sub_train_loss 1.97304
wandb:       test_acc 0.344
wandb:      valid_acc 0.356
wandb: 
wandb: üöÄ View run sleek-sweep-209 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/yc0wmv9v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170045-yc0wmv9v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5xo58jjn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170059-5xo58jjn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-210
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5xo58jjn
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 124.22it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 122.90it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 122.71it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 123.76it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 123.86it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 121.04it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 118.15it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 117.40it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 115.99it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:01<00:01, 118.41it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 117.37it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 119.19it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 121.92it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 123.80it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 123.17it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 123.29it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 123.89it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 123.78it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:02<00:00, 123.28it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:02<00:00, 120.73it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 117.36it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 115.35it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 113.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 119.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.47674
wandb: sub_train_loss 1.41468
wandb:       test_acc 0.46
wandb:      valid_acc 0.464
wandb: 
wandb: üöÄ View run astral-sweep-210 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5xo58jjn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170059-5xo58jjn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: stps2tjh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170115-stps2tjh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-211
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/stps2tjh
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 9/300 [00:00<00:03, 84.33it/s]  6%|‚ñã         | 19/300 [00:00<00:03, 89.90it/s] 10%|‚ñâ         | 29/300 [00:00<00:02, 92.65it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 94.64it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:02, 93.63it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:02, 91.30it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:02, 90.41it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:02, 90.95it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:02, 88.29it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:01<00:02, 88.54it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:01<00:02, 88.15it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:01<00:02, 90.85it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:01<00:01, 91.54it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:01<00:01, 93.54it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 94.78it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 96.04it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 96.62it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:01, 97.78it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:02<00:01, 96.91it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:02<00:01, 96.37it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:02<00:00, 95.66it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:02<00:00, 96.34it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:02<00:00, 97.71it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 98.81it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:02<00:00, 99.54it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 99.82it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 99.43it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 98.42it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:03<00:00, 96.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 94.57it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñÖ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñà‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñÑ‚ñá‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.79838
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run quiet-sweep-211 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/stps2tjh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170115-stps2tjh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2hafaxvn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170131-2hafaxvn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-212
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/2hafaxvn
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 8/300 [00:00<00:03, 78.63it/s]  6%|‚ñå         | 18/300 [00:00<00:03, 86.12it/s]  9%|‚ñâ         | 28/300 [00:00<00:03, 88.36it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 90.19it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 90.00it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:02, 90.63it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:02, 93.03it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:02, 93.80it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:02, 95.04it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:01<00:02, 95.72it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:01<00:01, 96.34it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:01<00:01, 96.44it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:01<00:01, 97.23it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 97.66it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 97.96it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 98.34it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 98.05it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:01, 98.29it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:01, 97.65it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:02<00:01, 97.66it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:02<00:00, 97.83it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:02<00:00, 97.58it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:02<00:00, 98.13it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:02<00:00, 98.15it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:02<00:00, 96.80it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:02<00:00, 95.63it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:02<00:00, 94.67it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 91.59it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:03<00:00, 88.74it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:03<00:00, 87.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 94.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñà‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÅ‚ñÑ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÜ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.45236
wandb: sub_train_loss 1.89496
wandb:       test_acc 0.47
wandb:      valid_acc 0.488
wandb: 
wandb: üöÄ View run major-sweep-212 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/2hafaxvn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170131-2hafaxvn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7wy7c5fo with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170147-7wy7c5fo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-213
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/7wy7c5fo
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 92.19it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 91.29it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 92.81it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 94.38it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 94.97it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 95.66it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:02, 98.13it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:02, 98.36it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:02, 98.80it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:01<00:02, 98.97it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:01<00:01, 97.43it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:01<00:01, 96.69it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 95.55it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 94.93it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 94.84it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 94.83it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:01, 95.21it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:01, 94.95it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:02<00:01, 95.73it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:02<00:01, 96.84it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:02<00:00, 97.20it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:02<00:00, 97.84it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:02<00:00, 96.85it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:02<00:00, 97.22it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 96.61it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 96.74it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 96.90it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 96.90it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:03<00:00, 96.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 96.22it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.44424
wandb: sub_train_loss 1.4484
wandb:       test_acc 0.454
wandb:      valid_acc 0.458
wandb: 
wandb: üöÄ View run hearty-sweep-213 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/7wy7c5fo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170147-7wy7c5fo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: oin7u047 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170202-oin7u047
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-214
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/oin7u047
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 95.72it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 95.30it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 96.69it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 97.01it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 94.00it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 95.56it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 95.13it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 93.73it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 92.06it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 93.52it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:02, 94.26it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 93.72it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 93.71it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 92.96it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 92.12it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 90.81it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 88.03it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:01, 85.53it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:02<00:01, 88.61it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:02<00:01, 92.45it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:02<00:00, 94.82it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 222/300 [00:02<00:00, 96.56it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:02<00:00, 97.87it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:02<00:00, 98.73it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:02<00:00, 99.93it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 100.40it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 101.11it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:03<00:00, 99.90it/s]  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:03<00:00, 98.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 95.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñá‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.45089
wandb: sub_train_loss 1.43213
wandb:       test_acc 0.455
wandb:      valid_acc 0.47
wandb: 
wandb: üöÄ View run stilted-sweep-214 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/oin7u047
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170202-oin7u047/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xcgdv26v with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170217-xcgdv26v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-215
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/xcgdv26v
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 93.51it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 93.17it/s] 10%|‚ñà         | 31/300 [00:00<00:02, 96.87it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:02, 96.48it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:02, 93.94it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:02, 93.89it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:02, 94.88it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:02, 94.71it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:02, 94.34it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:01<00:02, 95.14it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:01<00:01, 94.50it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:01<00:01, 94.28it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 94.02it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 93.41it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 93.44it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:01, 93.47it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:01, 93.54it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:01, 93.77it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:02<00:01, 93.16it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:02<00:01, 92.53it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:02<00:00, 92.76it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:02<00:00, 92.99it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:02<00:00, 93.43it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:02<00:00, 93.42it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:02<00:00, 93.72it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 94.41it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:02<00:00, 94.11it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:02<00:00, 94.34it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:03<00:00, 94.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 93.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñá‚ñà‚ñà‚ñÇ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñà‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñà‚ñà‚ñÅ‚ñÅ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñÖ‚ñá‚ñà‚ñà‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.45089
wandb: sub_train_loss 1.36695
wandb:       test_acc 0.447
wandb:      valid_acc 0.462
wandb: 
wandb: üöÄ View run olive-sweep-215 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/xcgdv26v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170217-xcgdv26v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: axl5caq5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170232-axl5caq5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-216
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/axl5caq5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 94.73it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 93.09it/s] 10%|‚ñà         | 30/300 [00:00<00:03, 88.61it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 88.22it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:02, 90.31it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 94.12it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:02, 96.35it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:02, 97.05it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:02, 97.11it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:01<00:02, 97.16it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:01<00:01, 97.82it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:01<00:01, 94.99it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 93.25it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 92.38it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 91.22it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:01, 90.59it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:01, 90.04it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:01, 90.97it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:02<00:01, 92.46it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:02<00:01, 94.42it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:02<00:00, 96.32it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:02<00:00, 97.75it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:02<00:00, 98.98it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:02<00:00, 98.77it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:02<00:00, 99.43it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 99.93it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 100.73it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:03<00:00, 101.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:03<00:00, 98.75it/s] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 95.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñà‚ñÇ‚ñÅ‚ñÑ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñá‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñá‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31093
wandb: sub_train_loss 1.75581
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run elated-sweep-216 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/axl5caq5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170232-axl5caq5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4nk0my9h with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170248-4nk0my9h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-217
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/4nk0my9h
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 209.96it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:00, 211.24it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 218.26it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 216.07it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 204.35it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 193.01it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 180.60it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:00<00:00, 177.08it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:00<00:00, 176.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 188.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.3161
wandb: sub_train_loss 1.85241
wandb:       test_acc 0.154
wandb:      valid_acc 0.164
wandb: 
wandb: üöÄ View run clean-sweep-217 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/4nk0my9h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170248-4nk0my9h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xr1fdrh0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170308-xr1fdrh0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-218
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/xr1fdrh0
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:00, 240.20it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 228.68it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 224.54it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 226.53it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 223.00it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 229.52it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 233.73it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:00<00:00, 236.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 232.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31388
wandb: sub_train_loss 1.83937
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run dry-sweep-218 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/xr1fdrh0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170308-xr1fdrh0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rg1u30he with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170321-rg1u30he
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-219
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/rg1u30he
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 225.55it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:00, 230.45it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 233.76it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 236.61it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 238.68it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 239.88it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:00<00:00, 236.78it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:00<00:00, 234.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 235.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.34417
wandb: sub_train_loss 1.82665
wandb:       test_acc 0.412
wandb:      valid_acc 0.408
wandb: 
wandb: üöÄ View run stellar-sweep-219 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/rg1u30he
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170321-rg1u30he/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 158m7tdu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170335-158m7tdu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-220
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/158m7tdu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:00, 239.81it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 233.05it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 226.28it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 230.18it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 233.15it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 231.34it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 231.38it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:00<00:00, 231.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 231.58it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30355
wandb: sub_train_loss 1.84345
wandb:       test_acc 0.321
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run dry-sweep-220 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/158m7tdu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170335-158m7tdu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bylhdclk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170347-bylhdclk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-221
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/bylhdclk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 223.40it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:00, 231.25it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 228.81it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 229.98it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 229.96it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 230.68it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 228.07it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:00<00:00, 225.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 227.25it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.81733
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run radiant-sweep-221 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/bylhdclk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170347-bylhdclk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: yxoco37w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170410-yxoco37w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-222
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/yxoco37w
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:00, 238.29it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 236.39it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 238.41it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 232.42it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 227.92it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 226.55it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:00<00:00, 226.56it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:00<00:00, 224.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 228.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.82761
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run copper-sweep-222 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/yxoco37w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170410-yxoco37w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: w484ephb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170421-w484ephb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-223
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/w484ephb
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 176.82it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 174.78it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 172.82it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 172.14it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 172.19it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 172.67it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 174.35it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 172.11it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:00<00:00, 176.95it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 175.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 175.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 174.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31388
wandb: sub_train_loss 1.86339
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run trim-sweep-223 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/w484ephb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170421-w484ephb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nyvtx1in with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170441-nyvtx1in
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-224
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/nyvtx1in
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 187.78it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 188.91it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 189.83it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 187.57it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 179.86it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 173.17it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 169.72it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 167.70it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 167.38it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 169.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 174.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.014 MB of 0.023 MB uploadedwandb: \ 0.014 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31388
wandb: sub_train_loss 1.85288
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run lemon-sweep-224 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/nyvtx1in
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170441-nyvtx1in/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gtdizenp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170457-gtdizenp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-225
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/gtdizenp
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 184.10it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 184.88it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 185.41it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 185.03it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 185.30it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 185.46it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 185.32it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 182.66it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 183.49it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 184.91it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 184.76it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.85058
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run lucky-sweep-225 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/gtdizenp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170457-gtdizenp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6nz6jx31 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170512-6nz6jx31
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-226
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/6nz6jx31
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 171.48it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 167.44it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 160.98it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 160.02it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 162.30it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 164.66it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 169.25it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:00<00:00, 168.52it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 169.65it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 169.40it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 169.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 167.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.82408
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run rich-sweep-226 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/6nz6jx31
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170512-6nz6jx31/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: c9yxtdkv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170524-c9yxtdkv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-227
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/c9yxtdkv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 178.50it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 179.31it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 169.60it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 166.14it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 163.49it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 161.99it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 161.92it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 167.31it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 169.28it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 174.26it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 179.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 171.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.36706
wandb: sub_train_loss 1.83757
wandb:       test_acc 0.415
wandb:      valid_acc 0.418
wandb: 
wandb: üöÄ View run deft-sweep-227 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/c9yxtdkv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170524-c9yxtdkv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: xa99gwih with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170537-xa99gwih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-228
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/xa99gwih
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 184.74it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:00, 188.70it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:00, 188.56it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 189.33it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 189.56it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 190.28it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 191.17it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:00<00:00, 191.68it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:00<00:00, 190.92it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 187.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 188.89it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.82977
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run giddy-sweep-228 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/xa99gwih
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170537-xa99gwih/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6rwbo44v with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170549-6rwbo44v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-229
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/6rwbo44v
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 148.99it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 153.71it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 152.66it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 155.08it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 155.83it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 153.76it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 152.13it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 149.67it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 148.20it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 146.23it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 145.27it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 144.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 148.78it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31388
wandb: sub_train_loss 1.87026
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run avid-sweep-229 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/6rwbo44v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170549-6rwbo44v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: lxpjjcmu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170604-lxpjjcmu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-230
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/lxpjjcmu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.37it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 144.91it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 146.95it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 143.81it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 143.49it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 142.86it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 143.28it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 144.48it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 143.09it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 143.07it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 141.96it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 142.08it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 141.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 142.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31388
wandb: sub_train_loss 1.80886
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run polished-sweep-230 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/lxpjjcmu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170604-lxpjjcmu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 7xgfsu5x with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170624-7xgfsu5x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-231
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/7xgfsu5x
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 157.89it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 158.05it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 156.04it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 154.43it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 154.20it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 155.50it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 153.40it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 154.08it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 153.37it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 153.48it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 153.77it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 154.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 154.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.83083
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run skilled-sweep-231 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/7xgfsu5x
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170624-7xgfsu5x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: iiyy6ks7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170640-iiyy6ks7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-232
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/iiyy6ks7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 135.99it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 133.12it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 129.35it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 127.58it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:01, 127.61it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 125.87it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 125.67it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 126.56it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 126.93it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:01<00:00, 128.68it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 130.97it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 128.51it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 127.50it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 127.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 127.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.80837
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run olive-sweep-232 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/iiyy6ks7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170640-iiyy6ks7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0l5qth71 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170654-0l5qth71
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-233
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0l5qth71
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 147.16it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 148.07it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 148.46it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 150.38it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 150.13it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 149.84it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 152.99it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 155.96it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 155.68it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 154.69it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 145.93it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 150.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 151.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.80196
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run whole-sweep-233 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0l5qth71
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170654-0l5qth71/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 27tu5d8y with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170706-27tu5d8y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-234
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/27tu5d8y
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 137.71it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 137.70it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 137.28it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:01, 136.70it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:00, 137.72it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:00, 143.49it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 146.71it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 149.78it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 151.63it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 151.11it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 151.39it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 150.56it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 148.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 146.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.82812
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run smooth-sweep-234 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/27tu5d8y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170706-27tu5d8y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7r7e06vz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170720-7r7e06vz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-235
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/7r7e06vz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 226.69it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 233.02it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:00, 234.18it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:00, 218.60it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:00, 210.75it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 204.75it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:00<00:00, 199.84it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:00<00:00, 197.86it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:00<00:00, 199.62it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 200.16it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 199.51it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 200.33it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 195.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 202.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31388
wandb: sub_train_loss 1.76832
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run laced-sweep-235 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/7r7e06vz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170720-7r7e06vz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 16jnm8ge with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170736-16jnm8ge
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-236
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/16jnm8ge
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 227.72it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 229.76it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:00, 232.04it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:00, 233.45it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 232.71it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 231.11it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 225.95it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:00<00:00, 226.37it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:00<00:00, 228.02it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 230.27it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 231.56it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 230.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 230.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31388
wandb: sub_train_loss 1.76858
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run volcanic-sweep-236 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/16jnm8ge
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170736-16jnm8ge/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: u8v4m0f9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170748-u8v4m0f9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-237
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/u8v4m0f9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 22/300 [00:00<00:01, 219.81it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 229.04it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 221.81it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 184.79it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 186.24it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 188.60it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 190.99it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:00<00:00, 199.24it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:00<00:00, 205.78it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 215.32it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 221.84it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 226.98it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 230.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 212.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.34343
wandb: sub_train_loss 1.74332
wandb:       test_acc 0.327
wandb:      valid_acc 0.326
wandb: 
wandb: üöÄ View run olive-sweep-237 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/u8v4m0f9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170748-u8v4m0f9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 46ug6vxy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170801-46ug6vxy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-238
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/46ug6vxy
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 202.58it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 198.55it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 198.16it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 208.68it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:00, 209.96it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:00<00:00, 214.39it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 217.53it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 220.17it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:00<00:00, 223.80it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 225.57it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 225.36it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 223.83it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 226.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 218.83it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.765
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run balmy-sweep-238 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/46ug6vxy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170801-46ug6vxy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zt1cs1ho with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170818-zt1cs1ho
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-239
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/zt1cs1ho
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 22/300 [00:00<00:01, 211.41it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 225.92it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 229.40it/s] 31%|‚ñà‚ñà‚ñà       | 93/300 [00:00<00:00, 221.76it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:00, 223.78it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 228.60it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 228.86it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:00<00:00, 222.92it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:00<00:00, 220.37it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 201.61it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 212.25it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 219.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 220.66it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.73949
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run amber-sweep-239 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/zt1cs1ho
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170818-zt1cs1ho/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 0crutjnx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170838-0crutjnx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-240
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0crutjnx
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 227.30it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 232.65it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:00, 234.92it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:00, 234.80it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 229.48it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 226.26it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 182.09it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:00<00:00, 162.71it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 156.28it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 151.73it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 151.13it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 153.88it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 160.71it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 180.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 182.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.71116
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run copper-sweep-240 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0crutjnx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170838-0crutjnx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: m3k0adns with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170851-m3k0adns
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-241
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/m3k0adns
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 186.27it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 187.77it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 189.79it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 189.59it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 188.77it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:00, 187.66it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:00, 188.35it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 186.71it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 185.09it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 185.03it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 183.40it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 175.89it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 177.97it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 180.09it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 179.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 183.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31388
wandb: sub_train_loss 1.79088
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run flowing-sweep-241 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/m3k0adns
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170851-m3k0adns/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ynvxvg76 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170902-ynvxvg76
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-242
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ynvxvg76
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 184.37it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 183.77it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 178.38it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 172.80it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 175.89it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 154.18it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 140.60it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:01, 130.89it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 140.11it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 154.76it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 162.82it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 170.87it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 177.71it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 180.49it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 183.73it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 185.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 167.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31388
wandb: sub_train_loss 1.7793
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run crimson-sweep-242 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ynvxvg76
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170902-ynvxvg76/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hbpqnygj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170917-hbpqnygj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-243
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/hbpqnygj
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 167.46it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 163.93it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 157.26it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 160.30it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 153.62it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 134.44it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 135.37it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:01, 150.28it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 158.70it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 164.91it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 168.72it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 172.89it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 178.50it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 182.85it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 184.32it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 186.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 167.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.33383
wandb: sub_train_loss 1.74524
wandb:       test_acc 0.26
wandb:      valid_acc 0.26
wandb: 
wandb: üöÄ View run flowing-sweep-243 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/hbpqnygj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170917-hbpqnygj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5e0yuz9s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170933-5e0yuz9s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-244
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5e0yuz9s
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 173.74it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 148.49it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 135.18it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 131.64it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 133.53it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 132.68it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 134.27it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 138.83it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:01, 138.68it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 140.36it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 145.02it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:00, 147.24it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 150.71it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 162.17it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 171.46it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 176.59it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 181.98it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 183.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 155.43it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.32459
wandb: sub_train_loss 1.7305
wandb:       test_acc 0.191
wandb:      valid_acc 0.196
wandb: 
wandb: üöÄ View run iconic-sweep-244 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5e0yuz9s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170933-5e0yuz9s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ql3bc73r with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_170948-ql3bc73r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-245
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ql3bc73r
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 175.56it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 171.61it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 169.00it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 169.69it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 170.23it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 176.24it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:00, 177.89it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:00<00:00, 174.77it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:00<00:00, 172.62it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 171.99it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 173.97it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 177.32it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 179.83it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 179.18it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 181.58it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 182.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 176.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.36891
wandb: sub_train_loss 1.68266
wandb:       test_acc 0.418
wandb:      valid_acc 0.42
wandb: 
wandb: üöÄ View run fragrant-sweep-245 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ql3bc73r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_170948-ql3bc73r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: os4wf1gc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171009-os4wf1gc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-246
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/os4wf1gc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 182.33it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 183.41it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 184.74it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 185.99it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 187.20it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:00, 188.32it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 189.15it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 189.11it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 187.87it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 182.91it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 180.77it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 179.43it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 179.31it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 179.34it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 174.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 182.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.36854
wandb: sub_train_loss 1.77273
wandb:       test_acc 0.425
wandb:      valid_acc 0.432
wandb: 
wandb: üöÄ View run distinctive-sweep-246 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/os4wf1gc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171009-os4wf1gc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: knghi8jf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171025-knghi8jf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-247
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/knghi8jf
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 165.49it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 155.29it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:01, 151.98it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 150.65it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:01, 149.80it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 149.07it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 148.67it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 148.15it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:01, 148.27it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:00, 146.78it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 146.62it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 146.92it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:01<00:00, 147.18it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 146.37it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 145.22it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 145.41it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 145.90it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 146.11it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 145.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 147.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31425
wandb: sub_train_loss 1.79194
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run good-sweep-247 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/knghi8jf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171025-knghi8jf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a5bj0t3w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171041-a5bj0t3w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-248
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/a5bj0t3w
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 156.91it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 153.90it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 153.95it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 154.60it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 155.69it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 158.23it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 156.34it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:01, 154.43it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:01, 153.26it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:00, 151.04it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 150.64it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 150.56it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 150.09it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 149.81it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 149.57it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 149.24it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 148.89it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 148.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 148.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 151.50it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31388
wandb: sub_train_loss 1.79008
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run smooth-sweep-248 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/a5bj0t3w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171041-a5bj0t3w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mvolde7e with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171052-mvolde7e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-249
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/mvolde7e
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 142.40it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 143.05it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 142.97it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 144.07it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 143.62it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 142.76it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 144.54it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 145.78it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 146.82it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 145.63it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:00, 146.63it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 144.70it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 148.07it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 150.27it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 151.53it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 152.47it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 152.99it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 153.09it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 152.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 148.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.013 MB of 0.017 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31241
wandb: sub_train_loss 1.74307
wandb:       test_acc 0.174
wandb:      valid_acc 0.182
wandb: 
wandb: üöÄ View run happy-sweep-249 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/mvolde7e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171052-mvolde7e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2xaz3cpi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171108-2xaz3cpi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-250
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/2xaz3cpi
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 131.60it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 142.78it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 147.02it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 146.98it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 141.39it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 139.67it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 137.41it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 138.13it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:01, 139.84it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 141.07it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:00, 140.90it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 144.12it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 146.65it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 148.34it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 149.29it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:01<00:00, 149.91it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 150.03it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 150.45it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 150.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 145.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31536
wandb: sub_train_loss 1.71984
wandb:       test_acc 0.188
wandb:      valid_acc 0.192
wandb: 
wandb: üöÄ View run fanciful-sweep-250 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/2xaz3cpi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171108-2xaz3cpi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: gubua55h with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171123-gubua55h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-251
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/gubua55h
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 145.43it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 148.04it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 150.61it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 151.79it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 151.68it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 153.32it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 153.53it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 153.67it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:01, 152.58it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:00, 148.13it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 142.97it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 139.23it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 138.23it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 141.89it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 142.27it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 144.01it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 146.99it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:01<00:00, 149.66it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 145.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 146.86it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñà‚ñÖ‚ñÉ‚ñÅ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñÑ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñà‚ñÑ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30281
wandb: sub_train_loss 1.73323
wandb:       test_acc 0.32
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run cerulean-sweep-251 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/gubua55h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171123-gubua55h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: l8f7axwv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171138-l8f7axwv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-252
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/l8f7axwv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:02, 140.50it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 141.94it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 142.32it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 147.89it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 143.43it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 142.85it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 141.41it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 142.98it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:01, 146.44it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:00, 148.54it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:00, 147.62it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 146.76it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 148.69it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 150.15it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 151.09it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 146.21it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 144.11it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 144.68it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 146.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 146.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.36965
wandb: sub_train_loss 1.67841
wandb:       test_acc 0.435
wandb:      valid_acc 0.434
wandb: 
wandb: üöÄ View run confused-sweep-252 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/l8f7axwv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171138-l8f7axwv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: k4sgxsk1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171153-k4sgxsk1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-253
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/k4sgxsk1
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 151.26it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 151.22it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 152.40it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 151.50it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 145.52it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 145.73it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 142.16it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 146.06it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 148.44it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 150.98it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 152.93it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 154.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 150.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.023 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.78498
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run clear-sweep-253 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/k4sgxsk1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171153-k4sgxsk1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7808g9a0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171210-7808g9a0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-254
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/7808g9a0
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 158.67it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 153.48it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 155.96it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 157.69it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:00, 158.48it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 159.29it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 159.08it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 152.64it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 153.38it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 155.68it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 155.39it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 149.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 153.78it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.7935
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run astral-sweep-254 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/7808g9a0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171210-7808g9a0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 04dnexgc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171222-04dnexgc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-255
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/04dnexgc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 153.31it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 155.73it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 156.94it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 157.89it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 158.09it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 158.31it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 156.32it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 153.03it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 130.25it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 126.50it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 120.85it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 118.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 122.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 136.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.78151
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run easy-sweep-255 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/04dnexgc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171222-04dnexgc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: s83oqfyw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171235-s83oqfyw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-256
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/s83oqfyw
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 141.97it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 138.35it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 142.67it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 145.04it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 146.90it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 147.69it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 148.89it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 147.93it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 147.66it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 148.25it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 148.37it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 148.59it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 148.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 147.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.7758
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run resilient-sweep-256 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/s83oqfyw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171235-s83oqfyw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: u0ccvjua with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171251-u0ccvjua
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-257
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/u0ccvjua
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 155.23it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 155.09it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 155.70it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 156.19it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 155.68it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 155.28it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 154.07it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 153.18it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 152.23it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 150.14it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 149.26it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 149.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 152.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.78567
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run fanciful-sweep-257 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/u0ccvjua
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171251-u0ccvjua/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dgiaw9qb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171307-dgiaw9qb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-258
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/dgiaw9qb
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 152.42it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 154.67it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 156.58it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 157.17it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 157.85it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 156.83it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 155.26it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 157.60it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 156.84it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 157.94it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 157.55it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 157.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 157.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.75935
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run royal-sweep-258 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/dgiaw9qb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171307-dgiaw9qb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: v02z207z with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171327-v02z207z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-259
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/v02z207z
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 123.54it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 121.21it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 123.71it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 123.70it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 124.35it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 124.58it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 115.66it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 108.58it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:01<00:00, 101.94it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:01<00:00, 94.47it/s]  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 92.92it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:01<00:00, 92.41it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 92.27it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 92.36it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 92.93it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 101.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 105.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.76299
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run rose-sweep-259 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/v02z207z
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171327-v02z207z/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mgq2oug9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171342-mgq2oug9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-260
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/mgq2oug9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 124.54it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 125.83it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 125.70it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 123.05it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 122.29it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 121.13it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 123.15it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 124.57it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 125.00it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 125.74it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 125.89it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 125.15it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 124.92it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 124.93it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 123.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 124.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.73961
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run quiet-sweep-260 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/mgq2oug9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171342-mgq2oug9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: y8wsy7rf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171404-y8wsy7rf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-261
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/y8wsy7rf
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 111.21it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 114.43it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:01, 118.37it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 122.16it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 124.59it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 126.01it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 126.85it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 126.67it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 126.57it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 125.70it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 125.75it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 125.67it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 125.81it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 125.87it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 125.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 124.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.76129
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run olive-sweep-261 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/y8wsy7rf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171404-y8wsy7rf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: crykcu93 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171418-crykcu93
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-262
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/crykcu93
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 127.81it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 127.57it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 124.92it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 122.26it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 121.28it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 123.62it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 121.40it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 121.02it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 120.89it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 123.02it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 123.43it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 123.85it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 124.42it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 124.47it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 122.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 123.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.77065
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run blooming-sweep-262 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/crykcu93
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171418-crykcu93/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 75tuhun4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171434-75tuhun4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-263
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/75tuhun4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 124.11it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 123.37it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 118.56it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 116.50it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 115.10it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:01, 114.11it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:01, 112.82it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 111.60it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 112.55it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:01<00:00, 113.45it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 112.47it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 110.41it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 114.17it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 117.75it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 120.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 121.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 116.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30318
wandb: sub_train_loss 1.74023
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run effortless-sweep-263 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/75tuhun4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171434-75tuhun4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 8f4qtkf5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171445-8f4qtkf5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-264
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/8f4qtkf5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 126.65it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 126.22it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 125.88it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 126.06it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 126.25it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 126.29it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 126.17it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 126.16it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:00<00:00, 125.81it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 123.95it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:01<00:00, 124.74it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 125.30it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 125.70it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 125.69it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 125.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 125.58it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.74176
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run gentle-sweep-264 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/8f4qtkf5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171445-8f4qtkf5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: c0dk3o54 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171459-c0dk3o54
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-265
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/c0dk3o54
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 99.07it/s] 10%|‚ñà         | 21/200 [00:00<00:01, 102.32it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 103.42it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:01, 104.04it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 102.24it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 102.00it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 99.04it/s]  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:01, 97.59it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:01, 96.87it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:01<00:00, 96.57it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:01<00:00, 95.92it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:01<00:00, 95.77it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:01<00:00, 94.52it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 91.73it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 92.04it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 92.51it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 93.01it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 92.98it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:02<00:00, 92.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 95.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.7473
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run glorious-sweep-265 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/c0dk3o54
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171459-c0dk3o54/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: y03s2een with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171515-y03s2een
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-266
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/y03s2een
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 96.92it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 98.48it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 99.94it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 99.78it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 101.10it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 102.17it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:01, 101.92it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:01, 103.26it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:01, 101.73it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:01<00:00, 100.61it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:01<00:00, 99.33it/s]  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 98.90it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [00:01<00:00, 99.71it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 100.79it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 101.91it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 102.59it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 103.11it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 103.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 101.45it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.76485
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run leafy-sweep-266 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/y03s2een
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171515-y03s2een/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jr1rswgw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171530-jr1rswgw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-267
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/jr1rswgw
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  4%|‚ñç         | 9/200 [00:00<00:02, 87.46it/s]  9%|‚ñâ         | 18/200 [00:00<00:02, 86.03it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:02, 86.35it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 87.25it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 85.74it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 85.81it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 85.98it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 86.41it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:01, 84.54it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:01<00:01, 84.55it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 88.05it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:01, 89.52it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 90.24it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 90.78it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 91.40it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 91.56it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 91.45it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 91.80it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:02<00:00, 92.41it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:02<00:00, 92.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 93.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 89.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.78553
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run different-sweep-267 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/jr1rswgw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171530-jr1rswgw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 89is8bog with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171541-89is8bog
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-268
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/89is8bog
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 100.81it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 101.20it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 102.07it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 102.28it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 102.58it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 102.77it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 101.49it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:01, 101.81it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 101.85it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 102.03it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 101.50it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 99.22it/s]  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 97.77it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 96.76it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 94.45it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 92.63it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 92.00it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 91.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 97.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.70703
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run whole-sweep-268 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/89is8bog
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171541-89is8bog/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: w352cl49 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171556-w352cl49
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-269
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/w352cl49
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 97.68it/s] 10%|‚ñà         | 21/200 [00:00<00:01, 100.74it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 101.43it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:01, 101.16it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 102.06it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 102.92it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 103.21it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:01, 103.01it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 102.22it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:01<00:00, 102.56it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 102.77it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 100.60it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 99.34it/s]  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 98.31it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 98.01it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 97.28it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 98.40it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 100.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 100.67it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.77377
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run peach-sweep-269 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/w352cl49
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171556-w352cl49/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: g7u3r08p with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171611-g7u3r08p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-270
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/g7u3r08p
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  4%|‚ñç         | 9/200 [00:00<00:02, 88.99it/s]  9%|‚ñâ         | 18/200 [00:00<00:02, 85.29it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 87.87it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 91.67it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:01, 95.42it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 97.74it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:01, 99.25it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:01, 100.32it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:01, 99.34it/s]  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:01<00:00, 100.49it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:01<00:00, 99.73it/s]  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:01<00:00, 100.10it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 100.69it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 101.33it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 101.37it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 100.90it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 98.81it/s]  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 97.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 97.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.77702
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run misty-sweep-270 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/g7u3r08p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171611-g7u3r08p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qqkye0g7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171622-qqkye0g7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-271
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/qqkye0g7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 154.31it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 148.99it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 146.25it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 151.02it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 150.48it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 134.59it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:00<00:01, 128.69it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 125.06it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:01<00:01, 121.35it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 118.27it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:01, 114.68it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:01, 114.76it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:01, 114.14it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 105.31it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 114.04it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 121.97it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 125.01it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:02<00:00, 128.14it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 135.39it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 137.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 139.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 128.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30502
wandb: sub_train_loss 1.65677
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run dutiful-sweep-271 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/qqkye0g7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171622-qqkye0g7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: q9kblqaf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171637-q9kblqaf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-272
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/q9kblqaf
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 155.29it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 156.14it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 157.53it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 158.28it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 129.02it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 114.92it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 114.36it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 112.91it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:01<00:01, 123.73it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 129.58it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 130.66it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 132.88it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 137.33it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 142.75it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 147.43it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 152.00it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 154.59it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 156.33it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 155.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 140.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30761
wandb: sub_train_loss 1.67704
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run worldly-sweep-272 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/q9kblqaf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171637-q9kblqaf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vnw6pc80 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171648-vnw6pc80
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-273
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/vnw6pc80
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 136.45it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 132.16it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 129.86it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 130.97it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 128.81it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 133.52it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 136.09it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 137.52it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:01, 138.06it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 139.82it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 140.66it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:00, 141.37it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 141.46it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 141.06it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 142.24it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 143.14it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 143.32it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 143.24it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:02<00:00, 143.08it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 142.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 139.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.68843
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run elated-sweep-273 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/vnw6pc80
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171648-vnw6pc80/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0h13lyit with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171702-0h13lyit
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-274
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0h13lyit
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 148.41it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 145.04it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 144.67it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 144.38it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 144.06it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 144.02it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 143.26it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 142.34it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 141.32it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 141.19it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 142.38it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 142.08it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 143.04it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 143.37it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 143.76it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 148.86it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 151.47it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 154.28it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 156.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 146.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.68077
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run iconic-sweep-274 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0h13lyit
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171702-0h13lyit/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: geoaumx7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171714-geoaumx7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-275
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/geoaumx7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 149.47it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 152.95it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 155.02it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 155.29it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 155.51it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 155.30it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 153.64it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 153.93it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:01, 154.26it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:00, 154.26it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 153.78it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 153.29it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 152.81it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 152.82it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 152.29it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 153.31it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 153.64it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 152.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 153.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.68994
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run trim-sweep-275 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/geoaumx7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171714-geoaumx7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 9bhz23v2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171728-9bhz23v2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-276
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/9bhz23v2
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 144.20it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 147.85it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 146.82it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 146.32it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 146.25it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 146.61it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 147.77it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 147.82it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:01, 146.47it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 146.67it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:00, 146.44it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 146.48it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 146.10it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 145.66it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:01<00:00, 144.99it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 144.07it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 140.83it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 140.04it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 138.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 143.57it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.67881
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run glamorous-sweep-276 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/9bhz23v2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171728-9bhz23v2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 70ejnucz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171743-70ejnucz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-277
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/70ejnucz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 113.04it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 112.97it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 113.38it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 113.54it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 113.60it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:02, 113.12it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 113.93it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 114.67it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 114.80it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 115.09it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 114.05it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 113.76it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 113.88it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 113.97it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 114.00it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 113.80it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 114.11it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 114.41it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 114.57it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 113.65it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 113.98it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 114.13it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 113.58it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 113.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 114.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 114.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.6471
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run sparkling-sweep-277 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/70ejnucz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171743-70ejnucz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: f0xpp09s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171753-f0xpp09s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-278
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/f0xpp09s
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 124.73it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 125.70it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 126.77it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 127.56it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 127.56it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 124.18it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 116.78it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 116.05it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:00<00:01, 118.94it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:01, 121.49it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 123.24it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 123.84it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 124.65it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 124.86it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 124.95it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 123.52it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 121.83it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 121.26it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:02<00:00, 121.50it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:02<00:00, 121.67it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 121.74it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 121.77it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 120.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 122.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb:      valid_acc ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.32201
wandb: sub_train_loss 1.59752
wandb:       test_acc 0.321
wandb:      valid_acc 0.32
wandb: 
wandb: üöÄ View run comic-sweep-278 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/f0xpp09s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171753-f0xpp09s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dkyszm2w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171809-dkyszm2w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-279
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/dkyszm2w
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 118.63it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 117.80it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:02, 121.61it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 120.33it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 120.11it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 121.98it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 113.48it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 103.27it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:01<00:01, 99.07it/s]  41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:01<00:01, 95.87it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:01<00:01, 91.72it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 100.54it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 105.11it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 108.19it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:01, 110.27it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 112.05it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 113.80it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 116.90it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:02<00:00, 118.95it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:02<00:00, 120.87it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:02<00:00, 122.24it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:02<00:00, 122.72it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:02<00:00, 121.26it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 120.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 113.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31869
wandb: sub_train_loss 1.62646
wandb:       test_acc 0.324
wandb:      valid_acc 0.32
wandb: 
wandb: üöÄ View run hearty-sweep-279 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/dkyszm2w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171809-dkyszm2w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: cn5kh3v7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171825-cn5kh3v7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-280
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/cn5kh3v7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 102.02it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 113.60it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 114.02it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 114.20it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 114.59it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 114.97it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 114.87it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 115.02it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 114.60it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 115.01it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 114.83it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 114.02it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 114.11it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 113.88it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 114.10it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 113.96it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 113.51it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 113.66it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 116.77it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:02<00:00, 118.61it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:02<00:00, 116.41it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 115.21it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 113.91it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:02<00:00, 113.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 114.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.45236
wandb: sub_train_loss 1.57209
wandb:       test_acc 0.451
wandb:      valid_acc 0.458
wandb: 
wandb: üöÄ View run dainty-sweep-280 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/cn5kh3v7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171825-cn5kh3v7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 15af7xdy with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171840-15af7xdy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-281
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/15af7xdy
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 106.29it/s]  8%|‚ñä         | 23/300 [00:00<00:02, 111.75it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:02, 111.97it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:02, 112.48it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:02, 113.38it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:02, 113.29it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 111.76it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 114.17it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 113.44it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:01<00:01, 114.55it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 114.33it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 114.64it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 113.51it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 113.51it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:01, 112.70it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 111.29it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 109.97it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 109.06it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:02<00:00, 109.15it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:02<00:00, 106.81it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:02<00:00, 105.57it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 108.28it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 112.78it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 115.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 118.06it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 112.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.65246
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run revived-sweep-281 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/15af7xdy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171840-15af7xdy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: matc217h with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171855-matc217h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-282
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/matc217h
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 124.43it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 124.23it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 123.44it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 121.58it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:02, 111.17it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:02, 111.10it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 112.56it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 114.61it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 114.53it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:01<00:01, 115.85it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:01<00:01, 116.33it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 116.23it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:01, 116.73it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:01, 116.73it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:00, 116.28it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 115.82it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 116.32it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 116.72it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:02<00:00, 116.63it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:02<00:00, 115.53it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:02<00:00, 115.71it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:02<00:00, 116.38it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:02<00:00, 115.65it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 115.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 116.00it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.43538
wandb: sub_train_loss 1.58259
wandb:       test_acc 0.429
wandb:      valid_acc 0.436
wandb: 
wandb: üöÄ View run happy-sweep-282 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/matc217h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171855-matc217h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: waqvrg8g with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171910-waqvrg8g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-283
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/waqvrg8g
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 106.39it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 101.52it/s] 11%|‚ñà         | 33/300 [00:00<00:02, 99.37it/s]  14%|‚ñà‚ñç        | 43/300 [00:00<00:02, 93.63it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:02, 92.10it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:02, 90.39it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:02, 88.95it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:02, 88.51it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:01<00:02, 89.21it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:01<00:02, 91.13it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:01<00:02, 91.76it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:01<00:01, 91.50it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 90.85it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 90.49it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 90.17it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 90.92it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:01, 92.22it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:01, 94.65it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:02<00:01, 96.19it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:02<00:01, 95.68it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:02<00:00, 95.38it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:02<00:00, 95.23it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:02<00:00, 95.15it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:02<00:00, 95.02it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:02<00:00, 94.80it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 94.78it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 94.81it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:03<00:00, 94.85it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:03<00:00, 94.94it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 93.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30318
wandb: sub_train_loss 1.58526
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run stilted-sweep-283 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/waqvrg8g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171910-waqvrg8g/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bu2sukwv with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171926-bu2sukwv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-284
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/bu2sukwv
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 100.44it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 101.08it/s] 11%|‚ñà         | 33/300 [00:00<00:02, 100.14it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:02, 98.69it/s]  18%|‚ñà‚ñä        | 54/300 [00:00<00:02, 96.57it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:02, 96.03it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:02, 97.40it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:02, 99.23it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:02, 99.90it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:01<00:01, 100.24it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:01<00:01, 100.51it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 99.90it/s]  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 99.13it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 100.28it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 100.86it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:01, 100.98it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:01<00:01, 100.85it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:01, 99.51it/s]  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:02<00:00, 98.20it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:02<00:00, 99.09it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:02<00:00, 100.00it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:02<00:00, 100.55it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:02<00:00, 100.90it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 101.39it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:02<00:00, 102.03it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 102.43it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 102.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 100.28it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.43907
wandb: sub_train_loss 1.51751
wandb:       test_acc 0.403
wandb:      valid_acc 0.402
wandb: 
wandb: üöÄ View run summer-sweep-284 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/bu2sukwv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171926-bu2sukwv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: w4w06pgc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171941-w4w06pgc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-285
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/w4w06pgc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 100.53it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 102.22it/s] 11%|‚ñà         | 33/300 [00:00<00:02, 102.56it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:02, 102.08it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:02, 102.02it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:02, 102.20it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:02, 102.00it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:02, 101.30it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:02, 99.96it/s]  37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:01, 98.84it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 98.03it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 98.87it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 99.39it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 99.98it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 100.25it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:01, 99.43it/s]  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:01, 99.01it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:01, 99.90it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:02<00:00, 99.77it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:02<00:00, 99.71it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 227/300 [00:02<00:00, 100.11it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:02<00:00, 99.96it/s]  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:02<00:00, 98.48it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:02<00:00, 97.87it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:02<00:00, 97.65it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 96.86it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 96.80it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:03<00:00, 96.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 99.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.66142
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run eternal-sweep-285 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/w4w06pgc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171941-w4w06pgc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mgehr9ef with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_171956-mgehr9ef
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-286
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/mgehr9ef
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 102.07it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 98.63it/s]  11%|‚ñà         | 32/300 [00:00<00:02, 96.43it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:02, 95.58it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 95.44it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:02, 94.95it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:02, 94.55it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:02, 94.74it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:02, 95.00it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:01<00:02, 96.83it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:01<00:01, 96.44it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:01<00:01, 95.23it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:01<00:01, 95.93it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 95.66it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 96.42it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 96.39it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:01, 96.60it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:01, 96.80it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:02<00:01, 96.80it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:02<00:01, 96.34it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:02<00:00, 96.34it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:02<00:00, 96.31it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:02<00:00, 95.84it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 244/300 [00:02<00:00, 97.86it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:02<00:00, 99.31it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 97.60it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 94.59it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 93.70it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:03<00:00, 94.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 95.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.36669
wandb: sub_train_loss 1.47613
wandb:       test_acc 0.338
wandb:      valid_acc 0.338
wandb: 
wandb: üöÄ View run youthful-sweep-286 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/mgehr9ef
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_171956-mgehr9ef/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mgaubvax with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172012-mgaubvax
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-287
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/mgaubvax
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 94.26it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 97.16it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 95.32it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 95.03it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 95.43it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 96.78it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 96.93it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 95.89it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 91.07it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 89.78it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:02, 88.99it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:01<00:02, 88.57it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:01<00:01, 88.17it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:01<00:01, 88.28it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 88.70it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 89.67it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 88.64it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 174/300 [00:01<00:01, 85.62it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:02<00:01, 81.95it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:02<00:01, 86.72it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:02<00:01, 86.96it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:02<00:01, 84.64it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:02<00:00, 85.54it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:02<00:00, 90.70it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:02<00:00, 94.36it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 96.28it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 97.13it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 98.39it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:03<00:00, 99.09it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:03<00:00, 100.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 92.31it/s] 
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñà‚ñá‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.33456
wandb: sub_train_loss 1.5336
wandb:       test_acc 0.321
wandb:      valid_acc 0.32
wandb: 
wandb: üöÄ View run smart-sweep-287 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/mgaubvax
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172012-mgaubvax/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: iiqryyds with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 64
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172027-iiqryyds
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-288
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/iiqryyds
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 100.97it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 101.28it/s] 11%|‚ñà         | 33/300 [00:00<00:02, 101.57it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:02, 99.01it/s]  18%|‚ñà‚ñä        | 54/300 [00:00<00:02, 96.97it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:02, 96.15it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:02, 95.63it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:02, 96.13it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:02, 96.72it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:01<00:02, 96.31it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:01<00:01, 97.12it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:01<00:01, 98.69it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:01<00:01, 99.68it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 100.92it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 101.56it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 101.97it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 102.32it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:01, 102.58it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 202/300 [00:02<00:00, 102.72it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:02<00:00, 102.78it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:02<00:00, 102.83it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:02<00:00, 101.90it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:02<00:00, 100.30it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:02<00:00, 98.89it/s]  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:02<00:00, 98.51it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 97.71it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:02<00:00, 96.76it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 96.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 99.04it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30428
wandb: sub_train_loss 1.58466
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run gallant-sweep-288 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/iiqryyds
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172027-iiqryyds/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0wgv4zfh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172042-0wgv4zfh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-289
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0wgv4zfh
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 202.36it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 200.58it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 196.21it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 198.48it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 206.22it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [00:00<00:00, 210.05it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:00<00:00, 208.57it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:00<00:00, 204.15it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:00<00:00, 201.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 204.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.7596
wandb: sub_train_loss 0.64249
wandb:       test_acc 0.617
wandb:      valid_acc 0.606
wandb: 
wandb: üöÄ View run pretty-sweep-289 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0wgv4zfh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172042-0wgv4zfh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: fcasrkkq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172056-fcasrkkq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-290
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/fcasrkkq
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 222.93it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:00, 220.61it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 219.46it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 219.38it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 219.20it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 219.73it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:00<00:00, 220.64it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:00<00:00, 220.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 220.78it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.75628
wandb: sub_train_loss 0.72409
wandb:       test_acc 0.742
wandb:      valid_acc 0.712
wandb: 
wandb: üöÄ View run pious-sweep-290 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/fcasrkkq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172056-fcasrkkq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: q0mu8d7j with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172119-q0mu8d7j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-291
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/q0mu8d7j
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:00, 233.01it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 235.00it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 236.62it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 226.86it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 227.14it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 231.21it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 234.23it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:00<00:00, 236.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 233.58it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.62555
wandb: sub_train_loss 1.12242
wandb:       test_acc 0.692
wandb:      valid_acc 0.68
wandb: 
wandb: üöÄ View run revived-sweep-291 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/q0mu8d7j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172119-q0mu8d7j/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: r3ycrl69 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172139-r3ycrl69
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-292
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/r3ycrl69
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 221.47it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:00, 215.83it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [00:00<00:00, 218.60it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 219.70it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 220.83it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 218.08it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:00<00:00, 216.94it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:00<00:00, 215.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 216.80it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÅ
wandb:       test_acc ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.60044
wandb: sub_train_loss 1.12716
wandb:       test_acc 0.689
wandb:      valid_acc 0.704
wandb: 
wandb: üöÄ View run jolly-sweep-292 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/r3ycrl69
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172139-r3ycrl69/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rz6gnwhc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172154-rz6gnwhc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-293
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/rz6gnwhc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:00, 231.16it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 235.70it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 225.54it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 220.22it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 220.07it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 220.95it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:00<00:00, 218.26it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:00<00:00, 219.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 222.31it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.73634
wandb: sub_train_loss 0.81797
wandb:       test_acc 0.562
wandb:      valid_acc 0.578
wandb: 
wandb: üöÄ View run tough-sweep-293 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/rz6gnwhc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172154-rz6gnwhc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: b4sa23rk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172210-b4sa23rk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-294
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/b4sa23rk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 212.12it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:00, 213.32it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 214.18it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 212.28it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 213.14it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 213.97it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 214.68it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:00<00:00, 215.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:00<00:00, 218.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 215.38it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.74077
wandb: sub_train_loss 0.8616
wandb:       test_acc 0.563
wandb:      valid_acc 0.564
wandb: 
wandb: üöÄ View run wandering-sweep-294 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/b4sa23rk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172210-b4sa23rk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 11pbz7yu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172225-11pbz7yu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-295
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/11pbz7yu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 171.53it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 169.17it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 169.02it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 170.29it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 177.10it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 180.54it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 182.53it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:00<00:00, 182.85it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:00<00:00, 182.49it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 170.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 172.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÉ
wandb:       test_acc ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñÜ‚ñá‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.29838
wandb: sub_train_loss 1.51258
wandb:       test_acc 0.252
wandb:      valid_acc 0.23
wandb: 
wandb: üöÄ View run soft-sweep-295 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/11pbz7yu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172225-11pbz7yu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ba3q3rva with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172241-ba3q3rva
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-296
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ba3q3rva
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 149.51it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 149.60it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 147.33it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 148.25it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 142.51it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 144.90it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 146.43it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 147.90it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 151.39it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:01<00:00, 154.53it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 155.27it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 155.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 150.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÜ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30502
wandb: sub_train_loss 1.77759
wandb:       test_acc 0.347
wandb:      valid_acc 0.376
wandb: 
wandb: üöÄ View run cosmic-sweep-296 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ba3q3rva
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172241-ba3q3rva/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: brgxjsed with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172252-brgxjsed
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-297
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/brgxjsed
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 178.09it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 177.31it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 176.48it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 179.81it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 184.56it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 186.04it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:00<00:00, 187.93it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 188.67it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:00<00:00, 189.54it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 191.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 186.82it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.25886
wandb: sub_train_loss 1.73812
wandb:       test_acc 0.414
wandb:      valid_acc 0.434
wandb: 
wandb: üöÄ View run woven-sweep-297 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/brgxjsed
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172252-brgxjsed/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jbbrhlhh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172306-jbbrhlhh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-298
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/jbbrhlhh
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:01, 180.13it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 179.82it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 180.51it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 180.41it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 180.75it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 180.82it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 180.79it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 181.37it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 179.29it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 176.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 178.85it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb: sub_train_loss ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.26625
wandb: sub_train_loss 1.84163
wandb:       test_acc 0.511
wandb:      valid_acc 0.542
wandb: 
wandb: üöÄ View run tough-sweep-298 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/jbbrhlhh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172306-jbbrhlhh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5w8ufl44 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172318-5w8ufl44
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-299
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5w8ufl44
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 179.69it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:00, 185.26it/s] 28%|‚ñà‚ñà‚ñä       | 56/200 [00:00<00:00, 184.98it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 184.08it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 179.85it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 176.37it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 176.72it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 178.02it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:00<00:00, 180.67it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 179.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 180.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.46123
wandb: sub_train_loss 1.38468
wandb:       test_acc 0.453
wandb:      valid_acc 0.484
wandb: 
wandb: üöÄ View run azure-sweep-299 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5w8ufl44
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172318-5w8ufl44/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: f7g5wq6o with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172339-f7g5wq6o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-300
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/f7g5wq6o
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 184.68it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 181.18it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 184.43it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 185.72it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 184.43it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 184.24it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 183.45it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:00<00:00, 181.40it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 179.85it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 175.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 177.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÖ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.37001
wandb: sub_train_loss 1.6572
wandb:       test_acc 0.439
wandb:      valid_acc 0.432
wandb: 
wandb: üöÄ View run stilted-sweep-300 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/f7g5wq6o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172339-f7g5wq6o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: r0blo9bq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172402-r0blo9bq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-301
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/r0blo9bq
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 153.44it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 153.51it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 149.42it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 144.10it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 137.72it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 139.47it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 141.67it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 143.66it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 143.66it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 142.39it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 143.13it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 144.15it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 126.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 138.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñá‚ñÖ‚ñÅ‚ñÉ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:       test_acc ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñà‚ñà‚ñá‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31019
wandb: sub_train_loss 1.84264
wandb:       test_acc 0.233
wandb:      valid_acc 0.208
wandb: 
wandb: üöÄ View run legendary-sweep-301 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/r0blo9bq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172402-r0blo9bq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: zdr6gjfg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172422-zdr6gjfg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-302
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/zdr6gjfg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 137.12it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 130.06it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:01, 138.35it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 141.68it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 143.49it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 144.45it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [00:00<00:00, 145.46it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 141.94it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 142.49it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 142.94it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 140.08it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 135.76it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 133.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 138.62it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÉ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÖ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ
wandb:       test_acc ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.19978
wandb: sub_train_loss 1.81422
wandb:       test_acc 0.251
wandb:      valid_acc 0.256
wandb: 
wandb: üöÄ View run confused-sweep-302 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/zdr6gjfg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172422-zdr6gjfg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: cndz1gaa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172437-cndz1gaa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-303
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/cndz1gaa
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 151.72it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 147.39it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 145.36it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 146.49it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 146.22it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 144.34it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 143.56it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 143.99it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:00<00:00, 138.13it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 136.36it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 128.54it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 127.84it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 129.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 137.14it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñà
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30724
wandb: sub_train_loss 2.01184
wandb:       test_acc 0.319
wandb:      valid_acc 0.314
wandb: 
wandb: üöÄ View run dainty-sweep-303 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/cndz1gaa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172437-cndz1gaa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hgo0ralk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172448-hgo0ralk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-304
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/hgo0ralk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 133.13it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 131.92it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 115.47it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:01, 125.78it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 123.84it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:00, 123.73it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 126.14it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 122.73it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 122.94it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 126.24it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 129.49it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 133.34it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 135.50it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 135.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 128.78it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.32644
wandb: sub_train_loss 1.67444
wandb:       test_acc 0.292
wandb:      valid_acc 0.336
wandb: 
wandb: üöÄ View run twilight-sweep-304 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/hgo0ralk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172448-hgo0ralk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bfj2jcdu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172503-bfj2jcdu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-305
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/bfj2jcdu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  7%|‚ñã         | 14/200 [00:00<00:01, 135.62it/s] 14%|‚ñà‚ñç        | 28/200 [00:00<00:01, 125.84it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 121.09it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 113.79it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 114.85it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 121.06it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 121.75it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 119.81it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 128.18it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:01<00:00, 134.36it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 141.39it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 146.39it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 149.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 151.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 134.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb: sub_train_loss ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ
wandb:      valid_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.23264
wandb: sub_train_loss 1.81639
wandb:       test_acc 0.151
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run skilled-sweep-305 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/bfj2jcdu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172503-bfj2jcdu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 02o2252w with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172518-02o2252w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-306
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/02o2252w
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 156.93it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 156.39it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 156.28it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 153.45it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 151.54it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 149.97it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 149.66it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 151.95it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 152.71it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 151.49it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 150.50it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:01<00:00, 149.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 151.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÖ‚ñÜ‚ñÉ‚ñÑ‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÑ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31204
wandb: sub_train_loss 1.6531
wandb:       test_acc 0.267
wandb:      valid_acc 0.274
wandb: 
wandb: üöÄ View run volcanic-sweep-306 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/02o2252w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172518-02o2252w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: aaqpfc77 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172539-aaqpfc77
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-307
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/aaqpfc77
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 226.63it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 231.95it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:00, 233.60it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:00, 234.69it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:00, 233.64it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:00, 233.45it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 232.40it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:00<00:00, 234.11it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:00<00:00, 234.06it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 233.29it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 232.50it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 232.00it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 232.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÑ‚ñá‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.69387
wandb: sub_train_loss 0.98712
wandb:       test_acc 0.592
wandb:      valid_acc 0.582
wandb: 
wandb: üöÄ View run dazzling-sweep-307 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/aaqpfc77
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172539-aaqpfc77/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2yfbckvt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172551-2yfbckvt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-308
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/2yfbckvt
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 234.39it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 222.18it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 221.32it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:00, 224.10it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:00, 226.47it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 228.88it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:00<00:00, 198.11it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:00<00:00, 202.43it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:00<00:00, 208.22it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 207.20it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 209.07it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 195.43it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:01<00:00, 199.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 208.88it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÉ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.55096
wandb: sub_train_loss 1.25506
wandb:       test_acc 0.607
wandb:      valid_acc 0.59
wandb: 
wandb: üöÄ View run fancy-sweep-308 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/2yfbckvt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172551-2yfbckvt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qq3tg6cb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172606-qq3tg6cb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-309
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/qq3tg6cb
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 229.53it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 224.14it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 216.85it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:00, 212.74it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:00, 213.04it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:00, 213.44it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 214.11it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 214.12it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:00<00:00, 214.36it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 216.21it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 213.62it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 212.57it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 185.74it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 203.23it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.64254
wandb: sub_train_loss 1.01728
wandb:       test_acc 0.762
wandb:      valid_acc 0.77
wandb: 
wandb: üöÄ View run dandy-sweep-309 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/qq3tg6cb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172606-qq3tg6cb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rpymdgax with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172617-rpymdgax
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-310
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/rpymdgax
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 208.96it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 216.58it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 219.54it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:00, 218.98it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:00, 218.39it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:00, 216.56it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 216.79it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:00<00:00, 220.20it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:00<00:00, 227.62it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 231.67it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:01<00:00, 233.59it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 226.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:01<00:00, 225.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 223.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.72009
wandb: sub_train_loss 1.00237
wandb:       test_acc 0.726
wandb:      valid_acc 0.76
wandb: 
wandb: üöÄ View run scarlet-sweep-310 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/rpymdgax
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172617-rpymdgax/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: c6aqyz7v with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172638-c6aqyz7v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-311
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/c6aqyz7v
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 229.39it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 229.12it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 227.28it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:00, 223.98it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:00, 216.15it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 194.17it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:00<00:00, 197.70it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:00<00:00, 198.14it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:00<00:00, 195.08it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 198.20it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 198.36it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 200.52it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 202.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 205.16it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.70384
wandb: sub_train_loss 0.90631
wandb:       test_acc 0.615
wandb:      valid_acc 0.64
wandb: 
wandb: üöÄ View run scarlet-sweep-311 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/c6aqyz7v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172638-c6aqyz7v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pi3wym1a with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172652-pi3wym1a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-312
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/pi3wym1a
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 21/300 [00:00<00:01, 208.36it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:01, 211.70it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:01, 219.16it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:00, 216.28it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:00, 212.49it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 210.82it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:00<00:00, 211.08it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 213.65it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:00<00:00, 214.58it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 213.12it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 211.22it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 211.15it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 218.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 215.10it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.017 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.79764
wandb: sub_train_loss 0.59884
wandb:       test_acc 0.793
wandb:      valid_acc 0.784
wandb: 
wandb: üöÄ View run glamorous-sweep-312 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/pi3wym1a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172652-pi3wym1a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 268rt0mt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172708-268rt0mt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-313
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/268rt0mt
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 170.45it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 170.74it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:01, 172.75it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:01, 172.45it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 173.17it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 174.94it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:00, 174.28it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 175.95it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:00<00:00, 179.47it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 181.54it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 180.98it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 181.70it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 179.71it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 177.48it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 177.19it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 175.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 176.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñÜ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñà‚ñá‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.20495
wandb: sub_train_loss 1.89351
wandb:       test_acc 0.162
wandb:      valid_acc 0.196
wandb: 
wandb: üöÄ View run blooming-sweep-313 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/268rt0mt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172708-268rt0mt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yd73lla5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172723-yd73lla5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-314
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/yd73lla5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 194.22it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 190.25it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 189.47it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 190.24it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:00<00:01, 190.82it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 190.61it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:00, 191.88it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 192.36it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:00<00:00, 190.17it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 184.06it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 178.12it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 174.67it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 173.66it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 173.34it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:01<00:00, 173.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 182.05it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.020 MB of 0.023 MB uploadedwandb: - 0.020 MB of 0.023 MB uploadedwandb: \ 0.020 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñá‚ñÜ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.37962
wandb: sub_train_loss 1.51684
wandb:       test_acc 0.55
wandb:      valid_acc 0.542
wandb: 
wandb: üöÄ View run sunny-sweep-314 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/yd73lla5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172723-yd73lla5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 291gyk7y with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172738-291gyk7y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-315
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/291gyk7y
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 180.87it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 181.95it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 184.22it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 174.92it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 176.41it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 177.47it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:00, 181.13it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:00<00:00, 184.49it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:00<00:00, 185.74it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 187.12it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 188.62it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 188.92it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 188.42it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:01<00:00, 188.39it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 185.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 183.81it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ
wandb: sub_train_loss ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÜ‚ñà‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñá‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.42356
wandb: sub_train_loss 1.47091
wandb:       test_acc 0.396
wandb:      valid_acc 0.434
wandb: 
wandb: üöÄ View run peachy-sweep-315 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/291gyk7y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172738-291gyk7y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: eb96ubk5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172752-eb96ubk5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-316
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/eb96ubk5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 180.55it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 177.43it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 179.41it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 178.75it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 180.58it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 182.38it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:00<00:00, 184.81it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 186.62it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 187.71it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 187.86it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 186.97it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 110.45it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 124.05it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 136.37it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 147.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 160.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñá‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÖ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.5192
wandb: sub_train_loss 1.31397
wandb:       test_acc 0.439
wandb:      valid_acc 0.45
wandb: 
wandb: üöÄ View run solar-sweep-316 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/eb96ubk5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172752-eb96ubk5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1hgaam83 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172804-1hgaam83
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-317
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/1hgaam83
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 173.08it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:01, 169.67it/s] 18%|‚ñà‚ñä        | 53/300 [00:00<00:01, 161.13it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:01, 162.84it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 164.29it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 165.99it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 165.67it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:00<00:00, 163.08it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:00<00:00, 163.22it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 161.61it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 161.39it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 160.73it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 161.30it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 158.87it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 156.82it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 154.61it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 153.52it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 159.84it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.4579
wandb: sub_train_loss 1.30787
wandb:       test_acc 0.616
wandb:      valid_acc 0.636
wandb: 
wandb: üöÄ View run lucky-sweep-317 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/1hgaam83
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172804-1hgaam83/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qr38a8h6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172819-qr38a8h6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-318
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/qr38a8h6
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 187.65it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 187.56it/s] 19%|‚ñà‚ñâ        | 57/300 [00:00<00:01, 187.94it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 190.07it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 184.10it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:00, 186.68it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 188.35it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:00<00:00, 189.56it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:00<00:00, 186.54it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 183.75it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 178.97it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 176.86it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 176.03it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 172.95it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 171.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 180.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.53877
wandb: sub_train_loss 1.34396
wandb:       test_acc 0.568
wandb:      valid_acc 0.586
wandb: 
wandb: üöÄ View run apricot-sweep-318 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/qr38a8h6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172819-qr38a8h6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 1mxp70yw with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172839-1mxp70yw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-319
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/1mxp70yw
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 154.90it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 156.24it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 156.64it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 157.64it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 150.91it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 142.92it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 136.79it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 132.54it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:00<00:01, 133.44it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 133.73it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:00, 134.06it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 134.21it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 134.20it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 132.72it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 137.18it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 143.69it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 146.92it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 150.49it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 153.10it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 143.65it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñà‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñà‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñá‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31241
wandb: sub_train_loss 1.55234
wandb:       test_acc 0.187
wandb:      valid_acc 0.178
wandb: 
wandb: üöÄ View run absurd-sweep-319 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/1mxp70yw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172839-1mxp70yw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: m8vukq94 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172851-m8vukq94
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-320
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/m8vukq94
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 162.32it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:02, 131.12it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 119.81it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 123.34it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 124.45it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 122.11it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 121.80it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 134.95it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:01<00:01, 141.66it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 144.63it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:00, 148.64it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 150.46it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 152.73it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 154.79it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 156.97it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 158.94it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:01<00:00, 158.40it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 157.99it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 147.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 143.25it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÜ‚ñÑ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb:       test_acc ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.3305
wandb: sub_train_loss 1.72891
wandb:       test_acc 0.27
wandb:      valid_acc 0.272
wandb: 
wandb: üöÄ View run fallen-sweep-320 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/m8vukq94
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172851-m8vukq94/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ezpqw1qi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172907-ezpqw1qi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-321
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ezpqw1qi
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 144.80it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 144.43it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 143.52it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 144.31it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 145.66it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 146.87it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 147.58it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:01, 148.88it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:01, 148.58it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 147.98it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:00, 145.57it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 144.71it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 144.11it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 143.60it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 141.71it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 140.98it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 138.87it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 136.99it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:01<00:00, 132.22it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 134.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 141.78it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÑ
wandb: sub_train_loss ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÑ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÑ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.27733
wandb: sub_train_loss 1.74641
wandb:       test_acc 0.247
wandb:      valid_acc 0.264
wandb: 
wandb: üöÄ View run floral-sweep-321 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ezpqw1qi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172907-ezpqw1qi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bskok9bt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172922-bskok9bt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-322
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/bskok9bt
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 146.20it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 152.12it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 147.64it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 145.21it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 143.92it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 139.56it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:00<00:01, 137.96it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 137.43it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:00<00:01, 136.77it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 135.18it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:01, 134.58it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 133.45it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 134.11it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 133.69it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 133.54it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 133.94it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 137.44it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 139.22it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 135.09it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:02<00:00, 138.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 138.24it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÅ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.52585
wandb: sub_train_loss 1.22032
wandb:       test_acc 0.556
wandb:      valid_acc 0.544
wandb: 
wandb: üöÄ View run stilted-sweep-322 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/bskok9bt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172922-bskok9bt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hhzaupfq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172938-hhzaupfq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-323
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/hhzaupfq
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 148.54it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 142.89it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 140.31it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 144.10it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 146.01it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 147.59it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 148.67it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 149.37it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:01, 151.85it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:00, 153.05it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 154.82it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 156.12it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 156.20it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 157.91it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 158.09it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 158.19it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 158.94it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 158.20it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 153.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñà‚ñà‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ
wandb:      valid_acc ‚ñÜ‚ñÜ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñà‚ñà‚ñÖ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31684
wandb: sub_train_loss 1.67781
wandb:       test_acc 0.185
wandb:      valid_acc 0.21
wandb: 
wandb: üöÄ View run fine-sweep-323 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/hhzaupfq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172938-hhzaupfq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: f4c2xz4a with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_172952-f4c2xz4a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-324
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/f4c2xz4a
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 128.45it/s]  9%|‚ñâ         | 27/300 [00:00<00:02, 130.66it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 131.85it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 132.39it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 133.93it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 136.35it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 136.22it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 136.64it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 138.22it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:01<00:01, 145.15it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:00, 149.97it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 152.40it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 154.11it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 155.45it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 156.32it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 158.08it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 159.32it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:01<00:00, 159.36it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 160.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 148.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.49298
wandb: sub_train_loss 1.29511
wandb:       test_acc 0.471
wandb:      valid_acc 0.486
wandb: 
wandb: üöÄ View run tough-sweep-324 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/f4c2xz4a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_172952-f4c2xz4a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qu6qhv03 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173008-qu6qhv03
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-325
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/qu6qhv03
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 149.05it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 151.72it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:00, 153.04it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 154.06it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 154.24it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 153.97it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 151.96it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 150.46it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 147.31it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 147.12it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 149.73it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 150.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 151.10it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.68575
wandb: sub_train_loss 1.00781
wandb:       test_acc 0.69
wandb:      valid_acc 0.684
wandb: 
wandb: üöÄ View run easy-sweep-325 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/qu6qhv03
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173008-qu6qhv03/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mz200igx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173019-mz200igx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-326
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/mz200igx
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 144.46it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 148.54it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:01, 148.56it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 149.79it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 146.31it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 145.34it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 148.40it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 146.91it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 146.14it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 145.74it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 144.14it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 142.76it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 141.41it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 144.94it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñÑ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.60266
wandb: sub_train_loss 1.31252
wandb:       test_acc 0.564
wandb:      valid_acc 0.574
wandb: 
wandb: üöÄ View run dashing-sweep-326 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/mz200igx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173019-mz200igx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2hlho4z3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173034-2hlho4z3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-327
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/2hlho4z3
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 142.19it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 148.33it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 152.51it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 153.55it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 155.81it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 156.55it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 154.56it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 153.55it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 152.60it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 150.15it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 147.89it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 144.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 149.36it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÇ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.52843
wandb: sub_train_loss 1.96852
wandb:       test_acc 0.502
wandb:      valid_acc 0.508
wandb: 
wandb: üöÄ View run honest-sweep-327 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/2hlho4z3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173034-2hlho4z3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 7dnlfrk4 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173049-7dnlfrk4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-328
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/7dnlfrk4
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 158.82it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 158.43it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 158.91it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 158.44it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 158.70it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 159.30it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 160.03it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 160.26it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:00<00:00, 158.15it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 157.54it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 158.83it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [00:01<00:00, 158.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 158.90it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.82681
wandb: sub_train_loss 0.57128
wandb:       test_acc 0.772
wandb:      valid_acc 0.77
wandb: 
wandb: üöÄ View run fearless-sweep-328 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/7dnlfrk4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173049-7dnlfrk4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 77dk59yt with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173100-77dk59yt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-329
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/77dk59yt
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 155.75it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 155.43it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 157.44it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 159.52it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 160.64it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 161.10it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 160.11it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 161.48it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 161.28it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 159.04it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 155.64it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 141.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 153.91it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.58789
wandb: sub_train_loss 1.13142
wandb:       test_acc 0.527
wandb:      valid_acc 0.546
wandb: 
wandb: üöÄ View run efficient-sweep-329 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/77dk59yt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173100-77dk59yt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: t2ve85te with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173115-t2ve85te
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-330
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/t2ve85te
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 147.23it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 152.58it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:00, 154.33it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 154.54it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 155.10it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 156.04it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 156.13it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 155.81it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [00:00<00:00, 155.04it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 154.61it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 154.23it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 153.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 154.34it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.63035
wandb: sub_train_loss 1.65078
wandb:       test_acc 0.588
wandb:      valid_acc 0.602
wandb: 
wandb: üöÄ View run stoic-sweep-330 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/t2ve85te
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173115-t2ve85te/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: sxju4ulc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173126-sxju4ulc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-331
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/sxju4ulc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 109.13it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 116.31it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:01, 120.11it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 122.24it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 123.03it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 123.78it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 124.44it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 124.83it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:00<00:00, 123.79it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 123.69it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 121.64it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 119.67it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 118.46it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 116.24it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 114.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 119.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñà‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñá‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñÜ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.44682
wandb: sub_train_loss 1.3252
wandb:       test_acc 0.458
wandb:      valid_acc 0.458
wandb: 
wandb: üöÄ View run rural-sweep-331 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/sxju4ulc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173126-sxju4ulc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: x5kgumiu with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173147-x5kgumiu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-332
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/x5kgumiu
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 116.20it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 91.18it/s]  17%|‚ñà‚ñã        | 34/200 [00:00<00:02, 80.26it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:02, 78.05it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 81.01it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 87.35it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:01, 91.77it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 90.94it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:01<00:01, 95.03it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:01<00:00, 99.12it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:01<00:00, 103.47it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 108.95it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 113.31it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 115.75it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 118.47it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 120.38it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 121.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 103.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÉ‚ñÅ‚ñÇ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÉ‚ñá‚ñà‚ñá‚ñÑ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30724
wandb: sub_train_loss 2.11704
wandb:       test_acc 0.276
wandb:      valid_acc 0.274
wandb: 
wandb: üöÄ View run flowing-sweep-332 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/x5kgumiu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173147-x5kgumiu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: iq96x76v with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173201-iq96x76v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-333
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/iq96x76v
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 118.98it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 113.89it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:01, 113.55it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:01, 113.31it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:01, 113.36it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:01, 113.36it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:01, 113.42it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 113.95it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 114.60it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:01<00:00, 116.97it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:01<00:00, 114.89it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 113.33it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 109.48it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 106.79it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 107.13it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 100.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 108.41it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÖ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñá‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÉ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñÜ‚ñÑ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñÜ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.4664
wandb: sub_train_loss 1.43763
wandb:       test_acc 0.417
wandb:      valid_acc 0.436
wandb: 
wandb: üöÄ View run sparkling-sweep-333 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/iq96x76v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173201-iq96x76v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bl5kzuc8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173213-bl5kzuc8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-334
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/bl5kzuc8
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 117.83it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 117.52it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 117.19it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 115.93it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 115.00it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 114.81it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 117.04it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 116.67it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 114.88it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 115.07it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:01<00:00, 114.73it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:01<00:00, 114.19it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 113.79it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 113.32it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [00:01<00:00, 113.25it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 113.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 114.60it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.64993
wandb: sub_train_loss 1.05126
wandb:       test_acc 0.623
wandb:      valid_acc 0.656
wandb: 
wandb: üöÄ View run curious-sweep-334 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/bl5kzuc8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173213-bl5kzuc8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ierstyid with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173228-ierstyid
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-335
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ierstyid
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 103.08it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:01, 109.01it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:01, 111.76it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 113.24it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:01, 113.50it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:01, 113.85it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [00:00<00:01, 112.46it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 111.01it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 109.82it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:01<00:00, 110.17it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 108.74it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 108.33it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 108.04it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 107.73it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 108.05it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 108.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 109.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 109.92it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÑ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñà‚ñá‚ñÑ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÑ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.49225
wandb: sub_train_loss 1.5831
wandb:       test_acc 0.476
wandb:      valid_acc 0.492
wandb: 
wandb: üöÄ View run effortless-sweep-335 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ierstyid
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173228-ierstyid/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: j6b4jm5c with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173242-j6b4jm5c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-336
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/j6b4jm5c
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 116.11it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 121.26it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 121.89it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 116.17it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 118.10it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 119.55it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [00:00<00:00, 119.26it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:00<00:00, 118.34it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [00:00<00:00, 115.75it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:01<00:00, 114.05it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 111.78it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:01<00:00, 110.86it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 109.38it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 109.42it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 109.35it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 108.92it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 113.52it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñÉ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30871
wandb: sub_train_loss 1.8985
wandb:       test_acc 0.321
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run breezy-sweep-336 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/j6b4jm5c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173242-j6b4jm5c/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: xq8lhg7s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173303-xq8lhg7s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-337
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/xq8lhg7s
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 99.04it/s] 10%|‚ñà         | 21/200 [00:00<00:01, 100.60it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 100.97it/s] 22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:01, 101.76it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:01, 100.95it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 101.75it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 101.96it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:01, 99.34it/s]  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:01, 97.30it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:01<00:00, 96.19it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:01<00:00, 95.81it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:01<00:00, 96.23it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 97.79it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 97.92it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 89.74it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 91.71it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 92.87it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 94.16it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:02<00:00, 94.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 96.60it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÜ‚ñà‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÇ‚ñÅ‚ñá‚ñÑ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñá‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÇ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.34417
wandb: sub_train_loss 1.93189
wandb:       test_acc 0.339
wandb:      valid_acc 0.348
wandb: 
wandb: üöÄ View run fluent-sweep-337 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/xq8lhg7s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173303-xq8lhg7s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: dzdvxg1c with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173318-dzdvxg1c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-338
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/dzdvxg1c
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  4%|‚ñç         | 9/200 [00:00<00:02, 89.28it/s] 10%|‚ñâ         | 19/200 [00:00<00:01, 90.99it/s] 14%|‚ñà‚ñç        | 29/200 [00:00<00:01, 90.88it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 89.55it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 88.93it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 92.09it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:01, 94.29it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 95.93it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:01, 95.96it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:01<00:01, 96.15it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:01<00:00, 97.25it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:01<00:00, 95.33it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 95.02it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 94.38it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 94.70it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 96.92it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 96.79it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 95.30it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:02<00:00, 94.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:02<00:00, 93.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 94.14it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÖ‚ñá‚ñÉ‚ñÅ‚ñÇ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñà‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 2.33179
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run sparkling-sweep-338 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/dzdvxg1c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173318-dzdvxg1c/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6v5bx2n0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173333-6v5bx2n0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-339
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/6v5bx2n0
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 94.65it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 92.73it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 90.57it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 90.44it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 90.70it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 90.48it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 90.76it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 90.71it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 90.93it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:01<00:01, 90.74it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 90.86it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 90.50it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 91.70it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 91.68it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 90.12it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 88.07it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 80.37it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:02<00:00, 75.97it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:02<00:00, 76.10it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:02<00:00, 76.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 85.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ
wandb: sub_train_loss ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.33013
wandb: sub_train_loss 1.60947
wandb:       test_acc 0.319
wandb:      valid_acc 0.356
wandb: 
wandb: üöÄ View run devout-sweep-339 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/6v5bx2n0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173333-6v5bx2n0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 1o3wi8yp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173345-1o3wi8yp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-340
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/1o3wi8yp
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  4%|‚ñç         | 9/200 [00:00<00:02, 89.11it/s]  9%|‚ñâ         | 18/200 [00:00<00:02, 89.21it/s] 14%|‚ñà‚ñé        | 27/200 [00:00<00:01, 89.25it/s] 18%|‚ñà‚ñä        | 37/200 [00:00<00:01, 90.10it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 91.65it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 94.71it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [00:00<00:01, 95.20it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 95.01it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:01, 94.49it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:01<00:01, 96.02it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:01<00:00, 97.29it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:01<00:00, 98.07it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 98.63it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 99.13it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 99.37it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 99.57it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 99.68it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 98.40it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:02<00:00, 97.43it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 96.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÜ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÖ‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÅ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÜ‚ñà‚ñá‚ñÇ‚ñÇ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÅ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñà‚ñÜ‚ñÇ‚ñÅ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.70594
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run brisk-sweep-340 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/1o3wi8yp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173345-1o3wi8yp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: iqy08tw5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173400-iqy08tw5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-341
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/iqy08tw5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 101.37it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 102.92it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 102.94it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 103.22it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 103.73it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 103.99it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 102.06it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:01, 102.66it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 101.96it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:01<00:00, 99.77it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 97.62it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 95.97it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [00:01<00:00, 94.94it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 94.33it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 94.16it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 93.64it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 93.85it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 95.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 95.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 98.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñà‚ñÉ‚ñÅ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÉ
wandb: sub_train_loss ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà‚ñÖ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñà‚ñÑ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÉ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÑ‚ñÜ‚ñà‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.2921
wandb: sub_train_loss 1.86823
wandb:       test_acc 0.268
wandb:      valid_acc 0.29
wandb: 
wandb: üöÄ View run noble-sweep-341 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/iqy08tw5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173400-iqy08tw5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 23dsnw2i with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173414-23dsnw2i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-342
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/23dsnw2i
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 95.04it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 96.50it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 98.76it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 101.06it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:01, 101.89it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 102.24it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:01, 102.74it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:01, 103.13it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [00:00<00:00, 103.31it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:01<00:00, 103.67it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:01<00:00, 101.87it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:01<00:00, 102.31it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 102.10it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 102.65it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 102.51it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 102.75it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [00:01<00:00, 102.89it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 100.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 101.70it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.25775
wandb: sub_train_loss 1.68736
wandb:       test_acc 0.267
wandb:      valid_acc 0.278
wandb: 
wandb: üöÄ View run serene-sweep-342 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/23dsnw2i
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173414-23dsnw2i/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5vfrw3ya with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173426-5vfrw3ya
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-343
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5vfrw3ya
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 161.06it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 162.06it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 161.91it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 163.10it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 163.75it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 163.72it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 161.27it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:01, 160.66it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 159.21it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 159.75it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:00, 160.35it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 160.86it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 161.07it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 161.34it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 160.89it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 158.05it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 154.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 159.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.66581
wandb: sub_train_loss 1.07442
wandb:       test_acc 0.65
wandb:      valid_acc 0.648
wandb: 
wandb: üöÄ View run feasible-sweep-343 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5vfrw3ya
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173426-5vfrw3ya/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: defyrznf with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173441-defyrznf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-344
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/defyrznf
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 146.30it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 146.78it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 147.58it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 145.94it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 146.59it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 146.80it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 141.73it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 141.09it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 140.29it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 143.42it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:00, 145.60it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 147.11it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 148.11it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 148.92it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:01<00:00, 149.02it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 149.41it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:01<00:00, 148.65it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 148.52it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 149.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 146.71it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÑ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.59749
wandb: sub_train_loss 1.15905
wandb:       test_acc 0.555
wandb:      valid_acc 0.548
wandb: 
wandb: üöÄ View run misunderstood-sweep-344 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/defyrznf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173441-defyrznf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 4qckmgbx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173455-4qckmgbx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-345
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/4qckmgbx
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 158.75it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 158.41it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 152.40it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 153.24it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 155.15it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 156.36it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 157.03it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 156.09it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 152.49it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 147.74it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 143.13it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 142.13it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 142.21it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 142.65it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:01<00:00, 142.46it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 142.13it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 141.97it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:01<00:00, 143.43it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:01<00:00, 144.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 147.44it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.57644
wandb: sub_train_loss 1.30201
wandb:       test_acc 0.51
wandb:      valid_acc 0.51
wandb: 
wandb: üöÄ View run copper-sweep-345 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/4qckmgbx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173455-4qckmgbx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: zrlrb44c with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173511-zrlrb44c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-346
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/zrlrb44c
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 150.01it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 153.06it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 154.91it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 155.57it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 155.94it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 155.82it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 154.57it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 155.27it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:01, 155.69it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 155.35it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 155.72it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 154.48it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 154.14it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 153.78it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 151.11it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 151.53it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 152.82it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 153.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 154.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÜ‚ñá‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÜ‚ñá‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.73264
wandb: sub_train_loss 0.86684
wandb:       test_acc 0.7
wandb:      valid_acc 0.714
wandb: 
wandb: üöÄ View run fresh-sweep-346 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/zrlrb44c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173511-zrlrb44c/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: s57z0od6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173532-s57z0od6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-347
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/s57z0od6
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 152.55it/s] 11%|‚ñà         | 33/300 [00:00<00:01, 157.14it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 152.41it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 154.22it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 155.15it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 154.33it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 148.88it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 148.45it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:01, 147.83it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:00, 146.20it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 146.86it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 147.42it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 145.84it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 144.97it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 144.08it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 144.50it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 145.19it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:01<00:00, 144.16it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 143.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 147.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.023 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÜ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.75
wandb: sub_train_loss 0.82044
wandb:       test_acc 0.72
wandb:      valid_acc 0.726
wandb: 
wandb: üöÄ View run misty-sweep-347 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/s57z0od6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173532-s57z0od6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nchx0fze with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173546-nchx0fze
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-348
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/nchx0fze
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 145.93it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 147.19it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 148.26it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:01, 149.09it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 149.38it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 149.53it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 151.00it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 124/300 [00:00<00:01, 154.60it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:01, 157.04it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:00, 157.31it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:00, 157.09it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 155.64it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:01<00:00, 153.91it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 151.74it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:01<00:00, 150.96it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:01<00:00, 152.33it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 149.99it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 147.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 144.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 150.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.74003
wandb: sub_train_loss 0.72984
wandb:       test_acc 0.698
wandb:      valid_acc 0.684
wandb: 
wandb: üöÄ View run fancy-sweep-348 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/nchx0fze
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173546-nchx0fze/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 16538865 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173602-16538865
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-349
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/16538865
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 126.80it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 125.80it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 124.36it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 122.87it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 122.79it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 122.67it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 123.22it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 122.17it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 120.81it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 120.79it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 119.53it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 118.75it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 119.34it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 120.08it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 120.71it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 120.78it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:01<00:00, 121.80it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 233/300 [00:01<00:00, 122.78it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:02<00:00, 122.75it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:02<00:00, 121.70it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 123.21it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 124.55it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:02<00:00, 125.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 122.42it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÇ‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñá‚ñÖ‚ñÑ‚ñà‚ñá‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.42578
wandb: sub_train_loss 1.41877
wandb:       test_acc 0.441
wandb:      valid_acc 0.438
wandb: 
wandb: üöÄ View run skilled-sweep-349 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/16538865
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173602-16538865/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: q27uaz2d with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173617-q27uaz2d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-350
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/q27uaz2d
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 123.36it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 125.14it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 125.31it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 125.22it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 124.57it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 124.03it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 123.07it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 123.95it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 123.79it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 124.02it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 123.89it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 123.85it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 124.08it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 124.21it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 124.27it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 124.40it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 221/300 [00:01<00:00, 124.31it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:01<00:00, 123.87it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 123.99it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 123.69it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 123.47it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 121.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 121.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 123.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.68279
wandb: sub_train_loss 1.01853
wandb:       test_acc 0.684
wandb:      valid_acc 0.698
wandb: 
wandb: üöÄ View run worldly-sweep-350 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/q27uaz2d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173617-q27uaz2d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: et5hge8x with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173638-et5hge8x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-351
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/et5hge8x
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 115.51it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 117.37it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:02, 119.95it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 122.92it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 124.84it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 125.97it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 123.79it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 122.63it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 124.39it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:01<00:01, 125.66it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:01<00:01, 126.49it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 126.85it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 124.27it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 122.41it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 123.78it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 124.79it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 125.27it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 126.38it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:01<00:00, 125.97it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:02<00:00, 123.48it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:02<00:00, 120.41it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:02<00:00, 116.91it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 117.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 122.53it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÇ‚ñÑ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñà‚ñÑ‚ñÅ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÅ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.50111
wandb: sub_train_loss 1.42615
wandb:       test_acc 0.511
wandb:      valid_acc 0.514
wandb: 
wandb: üöÄ View run rural-sweep-351 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/et5hge8x
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173638-et5hge8x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ot2xx0fe with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173649-ot2xx0fe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-352
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ot2xx0fe
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 112.02it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 114.04it/s] 12%|‚ñà‚ñè        | 36/300 [00:00<00:02, 111.93it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 111.91it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 112.47it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:02, 112.74it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 110.95it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 109.39it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:00<00:01, 106.80it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:01<00:01, 105.56it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:01, 104.52it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 104.79it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 106.91it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 108.51it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:01, 109.74it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:01, 110.87it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 111.57it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 111.96it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:02<00:00, 111.82it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:02<00:00, 111.60it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:02<00:00, 109.87it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 110.05it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 110.91it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:02<00:00, 111.39it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:02<00:00, 111.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 110.08it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.55871
wandb: sub_train_loss 1.41503
wandb:       test_acc 0.539
wandb:      valid_acc 0.54
wandb: 
wandb: üöÄ View run splendid-sweep-352 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ot2xx0fe
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173649-ot2xx0fe/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: z8679u0l with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173704-z8679u0l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-353
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/z8679u0l
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 116.75it/s]  8%|‚ñä         | 24/300 [00:00<00:02, 118.22it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:02, 120.76it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 121.71it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 120.20it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:01, 120.13it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:01, 114.13it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:00<00:01, 111.85it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 111.42it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:01<00:01, 111.18it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 115.77it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:01, 118.77it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 119.94it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:01, 120.86it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:01<00:00, 121.58it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 122.29it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 122.86it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:01<00:00, 122.57it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:02<00:00, 122.53it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:02<00:00, 122.60it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:02<00:00, 122.68it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:02<00:00, 122.21it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:02<00:00, 123.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 119.86it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñÇ‚ñÇ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ
wandb: sub_train_loss ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÅ‚ñÉ‚ñà‚ñÜ‚ñÉ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.42393
wandb: sub_train_loss 1.48953
wandb:       test_acc 0.437
wandb:      valid_acc 0.438
wandb: 
wandb: üöÄ View run summer-sweep-353 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/z8679u0l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173704-z8679u0l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: kd1mewx6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173719-kd1mewx6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-354
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/kd1mewx6
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 121.74it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 121.40it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 121.19it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 119.80it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 121.04it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 122.49it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 123.49it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 123.12it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 118.29it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 119.45it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 117.70it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 117.48it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 119.27it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 120.10it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 120.89it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:01<00:00, 120.78it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:01<00:00, 121.27it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 121.40it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:02<00:00, 119.05it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:02<00:00, 107.58it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:02<00:00, 108.98it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 281/300 [00:02<00:00, 111.01it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 111.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 117.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñà‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñÜ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.57201
wandb: sub_train_loss 1.19028
wandb:       test_acc 0.571
wandb:      valid_acc 0.592
wandb: 
wandb: üöÄ View run fiery-sweep-354 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/kd1mewx6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173719-kd1mewx6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 16r1rsn5 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173734-16r1rsn5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-355
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/16r1rsn5
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 9/300 [00:00<00:03, 87.79it/s]  6%|‚ñå         | 18/300 [00:00<00:03, 88.58it/s]  9%|‚ñâ         | 28/300 [00:00<00:02, 91.78it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 93.69it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:02, 94.02it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:02, 93.79it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:02, 95.71it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:02, 98.36it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 99.91it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 101/300 [00:01<00:01, 100.87it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:01<00:01, 99.66it/s]  41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:01<00:01, 100.28it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:01<00:01, 100.75it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 100.34it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 100.02it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:01, 100.00it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:01, 99.94it/s]  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:01, 100.29it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:02<00:01, 99.88it/s]  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:02<00:00, 97.24it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:02<00:00, 96.19it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:02<00:00, 95.65it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 95.34it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 95.20it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 94.63it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:02<00:00, 94.71it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 96.20it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 291/300 [00:02<00:00, 97.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 97.42it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñá‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñÅ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñá‚ñà‚ñÖ‚ñà‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñá‚ñà‚ñÜ‚ñà‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.81834
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run glowing-sweep-355 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/16r1rsn5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173734-16r1rsn5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: odu0mkly with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173750-odu0mkly
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-356
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/odu0mkly
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 102.15it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 99.76it/s]  11%|‚ñà         | 32/300 [00:00<00:02, 95.50it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:02, 94.24it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 93.77it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:02, 93.92it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:02, 94.44it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:02, 94.11it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:02, 92.09it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:01<00:02, 89.95it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:01<00:02, 89.40it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:01<00:02, 84.69it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 86.15it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 87.48it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 89.26it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 90.75it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 91.09it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 90.76it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:02<00:01, 91.72it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:02<00:01, 92.31it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:02<00:00, 92.26it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:02<00:00, 89.65it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:02<00:00, 87.80it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:02<00:00, 89.41it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:02<00:00, 91.08it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:02<00:00, 92.29it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:02<00:00, 92.72it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:03<00:00, 93.35it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:03<00:00, 93.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:03<00:00, 94.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 91.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñà‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñà‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñÇ‚ñÜ‚ñÑ‚ñÇ‚ñà‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÖ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñà‚ñÉ‚ñÜ‚ñÑ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30908
wandb: sub_train_loss 1.82352
wandb:       test_acc 0.321
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run polished-sweep-356 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/odu0mkly
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173750-odu0mkly/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wu843anp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173805-wu843anp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-357
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/wu843anp
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 97.89it/s]  7%|‚ñã         | 20/300 [00:00<00:02, 99.11it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 99.31it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:02, 99.97it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:02, 95.48it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:02, 97.16it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:02, 98.18it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:02, 99.19it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:02, 98.67it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:01<00:01, 99.50it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:01<00:01, 99.43it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:01<00:01, 98.43it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:01<00:01, 99.07it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 95.74it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 94.13it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 92.89it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:01, 91.39it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:01, 90.56it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:02<00:01, 89.65it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 206/300 [00:02<00:01, 90.06it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:02<00:00, 91.25it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:02<00:00, 91.62it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:02<00:00, 91.87it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:02<00:00, 91.50it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 91.50it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:02<00:00, 91.64it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:02<00:00, 91.56it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:03<00:00, 91.60it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:03<00:00, 91.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 94.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñÖ‚ñÇ‚ñÉ‚ñÜ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá
wandb: sub_train_loss ‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñà‚ñÜ‚ñÇ‚ñÉ
wandb:       test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñÖ‚ñÇ‚ñÑ‚ñÜ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñá
wandb:      valid_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñÇ‚ñÉ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.53471
wandb: sub_train_loss 1.37034
wandb:       test_acc 0.53
wandb:      valid_acc 0.538
wandb: 
wandb: üöÄ View run atomic-sweep-357 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/wu843anp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173805-wu843anp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6nzeavlx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173821-6nzeavlx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-358
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/6nzeavlx
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 96.93it/s]  7%|‚ñã         | 21/300 [00:00<00:02, 99.34it/s] 11%|‚ñà         | 32/300 [00:00<00:02, 100.72it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:02, 102.71it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:02, 103.84it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:02, 104.57it/s] 25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:02, 105.09it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:02, 105.54it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 105.69it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 109/300 [00:01<00:01, 105.53it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 105.68it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:01<00:01, 105.67it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 105.39it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:01<00:01, 105.06it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 105.14it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:01, 104.72it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:01, 103.76it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 103.96it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 103.40it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 219/300 [00:02<00:00, 102.83it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:02<00:00, 102.98it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:02<00:00, 100.87it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 99.85it/s]  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 98.86it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 98.28it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 97.88it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 95.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 101.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÉ‚ñÇ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÑ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñà‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñà‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.21713
wandb: sub_train_loss 1.69776
wandb:       test_acc 0.181
wandb:      valid_acc 0.21
wandb: 
wandb: üöÄ View run graceful-sweep-358 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/6nzeavlx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173821-6nzeavlx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 82vm73h8 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173841-82vm73h8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-359
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/82vm73h8
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:03, 95.33it/s]  7%|‚ñã         | 20/300 [00:00<00:03, 93.12it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 93.18it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:02, 92.31it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 92.95it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 93.10it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 93.42it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 93.06it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:02, 92.87it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 100/300 [00:01<00:02, 92.74it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:02, 93.05it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 92.78it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 91.75it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 92.08it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 91.97it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 92.17it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 92.87it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 92.97it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:02<00:01, 92.79it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:02<00:01, 92.24it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:02<00:00, 92.78it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:02<00:00, 93.22it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 230/300 [00:02<00:00, 93.14it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 91.68it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:02<00:00, 91.41it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 89.87it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:02<00:00, 88.64it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:03<00:00, 87.67it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:03<00:00, 86.71it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:03<00:00, 85.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 91.19it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñÉ‚ñÇ‚ñà‚ñÑ‚ñá‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
wandb: sub_train_loss ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÖ‚ñá‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñà‚ñÇ‚ñÇ‚ñÜ‚ñÑ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñà‚ñÇ‚ñÇ‚ñÜ‚ñÑ‚ñÜ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.78151
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run dazzling-sweep-359 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/82vm73h8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173841-82vm73h8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: n59qx68q with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173857-n59qx68q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-360
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/n59qx68q
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 100.92it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 101.22it/s] 11%|‚ñà         | 33/300 [00:00<00:02, 102.30it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:02, 101.90it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:02, 102.62it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:02, 103.48it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:02, 104.13it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:02, 104.61it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 103.91it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:01, 104.33it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:01<00:01, 104.10it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 103.94it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 103.56it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 103.44it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 103.29it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:01, 103.35it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:01, 103.39it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 103.59it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:02<00:00, 103.61it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:02<00:00, 100.62it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:02<00:00, 98.83it/s]  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:02<00:00, 96.54it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:02<00:00, 95.79it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 94.74it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 96.79it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 96.77it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:02<00:00, 97.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 101.07it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÖ
wandb: sub_train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÑ
wandb:      valid_acc ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñá‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÇ‚ñÖ‚ñÜ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.35709
wandb: sub_train_loss 1.38327
wandb:       test_acc 0.331
wandb:      valid_acc 0.336
wandb: 
wandb: üöÄ View run fallen-sweep-360 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/n59qx68q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173857-n59qx68q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vlt8jkti with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173912-vlt8jkti
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-361
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/vlt8jkti
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:00, 236.89it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 239.83it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 241.07it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 241.82it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:00<00:00, 242.06it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 242.89it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:00<00:00, 244.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:00<00:00, 245.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 243.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31388
wandb: sub_train_loss 1.8033
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run crisp-sweep-361 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/vlt8jkti
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173912-vlt8jkti/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: e7i5s6rg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173933-e7i5s6rg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-362
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/e7i5s6rg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:00, 231.68it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 228.89it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:00, 232.60it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 230.38it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 234.34it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 236.55it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:00<00:00, 236.79it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:00<00:00, 237.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 234.97it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31388
wandb: sub_train_loss 1.78864
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run driven-sweep-362 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/e7i5s6rg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173933-e7i5s6rg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ikpkdo8g with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173947-ikpkdo8g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-363
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ikpkdo8g
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 207.91it/s] 23%|‚ñà‚ñà‚ñé       | 46/200 [00:00<00:00, 228.04it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 237.83it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 242.56it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 245.40it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:00<00:00, 246.95it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 246.77it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:00<00:00, 246.05it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 242.53it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.34269
wandb: sub_train_loss 1.81061
wandb:       test_acc 0.396
wandb:      valid_acc 0.398
wandb: 
wandb: üöÄ View run polar-sweep-363 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ikpkdo8g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173947-ikpkdo8g/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yluqatom with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_173959-yluqatom
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-364
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/yluqatom
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 11%|‚ñà         | 22/200 [00:00<00:00, 218.37it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:00, 217.89it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 216.25it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [00:00<00:00, 214.67it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 216.00it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 218.25it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:00<00:00, 221.41it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:00<00:00, 221.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 219.89it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.34121
wandb: sub_train_loss 1.76699
wandb:       test_acc 0.384
wandb:      valid_acc 0.392
wandb: 
wandb: üöÄ View run lyric-sweep-364 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/yluqatom
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_173959-yluqatom/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 0jfwm340 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174014-0jfwm340
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-365
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0jfwm340
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 21/200 [00:00<00:00, 209.60it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:00, 208.29it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 204.92it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:00, 209.28it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 213.28it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:00<00:00, 216.14it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:00<00:00, 217.63it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:00<00:00, 218.96it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 216.63it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.75578
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run fiery-sweep-365 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/0jfwm340
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174014-0jfwm340/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jeuoybfq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174028-jeuoybfq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-366
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/jeuoybfq
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:00, 224.11it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:00, 228.67it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:00, 232.57it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 233.66it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [00:00<00:00, 235.68it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 237.21it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 236.91it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [00:00<00:00, 235.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 234.66it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.3209
wandb: sub_train_loss 1.7585
wandb:       test_acc 0.336
wandb:      valid_acc 0.346
wandb: 
wandb: üöÄ View run wise-sweep-366 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/jeuoybfq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174028-jeuoybfq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: b00m4xsg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174044-b00m4xsg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-367
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/b00m4xsg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 179.26it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 169.19it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:00, 157.32it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 172.64it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 173.20it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 171.45it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 169.47it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:00<00:00, 170.56it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:00<00:00, 175.83it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 180.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 174.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31388
wandb: sub_train_loss 1.79041
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run fresh-sweep-367 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/b00m4xsg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174044-b00m4xsg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: r5sy8orn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174104-r5sy8orn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-368
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/r5sy8orn
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 173.42it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 175.40it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:00, 178.47it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 178.75it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 179.94it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 179.54it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 177.18it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 177.94it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:00<00:00, 180.03it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 180.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 178.72it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31388
wandb: sub_train_loss 1.7797
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run curious-sweep-368 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/r5sy8orn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174104-r5sy8orn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: vpto4nc9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174116-vpto4nc9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-369
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/vpto4nc9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñâ         | 19/200 [00:00<00:00, 182.62it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:00, 182.86it/s] 28%|‚ñà‚ñà‚ñä       | 57/200 [00:00<00:00, 176.79it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 173.78it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 169.65it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 169.03it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 167.54it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 164.05it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:00<00:00, 163.89it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 160.69it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 161.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 166.79it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.34453
wandb: sub_train_loss 1.76583
wandb:       test_acc 0.387
wandb:      valid_acc 0.402
wandb: 
wandb: üöÄ View run eager-sweep-369 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/vpto4nc9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174116-vpto4nc9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: g5tjd6fk with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174137-g5tjd6fk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-370
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/g5tjd6fk
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 179.01it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 173.70it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 171.36it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:00, 178.76it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 183.61it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 186.46it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:00<00:00, 187.78it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:00<00:00, 175.61it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:00<00:00, 176.41it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 164.65it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 171.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.33715
wandb: sub_train_loss 1.7396
wandb:       test_acc 0.356
wandb:      valid_acc 0.342
wandb: 
wandb: üöÄ View run sweet-sweep-370 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/g5tjd6fk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174137-g5tjd6fk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nuuvbih3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174150-nuuvbih3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-371
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/nuuvbih3
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  9%|‚ñâ         | 18/200 [00:00<00:01, 179.14it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:00, 178.45it/s] 27%|‚ñà‚ñà‚ñã       | 54/200 [00:00<00:00, 177.61it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [00:00<00:00, 180.28it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [00:00<00:00, 179.96it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 182.35it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 182.84it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [00:00<00:00, 184.75it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:00<00:00, 185.23it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [00:01<00:00, 183.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 182.02it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.013 MB of 0.017 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.3401
wandb: sub_train_loss 1.73642
wandb:       test_acc 0.36
wandb:      valid_acc 0.38
wandb: 
wandb: üöÄ View run dainty-sweep-371 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/nuuvbih3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174150-nuuvbih3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: cphas8kc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174206-cphas8kc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-372
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/cphas8kc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s] 10%|‚ñà         | 20/200 [00:00<00:00, 192.47it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:00, 195.33it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 192.83it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 185.68it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 180.90it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:00<00:00, 179.54it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 169.20it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [00:00<00:00, 172.98it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:00<00:00, 172.70it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 169.45it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 176.17it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.017 MB uploadedwandb: / 0.014 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.71826
wandb:       test_acc 0.32
wandb:      valid_acc 0.318
wandb: 
wandb: üöÄ View run stellar-sweep-372 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/cphas8kc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174206-cphas8kc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: bzkecagc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174221-bzkecagc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-373
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/bzkecagc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 151.33it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 141.80it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 136.31it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:01, 136.76it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 136.50it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 139.16it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:00<00:00, 143.01it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:00<00:00, 141.11it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 144.49it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [00:01<00:00, 142.35it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 129.00it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 123.80it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 119.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 132.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31388
wandb: sub_train_loss 1.81996
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run devoted-sweep-373 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/bzkecagc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174221-bzkecagc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: zq78uwod with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174242-zq78uwod
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-374
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/zq78uwod
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 157.70it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 152.73it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 148.24it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:00, 145.21it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 146.13it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 145.16it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 145.86it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:00<00:00, 146.49it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:00<00:00, 147.55it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 148.53it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 148.42it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 148.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 148.53it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 147.88it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31942
wandb: sub_train_loss 1.79132
wandb:       test_acc 0.182
wandb:      valid_acc 0.2
wandb: 
wandb: üöÄ View run sage-sweep-374 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/zq78uwod
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174242-zq78uwod/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rf79mo0l with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174257-rf79mo0l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-375
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/rf79mo0l
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 151.48it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 152.50it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 152.86it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 153.46it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 152.17it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 152.12it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 152.08it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 152.16it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 151.90it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 148.84it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 147.37it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 147.08it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 150.08it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.32016
wandb: sub_train_loss 1.75872
wandb:       test_acc 0.243
wandb:      valid_acc 0.228
wandb: 
wandb: üöÄ View run mild-sweep-375 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/rf79mo0l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174257-rf79mo0l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5y6xfz6a with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174308-5y6xfz6a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-376
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5y6xfz6a
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 153.64it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 149.66it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 145.11it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 144.21it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:00, 145.42it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 147.85it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [00:00<00:00, 149.72it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [00:00<00:00, 150.07it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:00<00:00, 141.82it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 143.50it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 143.29it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 143.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 145.33it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31315
wandb: sub_train_loss 1.7307
wandb:       test_acc 0.178
wandb:      valid_acc 0.194
wandb: 
wandb: üöÄ View run lilac-sweep-376 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5y6xfz6a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174308-5y6xfz6a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: optpjpt3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174323-optpjpt3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-377
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/optpjpt3
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 146.85it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 146.49it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 146.91it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:00, 145.76it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:00, 145.25it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 143.38it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [00:00<00:00, 142.15it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:00<00:00, 142.38it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:00<00:00, 142.37it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 144.10it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [00:01<00:00, 143.52it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [00:01<00:00, 143.02it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 142.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 143.74it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30281
wandb: sub_train_loss 1.76852
wandb:       test_acc 0.318
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run eager-sweep-377 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/optpjpt3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174323-optpjpt3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yqrc4u2s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174334-yqrc4u2s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-378
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/yqrc4u2s
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 154.02it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 151.49it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 150.73it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 149.29it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [00:00<00:00, 149.46it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [00:00<00:00, 150.26it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 149.58it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:00<00:00, 149.91it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 149.81it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 149.85it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [00:01<00:00, 149.85it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 149.69it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 149.96it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.75035
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run twilight-sweep-378 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/yqrc4u2s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174334-yqrc4u2s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 87eakt3d with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174348-87eakt3d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-379
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/87eakt3d
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 22/300 [00:00<00:01, 212.88it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:01, 203.78it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 203.79it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:00, 215.17it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:00, 221.93it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:00, 221.99it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 225.91it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 184/300 [00:00<00:00, 227.58it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:00<00:00, 229.83it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 226.01it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 217.14it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:01<00:00, 212.66it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 210.50it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 217.03it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.32238
wandb: sub_train_loss 1.71232
wandb:       test_acc 0.16
wandb:      valid_acc 0.172
wandb: 
wandb: üöÄ View run peach-sweep-379 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/87eakt3d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174348-87eakt3d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: b8a1ts56 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174400-b8a1ts56
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-380
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/b8a1ts56
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 231.91it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 233.70it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:00, 235.40it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:00, 236.65it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:00<00:00, 239.49it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 238.62it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:00<00:00, 237.27it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:00<00:00, 234.82it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:00<00:00, 234.02it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 233.81it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 230.62it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 230.33it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 233.61it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ
wandb:      valid_acc ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÖ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.3257
wandb: sub_train_loss 1.69485
wandb:       test_acc 0.162
wandb:      valid_acc 0.176
wandb: 
wandb: üöÄ View run fine-sweep-380 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/b8a1ts56
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174400-b8a1ts56/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 48gibd77 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174414-48gibd77
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-381
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/48gibd77
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 233.45it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 232.35it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:00, 234.81it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:00, 236.37it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 236.76it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 237.62it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 237.26it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:00<00:00, 239.57it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:00<00:00, 241.47it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:01<00:00, 240.56it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 268/300 [00:01<00:00, 240.41it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 235.89it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 237.12it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.35857
wandb: sub_train_loss 1.65813
wandb:       test_acc 0.411
wandb:      valid_acc 0.404
wandb: 
wandb: üöÄ View run quiet-sweep-381 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/48gibd77
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174414-48gibd77/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 31k1xo2e with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174435-31k1xo2e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-382
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/31k1xo2e
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 222.28it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 235.82it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:00, 239.50it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:00, 242.49it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:00, 243.98it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:00<00:00, 242.42it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:00<00:00, 242.11it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:00<00:00, 239.72it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:00<00:00, 240.53it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 238.43it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 238.39it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 237.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 239.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.36558
wandb: sub_train_loss 1.62234
wandb:       test_acc 0.456
wandb:      valid_acc 0.466
wandb: 
wandb: üöÄ View run faithful-sweep-382 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/31k1xo2e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174435-31k1xo2e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pyktjo2x with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174450-pyktjo2x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-383
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/pyktjo2x
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 23/300 [00:00<00:01, 227.17it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 231.90it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:01, 225.77it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:00, 221.43it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:00, 218.63it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:00<00:00, 226.39it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:00<00:00, 233.11it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:00<00:00, 234.23it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:00<00:00, 232.74it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 230.59it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 229.01it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 228.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 228.49it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.40657
wandb: sub_train_loss 1.61918
wandb:       test_acc 0.5
wandb:      valid_acc 0.512
wandb: 
wandb: üöÄ View run proud-sweep-383 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/pyktjo2x
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174450-pyktjo2x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hlsjw8dg with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174505-hlsjw8dg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-384
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/hlsjw8dg
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  8%|‚ñä         | 24/300 [00:00<00:01, 236.61it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 234.15it/s] 24%|‚ñà‚ñà‚ñç       | 72/300 [00:00<00:00, 234.16it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:00, 231.93it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:00, 233.14it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 234.33it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:00<00:00, 233.21it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:00<00:00, 233.05it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:00<00:00, 233.05it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 227.87it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 226.89it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 223.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 228.08it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.41064
wandb: sub_train_loss 1.56615
wandb:       test_acc 0.544
wandb:      valid_acc 0.544
wandb: 
wandb: üöÄ View run true-sweep-384 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/hlsjw8dg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174505-hlsjw8dg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: yx0r0uqb with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174517-yx0r0uqb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-385
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/yx0r0uqb
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñã         | 19/300 [00:00<00:01, 185.31it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:01, 187.22it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 188.71it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 189.57it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 190.06it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:00, 189.35it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 137/300 [00:00<00:00, 187.62it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:00<00:00, 185.33it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:00<00:00, 184.74it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 180.72it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:01<00:00, 175.90it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 173.51it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:01<00:00, 161.90it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:01<00:00, 154.72it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:01<00:00, 150.38it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 298/300 [00:01<00:00, 147.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 170.18it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.32275
wandb: sub_train_loss 1.72639
wandb:       test_acc 0.157
wandb:      valid_acc 0.174
wandb: 
wandb: üöÄ View run devoted-sweep-385 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/yx0r0uqb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174517-yx0r0uqb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: r0vb9wlj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174531-r0vb9wlj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-386
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/r0vb9wlj
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  7%|‚ñã         | 20/300 [00:00<00:01, 191.70it/s] 13%|‚ñà‚ñé        | 40/300 [00:00<00:01, 184.50it/s] 20%|‚ñà‚ñâ        | 59/300 [00:00<00:01, 178.08it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:01, 174.98it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 167.79it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 160.73it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:01, 157.25it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:00, 157.34it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:00<00:00, 159.98it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 162.47it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:01<00:00, 166.38it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 214/300 [00:01<00:00, 159.64it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 161.26it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:01<00:00, 161.43it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:01<00:00, 162.22it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:01<00:00, 165.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 162.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 164.35it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31832
wandb: sub_train_loss 1.71342
wandb:       test_acc 0.151
wandb:      valid_acc 0.164
wandb: 
wandb: üöÄ View run laced-sweep-386 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/r0vb9wlj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174531-r0vb9wlj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hwaxq4v2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174546-hwaxq4v2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-387
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/hwaxq4v2
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 165.95it/s] 12%|‚ñà‚ñè        | 35/300 [00:00<00:01, 168.75it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:01, 166.77it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 166.27it/s] 29%|‚ñà‚ñà‚ñâ       | 87/300 [00:00<00:01, 170.41it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 172.95it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:00<00:01, 173.61it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 175.30it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:00<00:00, 174.43it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 177.42it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 181.62it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 182.38it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 183.16it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 183.61it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 183.21it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 183.22it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 177.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.33567
wandb: sub_train_loss 1.63046
wandb:       test_acc 0.296
wandb:      valid_acc 0.302
wandb: 
wandb: üöÄ View run amber-sweep-387 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/hwaxq4v2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174546-hwaxq4v2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 30gefktl with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174602-30gefktl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-388
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/30gefktl
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 165.45it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 168.04it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 165.38it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:01, 164.45it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 163.23it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 102/300 [00:00<00:01, 163.18it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:00<00:01, 162.32it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:01, 161.92it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 153/300 [00:00<00:00, 161.13it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 171/300 [00:01<00:00, 166.35it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:00, 168.80it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 169.79it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 169.64it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 168.61it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 259/300 [00:01<00:00, 171.70it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 173.77it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:01<00:00, 175.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 168.51it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.33235
wandb: sub_train_loss 1.58357
wandb:       test_acc 0.222
wandb:      valid_acc 0.25
wandb: 
wandb: üöÄ View run misunderstood-sweep-388 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/30gefktl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174602-30gefktl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hhasvelx with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174617-hhasvelx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-389
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/hhasvelx
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 160.76it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 160.96it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 164.37it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 167.23it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 168.09it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 167.74it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:00<00:01, 172.80it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 141/300 [00:00<00:00, 176.25it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:00<00:00, 179.40it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:00, 181.49it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 181.44it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 182.55it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:01<00:00, 182.75it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 183.32it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 182.24it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:01<00:00, 182.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 177.40it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.40694
wandb: sub_train_loss 1.56209
wandb:       test_acc 0.517
wandb:      valid_acc 0.516
wandb: 
wandb: üöÄ View run azure-sweep-389 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/hhasvelx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174617-hhasvelx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: h98p134k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174632-h98p134k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-390
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/h98p134k
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 18/300 [00:00<00:01, 178.95it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:01, 182.26it/s] 19%|‚ñà‚ñä        | 56/300 [00:00<00:01, 183.22it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 185.40it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 183.00it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 180.32it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:00, 184.06it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:00<00:00, 182.53it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:00<00:00, 185.74it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 188.54it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 189.78it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 189.07it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 250/300 [00:01<00:00, 187.71it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 269/300 [00:01<00:00, 187.93it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 187.95it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 186.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.3678
wandb: sub_train_loss 1.5024
wandb:       test_acc 0.418
wandb:      valid_acc 0.43
wandb: 
wandb: üöÄ View run ruby-sweep-390 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/h98p134k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174632-h98p134k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: r9j90ra7 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174648-r9j90ra7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-391
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/r9j90ra7
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 124.09it/s]  9%|‚ñâ         | 27/300 [00:00<00:02, 128.45it/s] 14%|‚ñà‚ñç        | 42/300 [00:00<00:01, 137.13it/s] 19%|‚ñà‚ñâ        | 58/300 [00:00<00:01, 142.35it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 143.55it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:01, 144.55it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 103/300 [00:00<00:01, 146.05it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 118/300 [00:00<00:01, 145.53it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 133/300 [00:00<00:01, 144.96it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 148/300 [00:01<00:01, 144.85it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:00, 144.44it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 178/300 [00:01<00:00, 145.74it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 194/300 [00:01<00:00, 147.96it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 149.52it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 151.24it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 151.19it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 150.57it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 151.77it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 153.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 146.46it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31388
wandb: sub_train_loss 1.71647
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run sage-sweep-391 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/r9j90ra7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174648-r9j90ra7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 19l5dcwa with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174703-19l5dcwa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-392
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/19l5dcwa
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  6%|‚ñå         | 17/300 [00:00<00:01, 162.09it/s] 11%|‚ñà‚ñè        | 34/300 [00:00<00:01, 162.52it/s] 17%|‚ñà‚ñã        | 51/300 [00:00<00:01, 159.29it/s] 22%|‚ñà‚ñà‚ñè       | 67/300 [00:00<00:01, 156.32it/s] 28%|‚ñà‚ñà‚ñä       | 83/300 [00:00<00:01, 153.44it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 152.38it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:00<00:01, 152.85it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/300 [00:00<00:01, 152.25it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:00<00:01, 149.13it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 162/300 [00:01<00:00, 146.41it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 147.14it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 150.03it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 152.09it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 153.04it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 154.14it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 154.95it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 155.08it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 153.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 152.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31388
wandb: sub_train_loss 1.6603
wandb:       test_acc 0.149
wandb:      valid_acc 0.162
wandb: 
wandb: üöÄ View run splendid-sweep-392 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/19l5dcwa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174703-19l5dcwa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: tmfw97ko with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174715-tmfw97ko
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-393
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/tmfw97ko
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 128.60it/s]  9%|‚ñâ         | 27/300 [00:00<00:02, 131.64it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:01, 134.23it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:01, 136.34it/s] 23%|‚ñà‚ñà‚ñé       | 69/300 [00:00<00:01, 134.77it/s] 28%|‚ñà‚ñà‚ñä       | 84/300 [00:00<00:01, 139.13it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 141.10it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 114/300 [00:00<00:01, 139.04it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 134.70it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 142/300 [00:01<00:01, 133.35it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 157/300 [00:01<00:01, 135.73it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:00, 139.43it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 144.44it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:00, 142.87it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:01<00:00, 139.20it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 136.33it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:01<00:00, 134.09it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:01<00:00, 131.98it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 130.55it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:02<00:00, 131.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 136.11it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31204
wandb: sub_train_loss 1.63764
wandb:       test_acc 0.158
wandb:      valid_acc 0.178
wandb: 
wandb: üöÄ View run fine-sweep-393 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/tmfw97ko
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174715-tmfw97ko/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6t40y8ma with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174729-6t40y8ma
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-394
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/6t40y8ma
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 144.48it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 147.14it/s] 15%|‚ñà‚ñå        | 46/300 [00:00<00:01, 150.41it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:01, 151.33it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 152.25it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 94/300 [00:00<00:01, 150.78it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 149.03it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:00<00:01, 147.80it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:01, 144.53it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 144.86it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:00, 146.16it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 147.41it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 147.80it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 147.91it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 232/300 [00:01<00:00, 148.67it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 148.40it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:01<00:00, 148.80it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:01<00:00, 148.36it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 292/300 [00:01<00:00, 147.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 148.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá
wandb:      valid_acc ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñá‚ñá‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.34417
wandb: sub_train_loss 1.51481
wandb:       test_acc 0.389
wandb:      valid_acc 0.402
wandb: 
wandb: üöÄ View run laced-sweep-394 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/6t40y8ma
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174729-6t40y8ma/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pgxrnq6s with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174740-pgxrnq6s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-395
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/pgxrnq6s
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 153.66it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 153.83it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 153.58it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 154.16it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 155.26it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 155.26it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 112/300 [00:00<00:01, 155.93it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:00<00:01, 156.20it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 144/300 [00:00<00:00, 156.11it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:00, 154.54it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:00, 153.48it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 153.58it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:01<00:00, 153.81it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 154.11it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 154.60it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 155.03it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:01<00:00, 155.09it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 288/300 [00:01<00:00, 153.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 154.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31647
wandb: sub_train_loss 1.59501
wandb:       test_acc 0.299
wandb:      valid_acc 0.308
wandb: 
wandb: üöÄ View run glad-sweep-395 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/pgxrnq6s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174740-pgxrnq6s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hizus4p6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: SAGE
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174755-hizus4p6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-396
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/hizus4p6
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 153.23it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 153.66it/s] 16%|‚ñà‚ñå        | 48/300 [00:00<00:01, 155.56it/s] 21%|‚ñà‚ñà‚ñè       | 64/300 [00:00<00:01, 154.98it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 155.91it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:01, 149.33it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 143.71it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:00<00:01, 137.42it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:00<00:01, 135.07it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 133.01it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 130.62it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 182/300 [00:01<00:00, 130.31it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 130.28it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 130.80it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:01<00:00, 130.89it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:01<00:00, 131.03it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:01<00:00, 137.84it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 143.40it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 147.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 141.05it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.339
wandb: sub_train_loss 1.55747
wandb:       test_acc 0.311
wandb:      valid_acc 0.338
wandb: 
wandb: üöÄ View run lyric-sweep-396 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/hizus4p6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174755-hizus4p6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: o0tc757l with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174810-o0tc757l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-397
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/o0tc757l
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 17/200 [00:00<00:01, 160.13it/s] 17%|‚ñà‚ñã        | 34/200 [00:00<00:01, 157.87it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:00, 154.19it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 151.91it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 151.27it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 150.88it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 150.58it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 150.92it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 149.14it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 149.20it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 149.60it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:01<00:00, 150.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 150.99it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.72142
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run mild-sweep-397 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/o0tc757l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174810-o0tc757l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ora3ian9 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174826-ora3ian9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-398
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ora3ian9
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 156.52it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 155.45it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:00, 159.30it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:00, 159.80it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 158.94it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:00<00:00, 158.99it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 159.11it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [00:00<00:00, 158.30it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:00<00:00, 155.98it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 156.51it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 157.40it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 155.11it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 157.13it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.017 MB of 0.023 MB uploadedwandb: / 0.017 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30502
wandb: sub_train_loss 1.68992
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run fluent-sweep-398 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ora3ian9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174826-ora3ian9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: x3q8zg3m with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174841-x3q8zg3m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-399
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/x3q8zg3m
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 158.51it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 153.74it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 151.87it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:00, 151.34it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:00, 150.73it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 150.41it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:00<00:00, 150.51it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:00<00:00, 150.85it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:00<00:00, 150.03it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [00:01<00:00, 148.40it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [00:01<00:00, 147.53it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 147.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 149.30it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.71803
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run hardy-sweep-399 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/x3q8zg3m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174841-x3q8zg3m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: umzzg5oc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174852-umzzg5oc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-400
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/umzzg5oc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 142.93it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 146.68it/s] 22%|‚ñà‚ñà‚ñé       | 45/200 [00:00<00:01, 148.10it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:00, 149.20it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:00, 148.66it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:00, 148.24it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:00<00:00, 146.84it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:00<00:00, 147.78it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:00<00:00, 147.53it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 148.81it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 147.71it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 149.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:01<00:00, 150.79it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 148.69it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30207
wandb: sub_train_loss 1.7093
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run drawn-sweep-400 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/umzzg5oc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174852-umzzg5oc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: y5qhtezz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174907-y5qhtezz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-401
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/y5qhtezz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 15/200 [00:00<00:01, 148.08it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 151.33it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:00, 156.15it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:00, 158.75it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:00, 160.26it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 161.83it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:00<00:00, 162.00it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [00:00<00:00, 162.19it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:00<00:00, 161.17it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 160.36it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 160.60it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 158.73it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30835
wandb: sub_train_loss 1.69915
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run sweepy-sweep-401 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/y5qhtezz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174907-y5qhtezz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: m1w5xzb2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174922-m1w5xzb2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-402
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/m1w5xzb2
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  8%|‚ñä         | 16/200 [00:00<00:01, 152.24it/s] 16%|‚ñà‚ñå        | 32/200 [00:00<00:01, 149.09it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 146.35it/s] 31%|‚ñà‚ñà‚ñà       | 62/200 [00:00<00:00, 146.41it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:00, 149.06it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:00, 150.08it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [00:00<00:00, 148.18it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:00<00:00, 150.96it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:00<00:00, 153.39it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 155.07it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 155.92it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [00:01<00:00, 157.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 153.01it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.023 MB uploadedwandb: / 0.013 MB of 0.023 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30465
wandb: sub_train_loss 1.69688
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run kind-sweep-402 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/m1w5xzb2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174922-m1w5xzb2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2tn1x9ha with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174938-2tn1x9ha
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-403
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/2tn1x9ha
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 128.29it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 128.70it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 125.26it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 126.15it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 127.00it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 118.48it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 115.25it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 109.80it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 110.40it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:01<00:00, 112.93it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 110.48it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 108.51it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 106.44it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [00:01<00:00, 106.54it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 106.38it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 105.86it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 112.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.39106
wandb: sub_train_loss 1.64131
wandb:       test_acc 0.416
wandb:      valid_acc 0.414
wandb: 
wandb: üöÄ View run graceful-sweep-403 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/2tn1x9ha
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174938-2tn1x9ha/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2w78swzp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_174953-2w78swzp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-404
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/2w78swzp
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 118.23it/s] 12%|‚ñà‚ñè        | 24/200 [00:00<00:01, 118.22it/s] 18%|‚ñà‚ñä        | 36/200 [00:00<00:01, 117.47it/s] 24%|‚ñà‚ñà‚ñç       | 48/200 [00:00<00:01, 117.49it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 117.30it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [00:00<00:01, 118.06it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:00, 117.58it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:00, 116.25it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [00:00<00:00, 114.31it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [00:01<00:00, 114.41it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 113.91it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 114.65it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 115.83it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [00:01<00:00, 118.85it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 121.06it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [00:01<00:00, 122.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 118.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.37777
wandb: sub_train_loss 1.67305
wandb:       test_acc 0.396
wandb:      valid_acc 0.388
wandb: 
wandb: üöÄ View run pleasant-sweep-404 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/2w78swzp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_174953-2w78swzp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: uw1287zp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175008-uw1287zp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-405
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/uw1287zp
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 12/200 [00:00<00:01, 119.98it/s] 12%|‚ñà‚ñé        | 25/200 [00:00<00:01, 122.22it/s] 19%|‚ñà‚ñâ        | 38/200 [00:00<00:01, 122.64it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 122.81it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 122.89it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [00:00<00:01, 120.34it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:00, 118.82it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:00, 118.19it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:00<00:00, 116.75it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:01<00:00, 115.40it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 114.76it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [00:01<00:00, 114.85it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [00:01<00:00, 114.86it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 115.01it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [00:01<00:00, 115.20it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:01<00:00, 115.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 117.29it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.31684
wandb: sub_train_loss 1.67604
wandb:       test_acc 0.319
wandb:      valid_acc 0.318
wandb: 
wandb: üöÄ View run atomic-sweep-405 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/uw1287zp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175008-uw1287zp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: ewlm38kh with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175020-ewlm38kh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-406
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ewlm38kh
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 123.22it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 121.43it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 116.67it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 116.83it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 117.32it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [00:00<00:01, 117.44it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [00:00<00:00, 117.29it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [00:00<00:00, 117.19it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:00<00:00, 116.55it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:01<00:00, 116.58it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [00:01<00:00, 116.15it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 115.24it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 114.56it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 113.85it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [00:01<00:00, 113.56it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [00:01<00:00, 116.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 116.54it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb:      valid_acc ‚ñÅ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.35192
wandb: sub_train_loss 1.65517
wandb:       test_acc 0.343
wandb:      valid_acc 0.34
wandb: 
wandb: üöÄ View run twilight-sweep-406 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/ewlm38kh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175020-ewlm38kh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 62tuudl1 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175040-62tuudl1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-407
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/62tuudl1
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 109.44it/s] 12%|‚ñà‚ñè        | 23/200 [00:00<00:01, 109.84it/s] 18%|‚ñà‚ñä        | 35/200 [00:00<00:01, 110.97it/s] 24%|‚ñà‚ñà‚ñé       | 47/200 [00:00<00:01, 111.41it/s] 30%|‚ñà‚ñà‚ñâ       | 59/200 [00:00<00:01, 110.60it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:01, 109.19it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:00<00:01, 108.06it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [00:00<00:00, 108.33it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:00<00:00, 106.89it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [00:01<00:00, 107.66it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:01<00:00, 108.21it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 107.96it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 107.64it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [00:01<00:00, 107.56it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [00:01<00:00, 107.80it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 110.30it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:01<00:00, 109.80it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 109.32it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30761
wandb: sub_train_loss 1.68474
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run wobbly-sweep-407 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/62tuudl1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175040-62tuudl1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: r3j0u2zi with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175052-r3j0u2zi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-408
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/r3j0u2zi
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñã         | 13/200 [00:00<00:01, 123.87it/s] 13%|‚ñà‚ñé        | 26/200 [00:00<00:01, 125.98it/s] 20%|‚ñà‚ñâ        | 39/200 [00:00<00:01, 126.43it/s] 26%|‚ñà‚ñà‚ñå       | 52/200 [00:00<00:01, 124.37it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [00:00<00:01, 125.90it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [00:00<00:01, 119.82it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:01, 99.83it/s]  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [00:00<00:01, 93.92it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:01<00:00, 94.38it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [00:01<00:00, 93.71it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [00:01<00:00, 89.33it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [00:01<00:00, 90.34it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [00:01<00:00, 91.23it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [00:01<00:00, 96.04it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [00:01<00:00, 104.21it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [00:01<00:00, 109.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:01<00:00, 105.29it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.4243
wandb: sub_train_loss 1.61972
wandb:       test_acc 0.433
wandb:      valid_acc 0.432
wandb: 
wandb: üöÄ View run zesty-sweep-408 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/r3j0u2zi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175052-r3j0u2zi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: c1kjkbsp with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175106-c1kjkbsp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-409
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/c1kjkbsp
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:02, 94.09it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 96.33it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 96.10it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 95.87it/s] 25%|‚ñà‚ñà‚ñå       | 50/200 [00:00<00:01, 94.25it/s] 30%|‚ñà‚ñà‚ñà       | 60/200 [00:00<00:01, 92.88it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [00:00<00:01, 92.75it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [00:00<00:01, 93.77it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:00<00:01, 95.16it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:01<00:01, 97.47it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [00:01<00:00, 98.91it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [00:01<00:00, 99.93it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:01<00:00, 100.54it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [00:01<00:00, 101.01it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 101.26it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 100.37it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [00:01<00:00, 97.63it/s]  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 97.19it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [00:02<00:00, 94.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 96.39it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.36115
wandb: sub_train_loss 1.72278
wandb:       test_acc 0.345
wandb:      valid_acc 0.348
wandb: 
wandb: üöÄ View run solar-sweep-409 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/c1kjkbsp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175106-c1kjkbsp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: x8p376in with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175127-x8p376in
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-410
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/x8p376in
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 100.01it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 100.86it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 98.50it/s]  22%|‚ñà‚ñà‚ñè       | 43/200 [00:00<00:01, 96.73it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:01, 96.46it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [00:00<00:01, 96.34it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:01, 98.47it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [00:00<00:01, 100.18it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:01, 100.73it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:01<00:00, 100.59it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [00:01<00:00, 98.56it/s]  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [00:01<00:00, 97.82it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [00:01<00:00, 97.38it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [00:01<00:00, 96.92it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [00:01<00:00, 97.30it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [00:01<00:00, 97.93it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [00:01<00:00, 99.24it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [00:01<00:00, 99.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 98.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 98.47it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.36595
wandb: sub_train_loss 1.64202
wandb:       test_acc 0.367
wandb:      valid_acc 0.358
wandb: 
wandb: üöÄ View run sweepy-sweep-410 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/x8p376in
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175127-x8p376in/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: vg3sbuj2 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175147-vg3sbuj2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-411
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/vg3sbuj2
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 95.91it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 95.98it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 94.09it/s] 20%|‚ñà‚ñà        | 40/200 [00:00<00:01, 83.50it/s] 24%|‚ñà‚ñà‚ñç       | 49/200 [00:00<00:01, 81.66it/s] 29%|‚ñà‚ñà‚ñâ       | 58/200 [00:00<00:01, 73.84it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 74.34it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:01, 72.75it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [00:01<00:01, 73.94it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [00:01<00:01, 72.74it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [00:01<00:01, 73.74it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [00:01<00:01, 76.20it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [00:01<00:01, 81.31it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [00:01<00:00, 85.11it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [00:01<00:00, 88.07it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [00:01<00:00, 90.91it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [00:01<00:00, 93.32it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [00:01<00:00, 94.53it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:02<00:00, 94.23it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:02<00:00, 96.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:02<00:00, 97.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 85.68it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.3305
wandb: sub_train_loss 1.74778
wandb:       test_acc 0.322
wandb:      valid_acc 0.324
wandb: 
wandb: üöÄ View run decent-sweep-411 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/vg3sbuj2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175147-vg3sbuj2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: iwqucdeq with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175210-iwqucdeq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-412
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/iwqucdeq
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 99.86it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 98.67it/s] 15%|‚ñà‚ñå        | 30/200 [00:00<00:01, 98.51it/s] 20%|‚ñà‚ñà        | 41/200 [00:00<00:01, 99.08it/s] 26%|‚ñà‚ñà‚ñå       | 51/200 [00:00<00:01, 97.43it/s] 30%|‚ñà‚ñà‚ñà       | 61/200 [00:00<00:01, 94.38it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [00:00<00:01, 91.93it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [00:00<00:01, 90.93it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [00:00<00:01, 92.73it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [00:01<00:01, 93.40it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [00:01<00:00, 93.05it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [00:01<00:00, 86.54it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [00:01<00:00, 88.27it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [00:01<00:00, 90.04it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [00:01<00:00, 91.61it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [00:01<00:00, 91.75it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [00:01<00:00, 92.62it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [00:01<00:00, 95.73it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [00:02<00:00, 98.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 94.20it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÑ‚ñÇ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.35524
wandb: sub_train_loss 1.5603
wandb:       test_acc 0.327
wandb:      valid_acc 0.328
wandb: 
wandb: üöÄ View run olive-sweep-412 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/iwqucdeq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175210-iwqucdeq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 5bhh0i2b with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175227-5bhh0i2b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-413
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5bhh0i2b
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  6%|‚ñå         | 11/200 [00:00<00:01, 101.36it/s] 11%|‚ñà         | 22/200 [00:00<00:01, 103.10it/s] 16%|‚ñà‚ñã        | 33/200 [00:00<00:01, 102.19it/s] 22%|‚ñà‚ñà‚ñè       | 44/200 [00:00<00:01, 101.58it/s] 28%|‚ñà‚ñà‚ñä       | 55/200 [00:00<00:01, 100.87it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [00:00<00:01, 99.75it/s]  38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [00:00<00:01, 99.13it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [00:00<00:01, 98.78it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [00:00<00:01, 97.69it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [00:01<00:00, 97.60it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [00:01<00:00, 97.57it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [00:01<00:00, 97.23it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [00:01<00:00, 97.06it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [00:01<00:00, 96.38it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [00:01<00:00, 96.11it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [00:01<00:00, 95.94it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [00:01<00:00, 97.27it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [00:01<00:00, 98.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [00:02<00:00, 99.55it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 98.59it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30982
wandb: sub_train_loss 1.75359
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run wise-sweep-413 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/5bhh0i2b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175227-5bhh0i2b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 6ml5kiep with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 200
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175242-6ml5kiep
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-414
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/6ml5kiep
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/200 [00:00<?, ?it/s]  5%|‚ñå         | 10/200 [00:00<00:01, 99.81it/s] 10%|‚ñà         | 20/200 [00:00<00:01, 99.80it/s] 16%|‚ñà‚ñå        | 31/200 [00:00<00:01, 100.43it/s] 21%|‚ñà‚ñà        | 42/200 [00:00<00:01, 100.39it/s] 26%|‚ñà‚ñà‚ñã       | 53/200 [00:00<00:01, 100.40it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [00:00<00:01, 99.76it/s]  37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [00:00<00:01, 99.75it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [00:00<00:01, 98.62it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [00:00<00:01, 96.32it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [00:01<00:01, 94.69it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [00:01<00:00, 93.97it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [00:01<00:00, 93.63it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [00:01<00:00, 93.54it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [00:01<00:00, 93.24it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [00:01<00:00, 92.69it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [00:01<00:00, 93.07it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [00:01<00:00, 93.31it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [00:01<00:00, 94.73it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [00:02<00:00, 95.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:02<00:00, 95.78it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.52696
wandb: sub_train_loss 1.69706
wandb:       test_acc 0.547
wandb:      valid_acc 0.542
wandb: 
wandb: üöÄ View run super-sweep-414 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/6ml5kiep
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175242-6ml5kiep/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jfmsgz61 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175257-jfmsgz61
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-415
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/jfmsgz61
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñç         | 14/300 [00:00<00:02, 135.16it/s] 10%|‚ñâ         | 29/300 [00:00<00:01, 141.62it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 145.80it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 146.37it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 147.08it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 147.95it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 148.43it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 148.78it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:00<00:01, 149.47it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:00, 149.47it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:00, 148.68it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:00, 148.20it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 196/300 [00:01<00:00, 147.97it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 211/300 [00:01<00:00, 147.86it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 145.99it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 144.39it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:01<00:00, 143.51it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 144.43it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:01<00:00, 142.98it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 146.21it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.50923
wandb: sub_train_loss 1.50511
wandb:       test_acc 0.473
wandb:      valid_acc 0.486
wandb: 
wandb: üöÄ View run spring-sweep-415 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/jfmsgz61
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175257-jfmsgz61/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2sxfi3qz with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175312-2sxfi3qz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-416
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/2sxfi3qz
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 143.29it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 144.09it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 142.81it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 140.66it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 142.04it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 140.58it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 143.32it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 145.11it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 146.00it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 151/300 [00:01<00:00, 149.19it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 167/300 [00:01<00:00, 151.82it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 183/300 [00:01<00:00, 152.68it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 151.63it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:01<00:00, 149.75it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:01<00:00, 150.55it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 247/300 [00:01<00:00, 150.61it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:01<00:00, 150.33it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 279/300 [00:01<00:00, 149.13it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:01<00:00, 148.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 147.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.52733
wandb: sub_train_loss 1.47918
wandb:       test_acc 0.51
wandb:      valid_acc 0.522
wandb: 
wandb: üöÄ View run dandy-sweep-416 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/2sxfi3qz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175312-2sxfi3qz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: mn7brp6n with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175328-mn7brp6n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-417
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/mn7brp6n
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 145.53it/s] 10%|‚ñà         | 31/300 [00:00<00:01, 151.39it/s] 16%|‚ñà‚ñå        | 47/300 [00:00<00:01, 152.83it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:01, 152.72it/s] 26%|‚ñà‚ñà‚ñã       | 79/300 [00:00<00:01, 154.10it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 154.92it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 155.34it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 127/300 [00:00<00:01, 156.26it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:00<00:01, 156.80it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:00, 156.76it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:00, 157.03it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:00, 155.95it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:01<00:00, 152.95it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 223/300 [00:01<00:00, 152.34it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 239/300 [00:01<00:00, 153.88it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 154.77it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 271/300 [00:01<00:00, 155.21it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:01<00:00, 155.88it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 154.87it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñà
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.46566
wandb: sub_train_loss 1.53537
wandb:       test_acc 0.47
wandb:      valid_acc 0.48
wandb: 
wandb: üöÄ View run crimson-sweep-417 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/mn7brp6n
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175328-mn7brp6n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: qxoxkcda with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175343-qxoxkcda
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-418
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/qxoxkcda
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 143.40it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 142.51it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 143.26it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 143.17it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 142.91it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 144.67it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 145.44it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 146.36it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 146.09it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 145.20it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 141.42it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 140.31it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 140.51it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 142.84it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:01<00:00, 146.29it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:01<00:00, 149.09it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 258/300 [00:01<00:00, 151.27it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:01<00:00, 152.19it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:01<00:00, 152.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 146.60it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.55318
wandb: sub_train_loss 1.47929
wandb:       test_acc 0.529
wandb:      valid_acc 0.542
wandb: 
wandb: üöÄ View run smart-sweep-418 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/qxoxkcda
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175343-qxoxkcda/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: 2pcb2k89 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175354-2pcb2k89
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-419
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/2pcb2k89
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 16/300 [00:00<00:01, 156.63it/s] 11%|‚ñà         | 32/300 [00:00<00:01, 143.72it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:01, 151.85it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 152.22it/s] 27%|‚ñà‚ñà‚ñã       | 81/300 [00:00<00:01, 152.39it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 152.50it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 113/300 [00:00<00:01, 152.42it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:00<00:01, 153.27it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:00<00:01, 153.30it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 161/300 [00:01<00:00, 154.48it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 177/300 [00:01<00:00, 153.38it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 193/300 [00:01<00:00, 152.51it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:01<00:00, 151.79it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 152.71it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:01<00:00, 153.28it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 257/300 [00:01<00:00, 153.67it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:01<00:00, 153.37it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 289/300 [00:01<00:00, 152.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:01<00:00, 152.55it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.42725
wandb: sub_train_loss 1.53967
wandb:       test_acc 0.428
wandb:      valid_acc 0.43
wandb: 
wandb: üöÄ View run eager-sweep-419 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/2pcb2k89
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175354-2pcb2k89/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a079pfmc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 1
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175409-a079pfmc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-420
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/a079pfmc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  5%|‚ñå         | 15/300 [00:00<00:01, 146.89it/s] 10%|‚ñà         | 30/300 [00:00<00:01, 147.15it/s] 15%|‚ñà‚ñå        | 45/300 [00:00<00:01, 147.19it/s] 20%|‚ñà‚ñà        | 60/300 [00:00<00:01, 147.16it/s] 25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:01, 147.04it/s] 30%|‚ñà‚ñà‚ñà       | 90/300 [00:00<00:01, 145.43it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:00<00:01, 145.47it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:00<00:01, 146.06it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:00<00:01, 146.05it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 147.05it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:00, 146.38it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:00, 145.72it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:01<00:00, 145.56it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:01<00:00, 145.18it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 144.86it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:01<00:00, 144.79it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:01<00:00, 145.25it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 270/300 [00:01<00:00, 145.41it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:01<00:00, 145.76it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 146.16it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.54653
wandb: sub_train_loss 1.48315
wandb:       test_acc 0.509
wandb:      valid_acc 0.506
wandb: 
wandb: üöÄ View run fine-sweep-420 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/a079pfmc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175409-a079pfmc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 9btj9v5j with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175429-9btj9v5j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-421
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/9btj9v5j
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 106.15it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 106.73it/s] 11%|‚ñà         | 33/300 [00:00<00:02, 105.81it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:02, 98.68it/s]  19%|‚ñà‚ñä        | 56/300 [00:00<00:02, 104.43it/s] 23%|‚ñà‚ñà‚ñé       | 68/300 [00:00<00:02, 107.86it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:01, 111.16it/s] 31%|‚ñà‚ñà‚ñà       | 92/300 [00:00<00:01, 113.26it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 112.73it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:01<00:01, 110.50it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:01<00:01, 111.23it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 112.12it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 152/300 [00:01<00:01, 112.93it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 164/300 [00:01<00:01, 114.78it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:01, 114.47it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 188/300 [00:01<00:00, 113.99it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 200/300 [00:01<00:00, 114.18it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 112.07it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 224/300 [00:02<00:00, 111.58it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:02<00:00, 112.43it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 248/300 [00:02<00:00, 113.35it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 260/300 [00:02<00:00, 113.59it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 114.32it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 284/300 [00:02<00:00, 114.88it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 118.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 112.43it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.38663
wandb: sub_train_loss 1.3288
wandb:       test_acc 0.351
wandb:      valid_acc 0.346
wandb: 
wandb: üöÄ View run dutiful-sweep-421 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/9btj9v5j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175429-9btj9v5j/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: hmgts0se with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175445-hmgts0se
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-422
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/hmgts0se
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 115.52it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 118.52it/s] 12%|‚ñà‚ñè        | 37/300 [00:00<00:02, 117.90it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:02, 116.80it/s] 20%|‚ñà‚ñà        | 61/300 [00:00<00:02, 116.48it/s] 24%|‚ñà‚ñà‚ñç       | 73/300 [00:00<00:01, 116.16it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:01, 117.34it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 97/300 [00:00<00:01, 107.55it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:00<00:01, 102.80it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 119/300 [00:01<00:01, 98.92it/s]  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 129/300 [00:01<00:01, 96.68it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 139/300 [00:01<00:01, 95.04it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 93.38it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 93.49it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 90.59it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:01, 90.36it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:01, 91.32it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 201/300 [00:01<00:00, 99.23it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 213/300 [00:02<00:00, 105.09it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:02<00:00, 108.94it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 237/300 [00:02<00:00, 109.74it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 249/300 [00:02<00:00, 110.25it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 261/300 [00:02<00:00, 111.72it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 273/300 [00:02<00:00, 112.30it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:02<00:00, 112.05it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 111.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 105.56it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.35783
wandb: sub_train_loss 1.35373
wandb:       test_acc 0.326
wandb:      valid_acc 0.33
wandb: 
wandb: üöÄ View run crisp-sweep-422 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/hmgts0se
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175445-hmgts0se/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rp39xqv0 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175500-rp39xqv0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-423
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/rp39xqv0
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 120.89it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 122.09it/s] 13%|‚ñà‚ñé        | 39/300 [00:00<00:02, 123.30it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 122.18it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:01, 122.88it/s] 26%|‚ñà‚ñà‚ñå       | 78/300 [00:00<00:01, 123.63it/s] 30%|‚ñà‚ñà‚ñà       | 91/300 [00:00<00:01, 124.23it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 104/300 [00:00<00:01, 124.61it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:00<00:01, 122.75it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 124.06it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 115.22it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 116.99it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 168/300 [00:01<00:01, 116.47it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 115.47it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 192/300 [00:01<00:00, 112.94it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 110.55it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:01<00:00, 110.71it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:01<00:00, 111.21it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 112.03it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 109.00it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 106.16it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 109.01it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 287/300 [00:02<00:00, 111.57it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 299/300 [00:02<00:00, 113.47it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 115.77it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.43168
wandb: sub_train_loss 1.33995
wandb:       test_acc 0.441
wandb:      valid_acc 0.442
wandb: 
wandb: üöÄ View run vague-sweep-423 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/rp39xqv0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175500-rp39xqv0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: iit68am6 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175516-iit68am6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-424
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/iit68am6
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 123.22it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 119.77it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 107.28it/s] 16%|‚ñà‚ñã        | 49/300 [00:00<00:02, 99.75it/s]  20%|‚ñà‚ñà        | 60/300 [00:00<00:02, 97.87it/s] 23%|‚ñà‚ñà‚ñé       | 70/300 [00:00<00:02, 94.23it/s] 27%|‚ñà‚ñà‚ñã       | 82/300 [00:00<00:02, 101.64it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:01, 109.61it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 108/300 [00:01<00:01, 114.71it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:01<00:01, 118.41it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 134/300 [00:01<00:01, 120.34it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 122.82it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 123.32it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 173/300 [00:01<00:01, 123.53it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 186/300 [00:01<00:00, 124.31it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:01<00:00, 124.62it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 212/300 [00:01<00:00, 124.42it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:01<00:00, 124.98it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 238/300 [00:02<00:00, 123.17it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:02<00:00, 123.18it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 120.82it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 277/300 [00:02<00:00, 121.80it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:02<00:00, 122.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 117.64it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.013 MB uploadedwandb: - 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:      valid_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.50369
wandb: sub_train_loss 1.24797
wandb:       test_acc 0.495
wandb:      valid_acc 0.506
wandb: 
wandb: üöÄ View run trim-sweep-424 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/iit68am6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175516-iit68am6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: pqrhbwhn with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175530-pqrhbwhn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-425
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/pqrhbwhn
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 12/300 [00:00<00:02, 119.32it/s]  8%|‚ñä         | 25/300 [00:00<00:02, 120.19it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 118.91it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 115.71it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:02, 114.69it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 114.34it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 112.99it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:00<00:01, 110.58it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:00<00:01, 111.34it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 122/300 [00:01<00:01, 113.77it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:01<00:01, 117.95it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 114.68it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 104.89it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 100.57it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:01<00:01, 93.90it/s]  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:01, 89.66it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 203/300 [00:01<00:01, 95.92it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:02<00:00, 101.19it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 228/300 [00:02<00:00, 106.77it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:02<00:00, 110.81it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 112.57it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 114.64it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 278/300 [00:02<00:00, 116.91it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 290/300 [00:02<00:00, 116.51it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 110.27it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb:      valid_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.3438
wandb: sub_train_loss 1.45777
wandb:       test_acc 0.329
wandb:      valid_acc 0.332
wandb: 
wandb: üöÄ View run giddy-sweep-425 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/pqrhbwhn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175530-pqrhbwhn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: a7znt8xc with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175546-a7znt8xc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-426
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/a7znt8xc
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñç         | 13/300 [00:00<00:02, 125.48it/s]  9%|‚ñä         | 26/300 [00:00<00:02, 115.38it/s] 13%|‚ñà‚ñé        | 38/300 [00:00<00:02, 114.10it/s] 17%|‚ñà‚ñã        | 50/300 [00:00<00:02, 114.49it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:02, 114.69it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:01, 115.16it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:01, 116.53it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 117.84it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 111/300 [00:00<00:01, 116.82it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 123/300 [00:01<00:01, 114.33it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:01<00:01, 113.24it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 147/300 [00:01<00:01, 102.42it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 158/300 [00:01<00:01, 100.44it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 100.48it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 180/300 [00:01<00:01, 102.95it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 191/300 [00:01<00:01, 104.35it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 204/300 [00:01<00:00, 110.43it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:01<00:00, 113.94it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:02<00:00, 115.03it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:02<00:00, 115.87it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 254/300 [00:02<00:00, 118.63it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 267/300 [00:02<00:00, 119.37it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 280/300 [00:02<00:00, 121.68it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 122.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 113.37it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.524
wandb: sub_train_loss 1.23441
wandb:       test_acc 0.53
wandb:      valid_acc 0.54
wandb: 
wandb: üöÄ View run worthy-sweep-426 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/a7znt8xc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175546-a7znt8xc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: jwnhcauj with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175604-jwnhcauj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-427
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/jwnhcauj
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 99.70it/s]  7%|‚ñã         | 21/300 [00:00<00:02, 102.38it/s] 11%|‚ñà         | 32/300 [00:00<00:02, 103.17it/s] 14%|‚ñà‚ñç        | 43/300 [00:00<00:02, 102.70it/s] 18%|‚ñà‚ñä        | 54/300 [00:00<00:02, 100.84it/s] 22%|‚ñà‚ñà‚ñè       | 65/300 [00:00<00:02, 99.86it/s]  25%|‚ñà‚ñà‚ñå       | 75/300 [00:00<00:02, 98.68it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:02, 98.06it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 95/300 [00:00<00:02, 97.84it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 105/300 [00:01<00:01, 97.86it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 115/300 [00:01<00:01, 97.63it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:01<00:01, 97.51it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:01<00:01, 97.35it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 97.24it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 155/300 [00:01<00:01, 97.27it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 96.36it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 175/300 [00:01<00:01, 94.81it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 185/300 [00:01<00:01, 94.80it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 195/300 [00:02<00:01, 93.79it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 205/300 [00:02<00:01, 93.40it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 215/300 [00:02<00:00, 92.79it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:02<00:00, 88.22it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 235/300 [00:02<00:00, 90.07it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 245/300 [00:02<00:00, 87.30it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 255/300 [00:02<00:00, 88.47it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 265/300 [00:02<00:00, 88.88it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 89.74it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:03<00:00, 90.62it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:03<00:00, 91.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 94.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.43648
wandb: sub_train_loss 1.45424
wandb:       test_acc 0.449
wandb:      valid_acc 0.454
wandb: 
wandb: üöÄ View run dry-sweep-427 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/jwnhcauj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175604-jwnhcauj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: rvunnw9d with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.125
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175618-rvunnw9d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-428
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/rvunnw9d
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 10/300 [00:00<00:02, 98.56it/s]  7%|‚ñã         | 21/300 [00:00<00:02, 100.27it/s] 11%|‚ñà         | 32/300 [00:00<00:02, 99.68it/s]  14%|‚ñà‚ñç        | 42/300 [00:00<00:02, 96.44it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 91.48it/s] 21%|‚ñà‚ñà        | 62/300 [00:00<00:02, 88.57it/s] 24%|‚ñà‚ñà‚ñé       | 71/300 [00:00<00:02, 86.92it/s] 27%|‚ñà‚ñà‚ñã       | 80/300 [00:00<00:02, 85.63it/s] 30%|‚ñà‚ñà‚ñâ       | 89/300 [00:00<00:02, 86.27it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 98/300 [00:01<00:02, 86.24it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:01<00:02, 85.31it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:01<00:02, 84.71it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 125/300 [00:01<00:02, 85.42it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 135/300 [00:01<00:01, 87.37it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 145/300 [00:01<00:01, 89.02it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 88.31it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 163/300 [00:01<00:01, 86.80it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 172/300 [00:01<00:01, 85.55it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 181/300 [00:02<00:01, 85.12it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 190/300 [00:02<00:01, 86.16it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:02<00:01, 85.58it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 208/300 [00:02<00:01, 84.93it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 217/300 [00:02<00:00, 84.55it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 226/300 [00:02<00:00, 84.09it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 236/300 [00:02<00:00, 86.11it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 246/300 [00:02<00:00, 87.97it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 256/300 [00:02<00:00, 89.07it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 266/300 [00:03<00:00, 89.61it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 276/300 [00:03<00:00, 89.72it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:03<00:00, 89.81it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 295/300 [00:03<00:00, 89.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 88.06it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.55096
wandb: sub_train_loss 1.23378
wandb:       test_acc 0.558
wandb:      valid_acc 0.572
wandb: 
wandb: üöÄ View run valiant-sweep-428 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/rvunnw9d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175618-rvunnw9d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: nkubz0n3 with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175632-nkubz0n3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-429
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/nkubz0n3
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 103.35it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 104.17it/s] 11%|‚ñà         | 33/300 [00:00<00:02, 103.65it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:02, 102.62it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:02, 101.50it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:02, 98.24it/s]  25%|‚ñà‚ñà‚ñå       | 76/300 [00:00<00:02, 97.27it/s] 29%|‚ñà‚ñà‚ñä       | 86/300 [00:00<00:02, 96.48it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:02, 96.07it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 106/300 [00:01<00:02, 95.68it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 116/300 [00:01<00:01, 95.09it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 126/300 [00:01<00:01, 95.40it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 136/300 [00:01<00:01, 95.08it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 146/300 [00:01<00:01, 94.88it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 156/300 [00:01<00:01, 95.05it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 166/300 [00:01<00:01, 95.63it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:01, 96.65it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:01, 98.67it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 197/300 [00:02<00:01, 92.74it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:02<00:00, 94.35it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 218/300 [00:02<00:00, 96.80it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 229/300 [00:02<00:00, 98.47it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 240/300 [00:02<00:00, 99.50it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 251/300 [00:02<00:00, 100.30it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 99.69it/s]  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 98.51it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 283/300 [00:02<00:00, 99.73it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 294/300 [00:03<00:00, 100.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 97.87it/s] 
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.44165
wandb: sub_train_loss 1.3519
wandb:       test_acc 0.451
wandb:      valid_acc 0.46
wandb: 
wandb: üöÄ View run chocolate-sweep-429 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/nkubz0n3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175632-nkubz0n3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: wx8we17k with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.25
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175647-wx8we17k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-430
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/wx8we17k
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 104.65it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 103.81it/s] 11%|‚ñà         | 33/300 [00:00<00:02, 104.86it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:02, 104.60it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:02, 104.61it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:02, 104.68it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:02, 104.63it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:02, 104.00it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 101.73it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:01, 99.43it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 120/300 [00:01<00:01, 98.29it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 130/300 [00:01<00:01, 96.98it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 140/300 [00:01<00:01, 96.72it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 150/300 [00:01<00:01, 96.23it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 160/300 [00:01<00:01, 95.67it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 170/300 [00:01<00:01, 82.03it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:01, 81.85it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:01, 85.20it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:02<00:01, 84.57it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 207/300 [00:02<00:01, 83.08it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 216/300 [00:02<00:01, 83.42it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 225/300 [00:02<00:00, 83.01it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 234/300 [00:02<00:00, 82.43it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 243/300 [00:02<00:00, 83.41it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 83.25it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 263/300 [00:02<00:00, 88.54it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 274/300 [00:02<00:00, 92.30it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 285/300 [00:03<00:00, 95.26it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 296/300 [00:03<00:00, 97.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 93.26it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.4771
wandb: sub_train_loss 1.41477
wandb:       test_acc 0.481
wandb:      valid_acc 0.494
wandb: 
wandb: üöÄ View run rural-sweep-430 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/wx8we17k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175647-wx8we17k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 4ll605ds with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175710-4ll605ds
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-431
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/4ll605ds
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  3%|‚ñé         | 9/300 [00:00<00:03, 88.67it/s]  6%|‚ñã         | 19/300 [00:00<00:02, 94.12it/s] 10%|‚ñà         | 30/300 [00:00<00:02, 97.76it/s] 14%|‚ñà‚ñé        | 41/300 [00:00<00:02, 99.48it/s] 17%|‚ñà‚ñã        | 52/300 [00:00<00:02, 100.45it/s] 21%|‚ñà‚ñà        | 63/300 [00:00<00:02, 101.16it/s] 25%|‚ñà‚ñà‚ñç       | 74/300 [00:00<00:02, 101.48it/s] 28%|‚ñà‚ñà‚ñä       | 85/300 [00:00<00:02, 101.53it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 96/300 [00:00<00:02, 101.39it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 107/300 [00:01<00:01, 99.21it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 117/300 [00:01<00:01, 98.26it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 128/300 [00:01<00:01, 99.29it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 138/300 [00:01<00:01, 99.16it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 149/300 [00:01<00:01, 99.71it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 159/300 [00:01<00:01, 99.49it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 169/300 [00:01<00:01, 99.34it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 179/300 [00:01<00:01, 96.90it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 189/300 [00:01<00:01, 94.45it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 199/300 [00:02<00:01, 94.04it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 210/300 [00:02<00:00, 95.91it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:02<00:00, 96.29it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:02<00:00, 97.45it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 241/300 [00:02<00:00, 97.98it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 252/300 [00:02<00:00, 99.07it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 262/300 [00:02<00:00, 99.23it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 272/300 [00:02<00:00, 99.37it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 282/300 [00:02<00:00, 97.89it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 293/300 [00:02<00:00, 99.13it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:03<00:00, 98.48it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb:       test_acc ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      valid_acc ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.30391
wandb: sub_train_loss 1.45534
wandb:       test_acc 0.319
wandb:      valid_acc 0.316
wandb: 
wandb: üöÄ View run bumbling-sweep-431 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/4ll605ds
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175710-4ll605ds/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Agent Starting Run: m5j0e0up with config:
wandb: 	activation_type: Relu
wandb: 	batch_size: 1024
wandb: 	dataset_name: CoraGraphDataset
wandb: 	exclusion_type: Largest
wandb: 	hidden_dim: 128
wandb: 	learning_rate: 0.0001
wandb: 	model_type: GCN
wandb: 	num_epochs: 300
wandb: 	num_hidden_layers: 3
wandb: 	optimizer_type: Adam
wandb: 	sample_rate: 0.375
wandb: 	trace_type: Feature
wandb: 	weight_decay: 0.0001
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.6
wandb: Run data is saved locally in /home/hli230/stats_leverage_sampling/GNN_test/SAGE_GCN/wandb/run-20240824_175724-m5j0e0up
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-432
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: üßπ View sweep at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/sweeps/fqnv4fuu
wandb: üöÄ View run at https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/m5j0e0up
  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
num_nodes 2708 num_edges 10556
  0%|          | 0/300 [00:00<?, ?it/s]  4%|‚ñé         | 11/300 [00:00<00:02, 102.44it/s]  7%|‚ñã         | 22/300 [00:00<00:02, 103.05it/s] 11%|‚ñà         | 33/300 [00:00<00:02, 101.49it/s] 15%|‚ñà‚ñç        | 44/300 [00:00<00:02, 102.35it/s] 18%|‚ñà‚ñä        | 55/300 [00:00<00:02, 103.11it/s] 22%|‚ñà‚ñà‚ñè       | 66/300 [00:00<00:02, 103.49it/s] 26%|‚ñà‚ñà‚ñå       | 77/300 [00:00<00:02, 103.48it/s] 29%|‚ñà‚ñà‚ñâ       | 88/300 [00:00<00:02, 103.84it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 99/300 [00:00<00:01, 103.88it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 110/300 [00:01<00:01, 103.96it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 121/300 [00:01<00:01, 103.83it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 132/300 [00:01<00:01, 104.10it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 143/300 [00:01<00:01, 104.30it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 154/300 [00:01<00:01, 104.43it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 165/300 [00:01<00:01, 104.17it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 176/300 [00:01<00:01, 104.14it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 187/300 [00:01<00:01, 104.37it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 198/300 [00:01<00:00, 103.88it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 209/300 [00:02<00:00, 103.94it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 220/300 [00:02<00:00, 103.97it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 231/300 [00:02<00:00, 103.35it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 242/300 [00:02<00:00, 101.87it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 253/300 [00:02<00:00, 101.48it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 264/300 [00:02<00:00, 101.04it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 275/300 [00:02<00:00, 100.55it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 286/300 [00:02<00:00, 101.78it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 297/300 [00:02<00:00, 102.73it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:02<00:00, 103.15it/s]
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.023 MB of 0.023 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  sub_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñà
wandb: sub_train_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:       test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñà
wandb:      valid_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñà
wandb: 
wandb: Run summary:
wandb:  sub_train_acc 0.4952
wandb: sub_train_loss 1.44491
wandb:       test_acc 0.507
wandb:      valid_acc 0.524
wandb: 
wandb: üöÄ View run restful-sweep-432 at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler/runs/m5j0e0up
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jamesli-wks-johns-hopkins-university/SAGE_GCN_hyperparameter_tuning_cora_correct_sampler
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240824_175724-m5j0e0up/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: Sweep Agent: Waiting for job.
wandb: Sweep Agent: Exiting.
