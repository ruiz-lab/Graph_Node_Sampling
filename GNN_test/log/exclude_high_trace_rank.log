exclude_high_
dataset: Cora
threshold: 0.4
calculating hat matrix

...

leverage_score computed
2263, 83.57% nodes are excluded
sampled training set size: 20, new test set size: 182, new val set size: 73
original: training set size: 140, original test set size: 1000, original val set size: 500
percentage preserved: training set: 14.29%, test set: 18.20%, val set: 14.60%
full size rank time: 0:00:17.455121

full size trace time: 0:00:00.003466

sub rank time: 0:00:00.265445

sub trace time: 0:00:00.008453

full size rank: 2408
sub rank: 176
rank ratio: 0.0731


full size trace: 0.0
sub trace: 0.0
threshold: 0.5
calculating hat matrix

...

leverage_score computed
1771, 65.40% nodes are excluded
sampled training set size: 46, new test set size: 366, new val set size: 163
original: training set size: 140, original test set size: 1000, original val set size: 500
percentage preserved: training set: 32.86%, test set: 36.60%, val set: 32.60%
full size rank time: 0:00:07.160121

full size trace time: 0:00:00.002103

sub rank time: 0:00:00.280788

sub trace time: 0:00:00.004947

full size rank: 2408
sub rank: 527
rank ratio: 0.2189


full size trace: 0.0
sub trace: 0.0
threshold: 0.6000000000000001
calculating hat matrix

...

leverage_score computed
960, 35.45% nodes are excluded
sampled training set size: 96, new test set size: 669, new val set size: 311
original: training set size: 140, original test set size: 1000, original val set size: 500
percentage preserved: training set: 68.57%, test set: 66.90%, val set: 62.20%
full size rank time: 0:00:05.353381

full size trace time: 0:00:00.007421

sub rank time: 0:00:00.810886

sub trace time: 0:00:00.000913

full size rank: 2408
sub rank: 558
rank ratio: 0.2317


full size trace: 0.0
sub trace: 0.0
threshold: 0.7000000000000001
calculating hat matrix

...

leverage_score computed
233, 8.60% nodes are excluded
sampled training set size: 128, new test set size: 917, new val set size: 454
original: training set size: 140, original test set size: 1000, original val set size: 500
percentage preserved: training set: 91.43%, test set: 91.70%, val set: 90.80%
full size rank time: 0:00:03.184157

full size trace time: 0:00:00.003143

sub rank time: 0:00:01.894819

sub trace time: 0:00:00.001151

full size rank: 2408
sub rank: 55
rank ratio: 0.0228


full size trace: 0.0
sub trace: 0.0
threshold: 0.8
calculating hat matrix

...

leverage_score computed
24, 0.89% nodes are excluded
sampled training set size: 140, new test set size: 991, new val set size: 493
original: training set size: 140, original test set size: 1000, original val set size: 500
percentage preserved: training set: 100.00%, test set: 99.10%, val set: 98.60%
full size rank time: 0:00:03.665388

full size trace time: 0:00:00.002526

sub rank time: 0:00:02.758218

sub trace time: 0:00:00.001195

full size rank: 2408
sub rank: 0
rank ratio: 0.0000


full size trace: 0.0
sub trace: 0.0
dataset: CiteSeer
threshold: 0.9
calculating hat matrix

...

leverage_score computed
2881, 86.59% nodes are excluded
sampled training set size: 21, new test set size: 128, new val set size: 74
original: training set size: 120, original test set size: 1000, original val set size: 500
percentage preserved: training set: 17.50%, test set: 12.80%, val set: 14.80%
full size rank time: 0:00:07.705735

full size trace time: 0:00:00.019911

sub rank time: 0:00:00.121878

sub trace time: 0:00:00.000788

full size rank: 2788
sub rank: 113
rank ratio: 0.0405


full size trace: 0.0
sub trace: 0.0
threshold: 0.9225
calculating hat matrix

...

leverage_score computed
2541, 76.38% nodes are excluded
sampled training set size: 32, new test set size: 229, new val set size: 130
original: training set size: 120, original test set size: 1000, original val set size: 500
percentage preserved: training set: 26.67%, test set: 22.90%, val set: 26.00%
full size rank time: 0:00:07.362247

full size trace time: 0:00:00.019852

sub rank time: 0:00:00.288991

sub trace time: 0:00:00.018696

full size rank: 2788
sub rank: 290
rank ratio: 0.1040


full size trace: 0.0
sub trace: 0.0
threshold: 0.9450000000000001
calculating hat matrix

...

leverage_score computed
1822, 54.76% nodes are excluded
sampled training set size: 57, new test set size: 462, new val set size: 226
original: training set size: 120, original test set size: 1000, original val set size: 500
percentage preserved: training set: 47.50%, test set: 46.20%, val set: 45.20%
full size rank time: 0:00:07.844813

full size trace time: 0:00:00.024863

sub rank time: 0:00:00.782608

sub trace time: 0:00:00.001001

full size rank: 2788
sub rank: 858
rank ratio: 0.3077


full size trace: 0.0
sub trace: 0.0
threshold: 0.9675
calculating hat matrix

...

leverage_score computed
517, 15.54% nodes are excluded
sampled training set size: 105, new test set size: 870, new val set size: 406
original: training set size: 120, original test set size: 1000, original val set size: 500
percentage preserved: training set: 87.50%, test set: 87.00%, val set: 81.20%
full size rank time: 0:00:06.972976

full size trace time: 0:00:00.021555

sub rank time: 0:00:03.851573

sub trace time: 0:00:00.004128

full size rank: 2788
sub rank: 169
rank ratio: 0.0606


full size trace: 0.0
sub trace: 0.0
threshold: 0.99
calculating hat matrix

...

leverage_score computed
6, 0.18% nodes are excluded
sampled training set size: 120, new test set size: 998, new val set size: 499
original: training set size: 120, original test set size: 1000, original val set size: 500
percentage preserved: training set: 100.00%, test set: 99.80%, val set: 99.80%
full size rank time: 0:00:07.654368

full size trace time: 0:00:00.019243

sub rank time: 0:00:06.434708

sub trace time: 0:00:00.015698

full size rank: 2788
sub rank: 0
rank ratio: 0.0000


full size trace: 0.0
sub trace: 0.0
dataset: PubMed
threshold: 0.015
calculating hat matrix

...

leverage_score computed
16309, 82.72% nodes are excluded
sampled training set size: 11, new test set size: 182, new val set size: 81
original: training set size: 60, original test set size: 1000, original val set size: 500
percentage preserved: training set: 18.33%, test set: 18.20%, val set: 16.20%
full size rank time: 0:15:37.980813

full size trace time: 0:00:00.244290

sub rank time: 0:00:09.280102

sub trace time: 0:00:00.022447

full size rank: 7596
sub rank: 988
rank ratio: 0.1301


full size trace: 0.0
sub trace: 0.0
threshold: 0.025
calculating hat matrix

...

leverage_score computed
7621, 38.65% nodes are excluded
sampled training set size: 37, new test set size: 587, new val set size: 300
original: training set size: 60, original test set size: 1000, original val set size: 500
percentage preserved: training set: 61.67%, test set: 58.70%, val set: 60.00%
full size rank time: 0:15:45.973319

full size trace time: 0:00:00.220542

sub rank time: 0:04:27.694536

sub trace time: 0:00:00.102074

full size rank: 7596
sub rank: 2806
rank ratio: 0.3694


full size trace: 0.0
sub trace: 0.0
threshold: 0.035
calculating hat matrix

...

leverage_score computed
3170, 16.08% nodes are excluded
sampled training set size: 46, new test set size: 831, new val set size: 417
original: training set size: 60, original test set size: 1000, original val set size: 500
percentage preserved: training set: 76.67%, test set: 83.10%, val set: 83.40%
full size rank time: 0:15:12.258130

full size trace time: 0:00:00.217223

sub rank time: 0:09:45.319514

sub trace time: 0:00:00.161634

full size rank: 7596
sub rank: 861
rank ratio: 0.1133


full size trace: 0.0
sub trace: 0.0
threshold: 0.045
calculating hat matrix

...

leverage_score computed
1448, 7.34% nodes are excluded
sampled training set size: 57, new test set size: 926, new val set size: 463
original: training set size: 60, original test set size: 1000, original val set size: 500
percentage preserved: training set: 95.00%, test set: 92.60%, val set: 92.60%
full size rank time: 0:15:37.898447

full size trace time: 0:00:00.274087

sub rank time: 0:12:18.500727

sub trace time: 0:00:00.216896

full size rank: 7596
sub rank: 294
rank ratio: 0.0387


full size trace: 0.0
sub trace: 0.0
threshold: 0.055
calculating hat matrix

...

leverage_score computed
697, 3.54% nodes are excluded
sampled training set size: 59, new test set size: 965, new val set size: 481
original: training set size: 60, original test set size: 1000, original val set size: 500
percentage preserved: training set: 98.33%, test set: 96.50%, val set: 96.20%
full size rank time: 0:15:36.685843

full size trace time: 0:00:00.214155

sub rank time: 0:13:40.961658

sub trace time: 0:00:00.198127

full size rank: 7596
sub rank: 82
rank ratio: 0.0108


full size trace: 0.0
sub trace: 0.0
Traceback (most recent call last):
  File "/home/jamesl/stats_leverage/GNN_Test/trace_rank.py", line 144, in <module>
    main(argparser)
  File "/home/jamesl/stats_leverage/GNN_Test/trace_rank.py", line 139, in main
    json.dump(rst_dict, f)
  File "/home/jamesl/anaconda3/envs/pytorch/lib/python3.11/json/__init__.py", line 179, in dump
    for chunk in iterable:
  File "/home/jamesl/anaconda3/envs/pytorch/lib/python3.11/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/home/jamesl/anaconda3/envs/pytorch/lib/python3.11/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/home/jamesl/anaconda3/envs/pytorch/lib/python3.11/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/home/jamesl/anaconda3/envs/pytorch/lib/python3.11/json/encoder.py", line 326, in _iterencode_list
    yield from chunks
  File "/home/jamesl/anaconda3/envs/pytorch/lib/python3.11/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/home/jamesl/anaconda3/envs/pytorch/lib/python3.11/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type int64 is not JSON serializable
